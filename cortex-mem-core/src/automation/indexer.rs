#![cfg(feature = "vector-search")]

use crate::{
    embedding::EmbeddingClient,
    filesystem::{CortexFilesystem, FilesystemOperations},
    session::Message,
    vector_store::{QdrantVectorStore, VectorStore},
    Result,
};
use std::sync::Arc;
use tracing::{debug, info, warn};

/// è‡ªåŠ¨ç´¢å¼•ç®¡ç†å™¨é…ç½®
#[derive(Debug, Clone)]
pub struct IndexerConfig {
    /// æ˜¯å¦è‡ªåŠ¨ç´¢å¼•æ–°æ¶ˆæ¯
    pub auto_index: bool,
    /// æ‰¹é‡ç´¢å¼•çš„batchå¤§å°
    pub batch_size: usize,
    /// æ˜¯å¦åœ¨åå°å¼‚æ­¥ç´¢å¼•
    pub async_index: bool,
}

impl Default for IndexerConfig {
    fn default() -> Self {
        Self {
            auto_index: true,
            batch_size: 10,
            async_index: true,
        }
    }
}

/// ç´¢å¼•ç»Ÿè®¡
#[derive(Debug, Clone, Default)]
pub struct IndexStats {
    pub total_indexed: usize,
    pub total_skipped: usize,
    pub total_errors: usize,
}

/// è‡ªåŠ¨ç´¢å¼•ç®¡ç†å™¨
///
/// è´Ÿè´£ï¼š
/// 1. ç›‘å¬æ–°æ¶ˆæ¯å¹¶è‡ªåŠ¨ç”Ÿæˆembedding
/// 2. æ‰¹é‡ç´¢å¼•ç°æœ‰æ¶ˆæ¯
/// 3. å¢é‡æ›´æ–°ç´¢å¼•
#[cfg(feature = "vector-search")]
pub struct AutoIndexer {
    filesystem: Arc<CortexFilesystem>,
    embedding: Arc<EmbeddingClient>,
    vector_store: Arc<QdrantVectorStore>,
    config: IndexerConfig,
}

#[cfg(feature = "vector-search")]
impl AutoIndexer {
    /// åˆ›å»ºæ–°çš„è‡ªåŠ¨ç´¢å¼•å™¨
    pub fn new(
        filesystem: Arc<CortexFilesystem>,
        embedding: Arc<EmbeddingClient>,
        vector_store: Arc<QdrantVectorStore>,
        config: IndexerConfig,
    ) -> Self {
        Self {
            filesystem,
            embedding,
            vector_store,
            config,
        }
    }

    /// ç´¢å¼•å•ä¸ªæ¶ˆæ¯
    pub async fn index_message(&self, thread_id: &str, message: &Message) -> Result<()> {
        info!("Indexing message {} in thread {}", message.id, thread_id);

        // 1. ç”Ÿæˆembedding
        let embedding = self.embedding.embed(&message.content).await?;

        // 2. åˆ›å»ºMemoryå¯¹è±¡
        let memory = crate::types::Memory {
            id: message.id.clone(),
            content: message.content.clone(),
            embedding,
            created_at: message.created_at,
            updated_at: message.created_at,
            metadata: crate::types::MemoryMetadata {
                user_id: None,
                agent_id: None,
                run_id: Some(thread_id.to_string()),
                actor_id: None,
                role: Some(format!("{:?}", message.role)),
                memory_type: crate::types::MemoryType::Conversational,
                hash: self.calculate_hash(&message.content),
                importance_score: 0.5,
                entities: vec![],
                topics: vec![],
                custom: std::collections::HashMap::new(),
            },
        };

        // 3. å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        self.vector_store.as_ref().insert(&memory).await?;

        debug!("Message {} indexed successfully", message.id);
        Ok(())
    }

    /// æ‰¹é‡ç´¢å¼•çº¿ç¨‹ä¸­çš„æ‰€æœ‰æ¶ˆæ¯
    pub async fn index_thread(&self, thread_id: &str) -> Result<IndexStats> {
        self.index_thread_with_progress::<fn(usize, usize)>(thread_id, None)
            .await
    }

    /// æ‰¹é‡ç´¢å¼•çº¿ç¨‹ä¸­çš„æ‰€æœ‰æ¶ˆæ¯ï¼Œå¸¦è¿›åº¦å›è°ƒ
    pub async fn index_thread_with_progress<F>(
        &self,
        thread_id: &str,
        mut progress_callback: Option<F>,
    ) -> Result<IndexStats>
    where
        F: FnMut(usize, usize) + Send,
    {
        info!("Starting batch indexing for thread: {}", thread_id);

        let mut stats = IndexStats::default();

        // 1. æ‰«ætimelineç›®å½•è·å–æ‰€æœ‰æ¶ˆæ¯
        let messages = self.collect_messages(thread_id).await?;
        let total_messages = messages.len();
        info!("Found {} messages to index", total_messages);

        if total_messages == 0 {
            return Ok(stats);
        }

        // 2. æ£€æŸ¥å“ªäº›æ¶ˆæ¯å·²ç»è¢«ç´¢å¼•ï¼ˆé€šè¿‡æŸ¥è¯¢å‘é‡æ•°æ®åº“ï¼‰
        let existing_ids = self.get_indexed_message_ids(thread_id).await?;
        let messages_to_index: Vec<_> = messages
            .into_iter()
            .filter(|m| !existing_ids.contains(&m.id))
            .collect();

        info!(
            "Skipping {} already indexed messages",
            total_messages - messages_to_index.len()
        );
        stats.total_skipped = total_messages - messages_to_index.len();

        if messages_to_index.is_empty() {
            info!("All messages already indexed");
            return Ok(stats);
        }

        // 3. åˆ†æ‰¹å¤„ç†
        let total_to_index = messages_to_index.len();
        for (batch_idx, chunk) in messages_to_index.chunks(self.config.batch_size).enumerate() {
            let batch_start = batch_idx * self.config.batch_size;

            // é€šçŸ¥è¿›åº¦
            if let Some(ref mut callback) = progress_callback {
                callback(batch_start, total_to_index);
            }

            // ç”Ÿæˆæ‰€æœ‰embedding
            let contents: Vec<String> = chunk.iter().map(|m| m.content.clone()).collect();

            match self.embedding.embed_batch(&contents).await {
                Ok(embeddings) => {
                    // ä¸ºæ¯ä¸ªæ¶ˆæ¯åˆ›å»ºMemoryå¹¶å­˜å‚¨
                    for (message, embedding) in chunk.iter().zip(embeddings.iter()) {
                        let memory = crate::types::Memory {
                            id: message.id.clone(),
                            content: message.content.clone(),
                            embedding: embedding.clone(),
                            created_at: message.created_at,
                            updated_at: message.created_at,
                            metadata: crate::types::MemoryMetadata {
                                user_id: None,
                                agent_id: None,
                                run_id: Some(thread_id.to_string()),
                                actor_id: None,
                                role: Some(format!("{:?}", message.role)),
                                memory_type: crate::types::MemoryType::Conversational,
                                hash: self.calculate_hash(&message.content),
                                importance_score: 0.5,
                                entities: vec![],
                                topics: vec![],
                                custom: std::collections::HashMap::new(),
                            },
                        };

                        match self.vector_store.as_ref().insert(&memory).await {
                            Ok(_) => {
                                stats.total_indexed += 1;
                                debug!("Indexed message {}", message.id);
                            }
                            Err(e) => {
                                warn!("Failed to index message {}: {}", message.id, e);
                                stats.total_errors += 1;
                            }
                        }
                    }
                }
                Err(e) => {
                    warn!(
                        "Failed to generate embeddings for batch {}: {}",
                        batch_idx, e
                    );
                    stats.total_errors += chunk.len();
                }
            }
        }

        info!(
            "Batch indexing complete: {} indexed, {} skipped, {} errors",
            stats.total_indexed, stats.total_skipped, stats.total_errors
        );

        Ok(stats)
    }

    /// è·å–å·²ç´¢å¼•çš„æ¶ˆæ¯IDåˆ—è¡¨
    async fn get_indexed_message_ids(
        &self,
        thread_id: &str,
    ) -> Result<std::collections::HashSet<String>> {
        use crate::vector_store::VectorStore;

        // ä½¿ç”¨scroll APIè·å–æ‰€æœ‰å·²ç´¢å¼•çš„æ¶ˆæ¯ID
        let filters = crate::types::Filters {
            run_id: Some(thread_id.to_string()),
            ..Default::default()
        };

        // æ»šåŠ¨æŸ¥è¯¢è·å–æ‰€æœ‰IDï¼ˆä¸éœ€è¦embeddingï¼‰
        match self.vector_store.as_ref().scroll_ids(&filters, 1000).await {
            Ok(ids) => Ok(ids.into_iter().collect()),
            Err(e) => {
                warn!(
                    "Failed to get indexed message IDs: {}, assuming none indexed",
                    e
                );
                Ok(std::collections::HashSet::new())
            }
        }
    }

    /// æ”¶é›†çº¿ç¨‹ä¸­çš„æ‰€æœ‰æ¶ˆæ¯
    async fn collect_messages(&self, thread_id: &str) -> Result<Vec<Message>> {
        let timeline_uri = format!("cortex://session/{}/timeline", thread_id);
        let mut messages = Vec::new();

        self.collect_messages_recursive(&timeline_uri, &mut messages)
            .await?;

        Ok(messages)
    }

    /// é€’å½’æ”¶é›†æ¶ˆæ¯
    fn collect_messages_recursive<'a>(
        &'a self,
        uri: &'a str,
        messages: &'a mut Vec<Message>,
    ) -> std::pin::Pin<Box<dyn std::future::Future<Output = Result<()>> + Send + 'a>> {
        Box::pin(async move {
            let entries = self.filesystem.as_ref().list(uri).await?;

            for entry in entries {
                if entry.is_directory && !entry.name.starts_with('.') {
                    self.collect_messages_recursive(&entry.uri, messages)
                        .await?;
                } else if entry.name.ends_with(".md") && !entry.name.starts_with('.') {
                    if let Ok(content) = self.filesystem.as_ref().read(&entry.uri).await {
                        if let Some(message) = self.parse_message_markdown(&content) {
                            messages.push(message);
                        }
                    }
                }
            }

            Ok(())
        })
    }

    /// è§£æMarkdownæ ¼å¼çš„æ¶ˆæ¯
    fn parse_message_markdown(&self, content: &str) -> Option<Message> {
        use crate::session::MessageRole;

        let mut role = MessageRole::User;
        let mut message_content = String::new();
        let mut id = String::new();
        let mut timestamp = chrono::Utc::now();

        for line in content.lines() {
            if line.starts_with("# ğŸ‘¤ User") {
                role = MessageRole::User;
            } else if line.starts_with("# ğŸ¤– Assistant") {
                role = MessageRole::Assistant;
            } else if line.starts_with("# ğŸ”§ System") {
                role = MessageRole::System;
            } else if line.starts_with("**ID**: `") {
                if let Some(id_str) = line
                    .strip_prefix("**ID**: `")
                    .and_then(|s| s.strip_suffix("`"))
                {
                    id = id_str.to_string();
                }
            } else if line.starts_with("**Timestamp**: ") {
                if let Some(ts_str) = line.strip_prefix("**Timestamp**: ") {
                    if let Ok(parsed_ts) =
                        chrono::DateTime::parse_from_str(ts_str, "%Y-%m-%d %H:%M:%S %Z")
                    {
                        timestamp = parsed_ts.with_timezone(&chrono::Utc);
                    }
                }
            } else if line.starts_with("## Content") {
                // å†…å®¹å¼€å§‹
            } else if !line.starts_with('#') && !line.starts_with("**") && !line.trim().is_empty() {
                if !message_content.is_empty() {
                    message_content.push('\n');
                }
                message_content.push_str(line);
            }
        }

        if !id.is_empty() && !message_content.is_empty() {
            Some(Message {
                id,
                role,
                content: message_content.trim().to_string(),
                timestamp,
                created_at: timestamp,
                metadata: None,
            })
        } else {
            None
        }
    }

    /// è®¡ç®—å†…å®¹å“ˆå¸Œ
    fn calculate_hash(&self, content: &str) -> String {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        let mut hasher = DefaultHasher::new();
        content.hash(&mut hasher);
        format!("{:x}", hasher.finish())
    }
}
