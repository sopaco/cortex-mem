# Cortex-Memory 3.0 è¯¦ç»†å¼€å‘è®¡åˆ’

> æŒ‰é˜¶æ®µæ‹†è§£çš„è¯¦ç»†å¼€å‘ä»»åŠ¡ã€äº¤ä»˜ç‰©å’ŒéªŒæ”¶æ ‡å‡†

---

## é˜¶æ®µ 0: å½“å‰é—®é¢˜ä¿®å¤ï¼ˆ2å‘¨ï¼Œå¿…é¡»ä¼˜å…ˆå®Œæˆï¼‰

### Sprint 0.1: ä¸‰å±‚æ–‡ä»¶è¡¥å…¨ï¼ˆ1å‘¨ï¼‰

#### Task 0.1.1: ç›®å½•æ‰«æä¸æ£€æµ‹

**è´Ÿè´£æ¨¡å—**: `cortex-mem-core/src/automation/auto_indexer.rs`

**ä»»åŠ¡æè¿°**:
1. å®ç° `scan_all_directories()` æ–¹æ³•ï¼Œé€’å½’æ‰«ææ‰€æœ‰ç»´åº¦çš„ç›®å½•
2. å®ç° `has_layers()` æ–¹æ³•ï¼Œæ£€æµ‹ç›®å½•æ˜¯å¦æ‹¥æœ‰ `.abstract` å’Œ `.overview`
3. å®ç° `filter_missing_layers()` æ–¹æ³•ï¼Œè¿‡æ»¤å‡ºç¼ºå¤±çš„ç›®å½•

**ä»£ç éª¨æ¶**:
```rust
// cortex-mem-core/src/automation/layer_generator.rs (æ–°æ–‡ä»¶)
pub struct LayerGenerator {
    filesystem: Arc<CortexFilesystem>,
    llm_client: Arc<dyn LLMClient>,
    config: LayerGenerationConfig,
}

pub struct LayerGenerationConfig {
    pub batch_size: usize,
    pub delay_ms: u64,
    pub auto_generate_on_startup: bool,
}

impl LayerGenerator {
    /// æ‰«ææ‰€æœ‰ç›®å½•
    pub async fn scan_all_directories(&self) -> Result<Vec<String>> {
        let mut directories = vec![];
        
        // æ‰«æå››ä¸ªç»´åº¦
        for scope in &["session", "user", "agent", "resources"] {
            let scope_dirs = self.scan_scope(scope).await?;
            directories.extend(scope_dirs);
        }
        
        Ok(directories)
    }
    
    async fn scan_scope(&self, scope: &str) -> Result<Vec<String>> {
        // TODO: é€’å½’æ‰«æ cortex://{scope}/ ä¸‹çš„æ‰€æœ‰ç›®å½•
        unimplemented!()
    }
    
    /// æ£€æµ‹ç›®å½•æ˜¯å¦æœ‰ L0/L1 æ–‡ä»¶
    pub async fn has_layers(&self, uri: &str) -> Result<bool> {
        let abstract_path = format!("{}/.abstract", uri);
        let overview_path = format!("{}/.overview", uri);
        
        Ok(
            self.filesystem.exists(&abstract_path).await? &&
            self.filesystem.exists(&overview_path).await?
        )
    }
    
    /// è¿‡æ»¤å‡ºç¼ºå¤± L0/L1 çš„ç›®å½•
    pub async fn filter_missing_layers(&self, dirs: &[String]) -> Result<Vec<String>> {
        let mut missing = vec![];
        for dir in dirs {
            if !self.has_layers(dir).await? {
                missing.push(dir.clone());
            }
        }
        Ok(missing)
    }
}
```

**Deliverables**:
- [ ] `layer_generator.rs` æ–‡ä»¶åˆ›å»º
- [ ] å•å…ƒæµ‹è¯•: `test_scan_all_directories()`
- [ ] å•å…ƒæµ‹è¯•: `test_has_layers()`
- [ ] å•å…ƒæµ‹è¯•: `test_filter_missing_layers()`

**éªŒæ”¶æ ‡å‡†**:
- èƒ½æ­£ç¡®æ‰«ææ‰€æœ‰ç»´åº¦çš„ç›®å½•
- å‡†ç¡®æ£€æµ‹ L0/L1 æ–‡ä»¶æ˜¯å¦å­˜åœ¨
- æµ‹è¯•è¦†ç›–ç‡ > 85%

---

#### Task 0.1.2: æ¸è¿›å¼ç”Ÿæˆå®ç°

**ä»»åŠ¡æè¿°**:
1. å®ç° `ensure_all_layers()` æ–¹æ³•ï¼Œåˆ†æ‰¹ç”Ÿæˆç¼ºå¤±çš„ L0/L1
2. æ·»åŠ æ‰¹æ¬¡é—´å»¶è¿Ÿï¼Œé¿å… LLM API é™æµ
3. å®ç°è¿›åº¦è·Ÿè¸ªå’Œç»Ÿè®¡

**ä»£ç éª¨æ¶**:
```rust
impl LayerGenerator {
    /// ç¡®ä¿æ‰€æœ‰ç›®å½•æ‹¥æœ‰ L0/L1
    pub async fn ensure_all_layers(&self) -> Result<GenerationStats> {
        info!("å¼€å§‹æ‰«æç›®å½•...");
        let directories = self.scan_all_directories().await?;
        
        info!("æ£€æµ‹ç¼ºå¤±çš„ L0/L1...");
        let missing = self.filter_missing_layers(&directories).await?;
        
        info!("å‘ç° {} ä¸ªç›®å½•ç¼ºå¤± L0/L1ï¼Œå¼€å§‹ç”Ÿæˆ...", missing.len());
        
        let mut stats = GenerationStats {
            total: missing.len(),
            generated: 0,
            failed: 0,
        };
        
        // åˆ†æ‰¹ç”Ÿæˆ
        for (batch_idx, batch) in missing.chunks(self.config.batch_size).enumerate() {
            info!("å¤„ç†æ‰¹æ¬¡ {}/{}", batch_idx + 1, (missing.len() + self.config.batch_size - 1) / self.config.batch_size);
            
            for dir in batch {
                match self.generate_layers_for_directory(dir).await {
                    Ok(_) => {
                        stats.generated += 1;
                        info!("âœ“ ç”ŸæˆæˆåŠŸ: {}", dir);
                    }
                    Err(e) => {
                        stats.failed += 1;
                        warn!("âœ— ç”Ÿæˆå¤±è´¥: {} - {}", dir, e);
                    }
                }
            }
            
            // æ‰¹æ¬¡é—´å»¶è¿Ÿ
            if batch_idx < (missing.len() + self.config.batch_size - 1) / self.config.batch_size - 1 {
                tokio::time::sleep(Duration::from_millis(self.config.delay_ms)).await;
            }
        }
        
        info!("ç”Ÿæˆå®Œæˆ: æˆåŠŸ {}, å¤±è´¥ {}", stats.generated, stats.failed);
        Ok(stats)
    }
    
    /// ä¸ºå•ä¸ªç›®å½•ç”Ÿæˆ L0/L1
    async fn generate_layers_for_directory(&self, uri: &str) -> Result<()> {
        // 1. è¯»å–ç›®å½•å†…å®¹
        let entries = self.filesystem.list(uri).await?;
        
        // 2. èšåˆå†…å®¹ï¼ˆè¯»å–å­æ–‡ä»¶ï¼‰
        let content = self.aggregate_directory_content(uri, &entries).await?;
        
        // 3. ç”Ÿæˆ L0 æŠ½è±¡
        let abstract_text = self.generate_abstract(&content).await?;
        
        // 4. ç”Ÿæˆ L1 æ¦‚è§ˆ
        let overview = self.generate_overview(&content).await?;
        
        // 5. å†™å…¥æ–‡ä»¶
        self.filesystem.write(&format!("{}/.abstract", uri), &abstract_text).await?;
        self.filesystem.write(&format!("{}/.overview", uri), &overview).await?;
        
        Ok(())
    }
    
    /// èšåˆç›®å½•å†…å®¹
    async fn aggregate_directory_content(&self, uri: &str, entries: &[String]) -> Result<String> {
        // TODO: è¯»å–å­æ–‡ä»¶å†…å®¹ï¼Œæ‹¼æ¥æˆå®Œæ•´æ–‡æœ¬
        // æ³¨æ„ï¼šéœ€è¦åˆç†æˆªæ–­ï¼Œé¿å…è¶…å‡º LLM ä¸Šä¸‹æ–‡é™åˆ¶
        unimplemented!()
    }
}
```

**Deliverables**:
- [ ] `ensure_all_layers()` å®ç°
- [ ] `generate_layers_for_directory()` å®ç°
- [ ] å•å…ƒæµ‹è¯•: `test_ensure_all_layers()`
- [ ] é›†æˆæµ‹è¯•: æ¨¡æ‹Ÿç¼ºå¤±ç›®å½•ç”Ÿæˆ

**éªŒæ”¶æ ‡å‡†**:
- èƒ½åˆ†æ‰¹ç”Ÿæˆæ‰€æœ‰ç¼ºå¤±çš„ L0/L1
- æ‰¹æ¬¡é—´å»¶è¿Ÿç”Ÿæ•ˆ
- ç»Ÿè®¡ä¿¡æ¯å‡†ç¡®
- å¤±è´¥åç»§ç»­å¤„ç†å…¶ä»–ç›®å½•

---

#### Task 0.1.3: CLI é›†æˆ

**ä»»åŠ¡æè¿°**:
1. æ·»åŠ  `layers ensure-all` å‘½ä»¤
2. æ·»åŠ  `layers status` å‘½ä»¤æŸ¥çœ‹è¿›åº¦
3. æ”¯æŒ `--tenant` å‚æ•°

**ä»£ç éª¨æ¶**:
```rust
// cortex-mem-cli/src/commands/layers.rs (æ–°æ–‡ä»¶)
use clap::{Args, Subcommand};

#[derive(Args)]
pub struct LayersCommand {
    #[command(subcommand)]
    pub action: LayersAction,
}

#[derive(Subcommand)]
pub enum LayersAction {
    /// ç¡®ä¿æ‰€æœ‰ç›®å½•æ‹¥æœ‰ L0/L1 æ–‡ä»¶
    EnsureAll {
        #[arg(long)]
        tenant: Option<String>,
    },
    
    /// æŸ¥çœ‹å±‚çº§ç”ŸæˆçŠ¶æ€
    Status {
        #[arg(long)]
        tenant: Option<String>,
    },
}

pub async fn handle_layers_command(cmd: LayersCommand, config: &Config) -> Result<()> {
    match cmd.action {
        LayersAction::EnsureAll { tenant } => {
            println!("å¼€å§‹æ£€æŸ¥å¹¶ç”Ÿæˆç¼ºå¤±çš„ L0/L1 æ–‡ä»¶...");
            
            let layer_generator = LayerGenerator::new(/* ... */);
            let stats = layer_generator.ensure_all_layers().await?;
            
            println!("\nç”Ÿæˆå®Œæˆ:");
            println!("  æ€»è®¡: {}", stats.total);
            println!("  æˆåŠŸ: {}", stats.generated);
            println!("  å¤±è´¥: {}", stats.failed);
            
            Ok(())
        }
        
        LayersAction::Status { tenant } => {
            // TODO: æ˜¾ç¤ºå½“å‰çŠ¶æ€ï¼ˆå¤šå°‘ç›®å½•æœ‰/æ²¡æœ‰ L0/L1ï¼‰
            unimplemented!()
        }
    }
}
```

**Deliverables**:
- [ ] `layers.rs` å‘½ä»¤æ–‡ä»¶
- [ ] é›†æˆåˆ°ä¸» CLI
- [ ] ç”¨æˆ·æ–‡æ¡£æ›´æ–°

**éªŒæ”¶æ ‡å‡†**:
- `cortex-mem-cli layers ensure-all` èƒ½æ­£å¸¸è¿è¡Œ
- è¾“å‡ºæ¸…æ™°çš„è¿›åº¦å’Œç»Ÿè®¡ä¿¡æ¯
- æ”¯æŒå¤šç§Ÿæˆ·éš”ç¦»

---

#### Task 0.1.4: å¯åŠ¨æ—¶è‡ªåŠ¨æ£€æŸ¥

**ä»»åŠ¡æè¿°**:
1. åœ¨ `AutomationManager` å¯åŠ¨æ—¶è§¦å‘æ£€æŸ¥
2. æ”¯æŒé…ç½®å¼€å…³

**ä»£ç éª¨æ¶**:
```rust
// cortex-mem-core/src/automation/manager.rs
impl AutomationManager {
    pub async fn start(&self) -> Result<()> {
        // å¯åŠ¨ç°æœ‰è‡ªåŠ¨åŒ–...
        
        // æ£€æŸ¥å¹¶ç”Ÿæˆç¼ºå¤±çš„ L0/L1
        if self.config.layer_generation.auto_generate_on_startup {
            info!("å¯åŠ¨æ—¶è‡ªåŠ¨æ£€æŸ¥å¹¶ç”Ÿæˆç¼ºå¤±çš„ L0/L1...");
            tokio::spawn({
                let layer_generator = self.layer_generator.clone();
                async move {
                    if let Err(e) = layer_generator.ensure_all_layers().await {
                        error!("è‡ªåŠ¨ç”Ÿæˆ L0/L1 å¤±è´¥: {}", e);
                    }
                }
            });
        }
        
        Ok(())
    }
}
```

**Deliverables**:
- [ ] `AutomationManager` é›†æˆ
- [ ] é…ç½®é¡¹æ·»åŠ 
- [ ] æ—¥å¿—è¾“å‡º

**éªŒæ”¶æ ‡å‡†**:
- å¯åŠ¨æ—¶è‡ªåŠ¨æ£€æŸ¥ï¼ˆå¦‚æœé…ç½®å¯ç”¨ï¼‰
- ä¸é˜»å¡ä¸»å¯åŠ¨æµç¨‹ï¼ˆåå°å¼‚æ­¥ï¼‰
- å¤±è´¥ä¸å½±å“åº”ç”¨å¯åŠ¨

---

### Sprint 0.2: .abstract å¤§å°æ§åˆ¶ï¼ˆ0.5å‘¨ï¼‰

#### Task 0.2.1: æ›´æ–° Prompt æ¨¡æ¿

**ä»»åŠ¡æè¿°**:
1. å¼ºåŒ– Prompt çº¦æŸï¼Œæ˜ç¡®é•¿åº¦è¦æ±‚
2. æ·»åŠ åå¤„ç†æˆªæ–­é€»è¾‘

**ä»£ç éª¨æ¶**:
```rust
// cortex-mem-core/src/layers/generator.rs
pub struct AbstractConfig {
    pub max_tokens: usize,   // é»˜è®¤ 400
    pub max_chars: usize,    // é»˜è®¤ 2000
    pub target_sentences: usize, // é»˜è®¤ 2
}

impl LayerGenerator {
    async fn generate_abstract_v2(&self, content: &str, category: &str) -> Result<String> {
        let prompt = format!(
            r#"è¯·ä¸ºä»¥ä¸‹{category}å†…å®¹ç”Ÿæˆç®€æ´çš„æ‘˜è¦ã€‚

ã€ä¸¥æ ¼è¦æ±‚ã€‘
- æœ€å¤š {max_tokens} tokensï¼ˆçº¦ {max_chars} å­—ç¬¦ï¼‰
- {target_sentences} ä¸ªå®Œæ•´å¥å­
- æç‚¼æ ¸å¿ƒè¦ç‚¹ï¼Œåˆ é™¤ç»†èŠ‚æè¿°
- ä½¿ç”¨ç²¾ç‚¼è¯­è¨€ï¼Œé¿å…å†—ä½™

ã€å†…å®¹ã€‘
{content}

ã€è¾“å‡ºæ ¼å¼ã€‘
ä»…è¿”å›æ‘˜è¦æ–‡æœ¬ï¼Œä¸è¦åŒ…å«ä»»ä½•å‰ç¼€ã€åç¼€æˆ–è§£é‡Šã€‚"#,
            category = category,
            max_tokens = self.config.abstract_config.max_tokens,
            max_chars = self.config.abstract_config.max_chars,
            target_sentences = self.config.abstract_config.target_sentences,
            content = self.truncate_content(content, 4000),
        );
        
        let response = self.llm_client.generate(&prompt).await?;
        
        // å¼ºåˆ¶æ‰§è¡Œé•¿åº¦é™åˆ¶
        let abstract_text = self.enforce_limits(response)?;
        
        Ok(abstract_text)
    }
    
    fn enforce_limits(&self, text: String) -> Result<String> {
        let mut result = text.trim().to_string();
        let max_chars = self.config.abstract_config.max_chars;
        
        if result.len() <= max_chars {
            return Ok(result);
        }
        
        // æˆªæ–­åˆ°æœ€åä¸€ä¸ªå¥å·/é—®å·/å¹å·
        if let Some(pos) = result[..max_chars]
            .rfind(|c| c == 'ã€‚' || c == '.' || c == '?' || c == '!' || c == 'ï¼' || c == 'ï¼Ÿ')
        {
            result.truncate(pos + 'ã€‚'.len_utf8());
        } else {
            result.truncate(max_chars - 3);
            result.push_str("...");
        }
        
        Ok(result)
    }
    
    fn truncate_content(&self, content: &str, max_chars: usize) -> String {
        if content.len() <= max_chars {
            content.to_string()
        } else {
            format!("{}...", &content[..max_chars])
        }
    }
}
```

**Deliverables**:
- [ ] Prompt æ¨¡æ¿æ›´æ–°
- [ ] `enforce_limits()` å®ç°
- [ ] å•å…ƒæµ‹è¯•: `test_enforce_limits()`
- [ ] å•å…ƒæµ‹è¯•: `test_generate_abstract_v2()`

**éªŒæ”¶æ ‡å‡†**:
- 100% çš„æ–°ç”Ÿæˆ `.abstract` < 2K å­—ç¬¦
- Prompt æ¸…æ™°çº¦æŸé•¿åº¦
- åå¤„ç†æˆªæ–­æ­£ç¡®

---

#### Task 0.2.2: ç°æœ‰æ–‡ä»¶é‡æ–°ç”Ÿæˆ

**ä»»åŠ¡æè¿°**:
1. æ‰«ææ‰€æœ‰ç°æœ‰ `.abstract` æ–‡ä»¶
2. æ£€æµ‹è¶…å¤§æ–‡ä»¶ï¼ˆ> 2Kï¼‰
3. é‡æ–°ç”Ÿæˆ

**ä»£ç éª¨æ¶**:
```rust
impl LayerGenerator {
    /// é‡æ–°ç”Ÿæˆæ‰€æœ‰è¶…å¤§çš„ .abstract æ–‡ä»¶
    pub async fn regenerate_oversized_abstracts(&self) -> Result<RegenerationStats> {
        let directories = self.scan_all_directories().await?;
        let mut stats = RegenerationStats::default();
        
        for dir in directories {
            let abstract_path = format!("{}/.abstract", dir);
            
            if let Ok(content) = self.filesystem.read(&abstract_path).await {
                if content.len() > self.config.abstract_config.max_chars {
                    info!("é‡æ–°ç”Ÿæˆè¶…å¤§ .abstract: {} ({} å­—ç¬¦)", dir, content.len());
                    
                    match self.generate_layers_for_directory(&dir).await {
                        Ok(_) => stats.regenerated += 1,
                        Err(e) => {
                            stats.failed += 1;
                            warn!("é‡æ–°ç”Ÿæˆå¤±è´¥: {} - {}", dir, e);
                        }
                    }
                }
            }
        }
        
        Ok(stats)
    }
}
```

**Deliverables**:
- [ ] `regenerate_oversized_abstracts()` å®ç°
- [ ] CLI å‘½ä»¤: `layers regenerate-oversized`
- [ ] æ‰§è¡Œè„šæœ¬æ–‡æ¡£

**éªŒæ”¶æ ‡å‡†**:
- æ‰€æœ‰ç°æœ‰ `.abstract` æ–‡ä»¶ < 2K
- é‡æ–°ç”Ÿæˆä¸ç ´ååŸæœ‰å†…å®¹è´¨é‡

---

### Sprint 0.3: æ€§èƒ½ä¼˜åŒ–ï¼ˆ0.5å‘¨ï¼‰

#### Task 0.3.1: å¹¶å‘ L0/L1/L2 è¯»å–

**ä»»åŠ¡æè¿°**:
1. å®ç°å¹¶å‘è¯»å–æ¥å£
2. é›†æˆåˆ°æœç´¢æµç¨‹

**ä»£ç éª¨æ¶**:
```rust
// cortex-mem-core/src/layers/reader.rs
use futures::future::try_join_all;

pub struct LayerBundle {
    pub abstract_text: Option<String>,
    pub overview: Option<String>,
    pub content: Option<String>,
}

impl LayerReader {
    /// å¹¶å‘è¯»å–æ‰€æœ‰å±‚çº§
    pub async fn read_all_layers_concurrent(
        &self,
        uris: &[String],
    ) -> Result<HashMap<String, LayerBundle>> {
        let tasks: Vec<_> = uris.iter().map(|uri| {
            let uri = uri.clone();
            let filesystem = self.filesystem.clone();
            
            async move {
                let (l0, l1, l2) = tokio::join!(
                    filesystem.read(&format!("{}/.abstract", uri)),
                    filesystem.read(&format!("{}/.overview", uri)),
                    filesystem.read(&uri),
                );
                
                (uri, LayerBundle {
                    abstract_text: l0.ok(),
                    overview: l1.ok(),
                    content: l2.ok(),
                })
            }
        }).collect();
        
        let results = futures::future::join_all(tasks).await;
        Ok(results.into_iter().collect())
    }
}
```

**Deliverables**:
- [ ] `read_all_layers_concurrent()` å®ç°
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] é›†æˆåˆ° `VectorSearchEngine`

**éªŒæ”¶æ ‡å‡†**:
- æ€§èƒ½æå‡ 30%+ (100ms -> 70ms)
- å¹¶å‘å®‰å…¨
- æ—  deadlock

---

#### Task 0.3.2: Embedding ç¼“å­˜

**ä»»åŠ¡æè¿°**:
1. å®ç° LRU ç¼“å­˜å±‚
2. åŒ…è£…ç°æœ‰ `EmbeddingClient`

**ä»£ç éª¨æ¶**:
```rust
// cortex-mem-core/src/embedding/cached_client.rs
use lru::LruCache;
use std::sync::Arc;
use tokio::sync::Mutex;

pub struct CachedEmbeddingClient {
    inner: Arc<dyn EmbeddingClient>,
    cache: Arc<Mutex<LruCache<String, Vec<f32>>>>,
}

impl CachedEmbeddingClient {
    pub fn new(client: Arc<dyn EmbeddingClient>, capacity: usize) -> Self {
        Self {
            inner: client,
            cache: Arc::new(Mutex::new(LruCache::new(capacity))),
        }
    }
}

#[async_trait]
impl EmbeddingClient for CachedEmbeddingClient {
    async fn embed(&self, text: &str) -> Result<Vec<f32>> {
        // 1. æ£€æŸ¥ç¼“å­˜
        {
            let mut cache = self.cache.lock().await;
            if let Some(vector) = cache.get(text) {
                return Ok(vector.clone());
            }
        }
        
        // 2. ç”Ÿæˆ Embedding
        let vector = self.inner.embed(text).await?;
        
        // 3. å†™å…¥ç¼“å­˜
        {
            let mut cache = self.cache.lock().await;
            cache.put(text.to_string(), vector.clone());
        }
        
        Ok(vector)
    }
}
```

**Deliverables**:
- [ ] `CachedEmbeddingClient` å®ç°
- [ ] é…ç½®æ”¯æŒ
- [ ] å•å…ƒæµ‹è¯•
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•

**éªŒæ”¶æ ‡å‡†**:
- é‡å¤æŸ¥è¯¢ä» 50ms -> 0.1ms
- ç¼“å­˜å‘½ä¸­ç‡ç›‘æ§
- å†…å­˜å ç”¨å¯æ§

---

#### Task 0.3.3: æ‰¹é‡ Embedding

**ä»»åŠ¡æè¿°**:
1. æ‰©å±• `EmbeddingClient` trait æ”¯æŒæ‰¹é‡æ¥å£
2. å®ç° OpenAI API æ‰¹é‡è°ƒç”¨

**ä»£ç éª¨æ¶**:
```rust
// cortex-mem-core/src/embedding/client.rs
#[async_trait]
pub trait EmbeddingClient: Send + Sync {
    async fn embed(&self, text: &str) -> Result<Vec<f32>>;
    
    /// æ‰¹é‡ç”Ÿæˆ Embedding
    async fn embed_batch(&self, texts: &[String]) -> Result<Vec<Vec<f32>>> {
        // é»˜è®¤å®ç°ï¼šé€ä¸ªè°ƒç”¨
        let mut results = Vec::with_capacity(texts.len());
        for text in texts {
            results.push(self.embed(text).await?);
        }
        Ok(results)
    }
}

// cortex-mem-core/src/embedding/openai_client.rs
impl EmbeddingClient for OpenAIEmbeddingClient {
    async fn embed_batch(&self, texts: &[String]) -> Result<Vec<Vec<f32>>> {
        if texts.is_empty() {
            return Ok(vec![]);
        }
        
        let response = self.client
            .post(&format!("{}/embeddings", self.config.api_base))
            .header("Authorization", format!("Bearer {}", self.config.api_key))
            .json(&serde_json::json!({
                "model": self.config.model_name,
                "input": texts,
            }))
            .send()
            .await?;
        
        let data: EmbeddingResponse = response.json().await?;
        Ok(data.data.into_iter().map(|d| d.embedding).collect())
    }
}
```

**Deliverables**:
- [ ] `embed_batch()` trait æ–¹æ³•
- [ ] OpenAI æ‰¹é‡å®ç°
- [ ] é›†æˆåˆ°æœç´¢æµç¨‹
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•

**éªŒæ”¶æ ‡å‡†**:
- 10 ä¸ªæŸ¥è¯¢ä» 500ms -> 100ms
- æ”¯æŒæœ€å¤š 2048 ä¸ªæ‰¹é‡
- é”™è¯¯å¤„ç†å®Œå–„

---

## é˜¶æ®µ 1: æ£€ç´¢å¼•æ“å‡çº§ï¼ˆ6å‘¨ï¼‰

### Sprint 1.1: ç›®å½•é€’å½’æ£€ç´¢æ ¸å¿ƒï¼ˆ2å‘¨ï¼‰

#### Task 1.1.1: å®šä¹‰æ ¸å¿ƒæ•°æ®ç»“æ„

**ä»£ç éª¨æ¶**:
```rust
// cortex-mem-core/src/search/hierarchical.rs (æ–°æ–‡ä»¶)
pub struct HierarchicalRetriever {
    vector_store: Arc<dyn VectorStore>,
    embedding_client: Arc<dyn EmbeddingClient>,
    filesystem: Arc<CortexFilesystem>,
    config: HierarchicalConfig,
}

pub struct HierarchicalConfig {
    pub enabled: bool,
    pub max_depth: usize,
    pub score_propagation_alpha: f32,
    pub convergence_rounds: usize,
    pub global_search_topk: usize,
}

pub struct TypedQuery {
    pub query: String,
    pub context_type: ContextType,
    pub target_scope: Option<String>,
    pub limit: usize,
}

pub enum ContextType {
    Memory,
    Resource,
    Agent,
    Session,
}

pub struct HierarchicalResult {
    pub results: Vec<SearchResult>,
    pub trace: Option<SearchTrace>,
}

pub struct SearchTrace {
    pub steps: Vec<String>,
    pub duration_ms: u64,
}
```

**Deliverables**:
- [ ] æ•°æ®ç»“æ„å®šä¹‰
- [ ] é…ç½®é»˜è®¤å€¼
- [ ] æ–‡æ¡£æ³¨é‡Š

---

#### Task 1.1.2: å®ç°å…¨å±€æœç´¢

**ä»£ç éª¨æ¶**:
```rust
impl HierarchicalRetriever {
    /// å…¨å±€å‘é‡æœç´¢ï¼Œå®šä½é«˜åˆ†ç›®å½•
    async fn global_search(
        &self,
        query: &TypedQuery,
        topk: usize,
    ) -> Result<Vec<DirectoryScore>> {
        // 1. ç”ŸæˆæŸ¥è¯¢å‘é‡
        let query_vector = self.embedding_client.embed(&query.query).await?;
        
        // 2. å‘é‡æ£€ç´¢ï¼ˆä»…æ£€ç´¢ç›®å½•ï¼Œis_leaf=falseï¼‰
        let search_opts = SearchOptions {
            limit: topk * 3, // æ£€ç´¢æ›´å¤šå€™é€‰
            filters: vec![
                ("is_leaf", "false"), // ä»…ç›®å½•
                ("context_type", &query.context_type.to_string()),
            ],
            score_threshold: Some(0.5),
        };
        
        let results = self.vector_store.search(&query_vector, &search_opts).await?;
        
        // 3. æå–ç›®å½•åˆ†æ•°
        let dir_scores: Vec<_> = results.into_iter()
            .map(|r| DirectoryScore {
                uri: r.uri.clone(),
                score: r.score,
                depth: self.calculate_depth(&r.uri),
            })
            .collect();
        
        // 4. æŒ‰åˆ†æ•°æ’åºï¼Œå– topk
        let mut sorted = dir_scores;
        sorted.sort_by(|a, b| b.score.partial_cmp(&a.score).unwrap());
        sorted.truncate(topk);
        
        Ok(sorted)
    }
    
    fn calculate_depth(&self, uri: &str) -> usize {
        uri.split('/').filter(|s| !s.is_empty()).count() - 1
    }
}
```

**Deliverables**:
- [ ] `global_search()` å®ç°
- [ ] å•å…ƒæµ‹è¯•
- [ ] é›†æˆæµ‹è¯•

---

#### Task 1.1.3: å®ç°é€’å½’æœç´¢

**ä»£ç éª¨æ¶**:
```rust
impl HierarchicalRetriever {
    /// é€’å½’æœç´¢å­ç›®å½•
    async fn recursive_search(
        &self,
        start_dir: &DirectoryScore,
        query: &TypedQuery,
        max_depth: usize,
    ) -> Result<Vec<Candidate>> {
        let mut candidates = vec![];
        let mut to_explore = vec![(start_dir.uri.clone(), start_dir.score, 0)];
        
        while let Some((current_uri, parent_score, depth)) = to_explore.pop() {
            if depth >= max_depth {
                continue;
            }
            
            // 1. åˆ—å‡ºå­ç›®å½•
            let children = self.list_children(&current_uri).await?;
            
            // 2. å‘é‡æ£€ç´¢å­èŠ‚ç‚¹
            let child_results = self.search_children(&current_uri, query).await?;
            
            // 3. åº”ç”¨åˆ†æ•°ä¼ æ’­
            for result in child_results {
                let propagated_score = self.config.score_propagation_alpha * result.score
                    + (1.0 - self.config.score_propagation_alpha) * parent_score;
                
                if result.is_leaf {
                    // å¶å­èŠ‚ç‚¹ï¼ŒåŠ å…¥å€™é€‰
                    candidates.push(Candidate {
                        uri: result.uri.clone(),
                        score: result.score,
                        final_score: propagated_score,
                        parent_uri: current_uri.clone(),
                        depth: depth + 1,
                    });
                } else {
                    // ç›®å½•èŠ‚ç‚¹ï¼Œç»§ç»­é€’å½’
                    to_explore.push((result.uri.clone(), propagated_score, depth + 1));
                }
            }
        }
        
        Ok(candidates)
    }
    
    async fn list_children(&self, uri: &str) -> Result<Vec<String>> {
        self.filesystem.list(uri).await
    }
    
    async fn search_children(&self, parent_uri: &str, query: &TypedQuery) -> Result<Vec<SearchResult>> {
        // TODO: åœ¨æŒ‡å®šçˆ¶ç›®å½•ä¸‹æœç´¢
        unimplemented!()
    }
}
```

**Deliverables**:
- [ ] `recursive_search()` å®ç°
- [ ] å•å…ƒæµ‹è¯•
- [ ] é›†æˆæµ‹è¯•
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•

---

#### Task 1.1.4: åˆ†æ•°ä¼ æ’­ä¸æ’åº

**ä»£ç éª¨æ¶**:
```rust
impl HierarchicalRetriever {
    /// åº”ç”¨åˆ†æ•°ä¼ æ’­å¹¶æ’åº
    fn apply_score_propagation_and_sort(
        &self,
        mut candidates: Vec<Candidate>,
        limit: usize,
    ) -> Vec<SearchResult> {
        // åˆ†æ•°ä¼ æ’­å·²åœ¨é€’å½’æœç´¢ä¸­å®Œæˆ
        
        // æŒ‰ final_score æ’åº
        candidates.sort_by(|a, b| {
            b.final_score.partial_cmp(&a.final_score).unwrap()
        });
        
        // æˆªæ–­åˆ° limit
        candidates.truncate(limit);
        
        // è½¬æ¢ä¸º SearchResult
        candidates.into_iter().map(|c| SearchResult {
            uri: c.uri,
            score: c.final_score,
            // ... å…¶ä»–å­—æ®µ
        }).collect()
    }
}
```

**Deliverables**:
- [ ] æ’åºé€»è¾‘
- [ ] å•å…ƒæµ‹è¯•

---

### Sprint 1.2: æ„å›¾åˆ†æé›†æˆï¼ˆ2å‘¨ï¼‰

#### Task 1.2.1: å®ç°è½»é‡çº§æ„å›¾åˆ†æå™¨

**ä»£ç éª¨æ¶**:
```rust
// cortex-mem-core/src/search/intent_analyzer.rs (æ–°æ–‡ä»¶)
pub struct LightweightIntentAnalyzer {
    llm_client: Arc<dyn LLMClient>,
    config: IntentAnalyzerConfig,
}

pub struct IntentAnalyzerConfig {
    pub enabled: bool,
    pub max_queries: usize,
    pub use_recent_context: bool,
    pub context_window_messages: usize,
}

impl LightweightIntentAnalyzer {
    pub async fn analyze(
        &self,
        query: &str,
        recent_context: Option<&str>,
    ) -> Result<Vec<TypedQuery>> {
        if !self.config.enabled {
            // ç¦ç”¨æ—¶ï¼Œè¿”å›å•ä¸€æŸ¥è¯¢
            return Ok(vec![TypedQuery {
                query: query.to_string(),
                context_type: ContextType::Resource,
                target_scope: None,
                limit: 10,
            }]);
        }
        
        let prompt = format!(
            r#"åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œåˆ¤æ–­éœ€è¦æœç´¢çš„å†…å®¹ç±»å‹ã€‚

ã€æŸ¥è¯¢ã€‘
{}

ã€æœ€è¿‘ä¸Šä¸‹æ–‡ã€‘
{}

ã€è¦æ±‚ã€‘
è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
- query: ä¼˜åŒ–åçš„æŸ¥è¯¢æ–‡æœ¬
- context_type: "memory" | "resource" | "agent" | "session"
- target_scope: å¯é€‰çš„ç›®æ ‡èŒƒå›´ï¼ˆå¦‚ "user/preferences"ï¼‰

æœ€å¤šè¿”å› {} ä¸ªæŸ¥è¯¢ã€‚"#,
            query,
            recent_context.unwrap_or("æ— "),
            self.config.max_queries
        );
        
        let response = self.llm_client.generate(&prompt).await?;
        
        // è§£æ JSON
        let queries: Vec<TypedQuery> = serde_json::from_str(&response)
            .map_err(|e| Error::ParseError(format!("Failed to parse intent analysis response: {}", e)))?;
        
        // é™åˆ¶æ•°é‡
        Ok(queries.into_iter().take(self.config.max_queries).collect())
    }
}
```

**Deliverables**:
- [ ] `LightweightIntentAnalyzer` å®ç°
- [ ] Prompt æ¨¡æ¿
- [ ] å•å…ƒæµ‹è¯•
- [ ] é›†æˆæµ‹è¯•

---

#### Task 1.2.2: é›†æˆåˆ°æœç´¢æµç¨‹

**ä»£ç éª¨æ¶**:
```rust
// cortex-mem-core/src/search/engine.rs
impl VectorSearchEngine {
    pub async fn search_with_intent(
        &self,
        query: &str,
        recent_context: Option<&str>,
        options: &SearchOptions,
    ) -> Result<Vec<SearchResult>> {
        // 1. æ„å›¾åˆ†æ
        let typed_queries = self.intent_analyzer.analyze(query, recent_context).await?;
        
        // 2. å¹¶å‘æ£€ç´¢
        let search_tasks: Vec<_> = typed_queries.iter().map(|tq| {
            self.hierarchical_retriever.retrieve(tq)
        }).collect();
        
        let results = futures::future::try_join_all(search_tasks).await?;
        
        // 3. åˆå¹¶ç»“æœï¼ˆå»é‡ã€æ’åºï¼‰
        let merged = self.merge_results(results);
        
        Ok(merged)
    }
    
    fn merge_results(&self, results: Vec<HierarchicalResult>) -> Vec<SearchResult> {
        let mut all_results = vec![];
        for r in results {
            all_results.extend(r.results);
        }
        
        // å»é‡ï¼ˆæŒ‰ URIï¼‰
        let mut seen = HashSet::new();
        let unique: Vec<_> = all_results.into_iter()
            .filter(|r| seen.insert(r.uri.clone()))
            .collect();
        
        // æŒ‰åˆ†æ•°æ’åº
        let mut sorted = unique;
        sorted.sort_by(|a, b| b.score.partial_cmp(&a.score).unwrap());
        
        sorted
    }
}
```

**Deliverables**:
- [ ] `search_with_intent()` å®ç°
- [ ] `merge_results()` å®ç°
- [ ] é›†æˆæµ‹è¯•
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•

---

### Sprint 1.3: æµ‹è¯•ä¸ä¼˜åŒ–ï¼ˆ2å‘¨ï¼‰

#### Task 1.3.1: LOMOCO åŸºå‡†æµ‹è¯•

**ä»»åŠ¡æè¿°**:
1. è¿è¡Œ LOMOCO è¯„ä¼°æ¡†æ¶
2. å¯¹æ¯” 2.x å’Œ 3.0 æ€§èƒ½
3. è°ƒä¼˜å‚æ•°

**Deliverables**:
- [ ] åŸºå‡†æµ‹è¯•è„šæœ¬
- [ ] æ€§èƒ½æŠ¥å‘Šæ–‡æ¡£
- [ ] å‚æ•°è°ƒä¼˜è®°å½•

**éªŒæ”¶æ ‡å‡†**:
- Recall@1 > 95%
- MRR > 95%
- NDCG@5 > 85%

---

#### Task 1.3.2: æ€§èƒ½ä¼˜åŒ–

**ä»»åŠ¡æè¿°**:
1. åˆ†ææ€§èƒ½ç“¶é¢ˆ
2. ä¼˜åŒ–çƒ­ç‚¹ä»£ç 
3. ç¼“å­˜ä¼˜åŒ–

**Deliverables**:
- [ ] æ€§èƒ½åˆ†ææŠ¥å‘Š
- [ ] ä¼˜åŒ–ä»£ç 
- [ ] åŸºå‡†å¯¹æ¯”

**éªŒæ”¶æ ‡å‡†**:
- æŸ¥è¯¢å»¶è¿Ÿ < 100ms (P95)
- ååé‡ > 100 QPS

---

## é˜¶æ®µ 2: è®°å¿†ç®¡ç†å¢å¼ºï¼ˆ4å‘¨ï¼‰

### Sprint 2.1: è®°å¿†åˆ†ç±»æ‰©å±•ï¼ˆ2å‘¨ï¼‰

#### Task 2.1.1: æ‰©å±• MemoryCategory æšä¸¾

**ä»£ç éª¨æ¶**:
```rust
// cortex-mem-core/src/session/extraction.rs
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum MemoryCategory {
    // ç”¨æˆ·è®°å¿†
    Profile,      // ğŸ†• ç”¨æˆ·ç”»åƒ
    Preference,   // ç”¨æˆ·åå¥½
    Entity,       // å®ä½“è®°å¿†
    Event,        // äº‹ä»¶è®°å½•
    
    // Agent è®°å¿†
    Case,         // æ¡ˆä¾‹åº“
    Pattern,      // ğŸ†• æ¨¡å¼åº“
}

impl MemoryCategory {
    pub fn to_path(&self) -> &str {
        match self {
            Self::Profile => "user/profile.md",
            Self::Preference => "user/preferences",
            Self::Entity => "user/entities",
            Self::Event => "user/events",
            Self::Case => "agent/cases",
            Self::Pattern => "agent/patterns",
        }
    }
    
    pub fn should_merge(&self) -> bool {
        matches!(self, Self::Profile | Self::Preference)
    }
}
```

**Deliverables**:
- [ ] æšä¸¾æ‰©å±•
- [ ] è·¯å¾„æ˜ å°„æ›´æ–°
- [ ] æ–‡æ¡£æ›´æ–°

---

#### Task 2.1.2: å®ç° Profile æå–

**ä»£ç éª¨æ¶**:
```rust
impl MemoryExtractor {
    async fn extract_profile(
        &self,
        messages: &[Message],
    ) -> Result<Option<CandidateMemory>> {
        let prompt = format!(
            r#"ä»å¯¹è¯ä¸­æå–ç”¨æˆ·ç”»åƒä¿¡æ¯ã€‚

ã€å¯¹è¯ã€‘
{}

ã€è¦æ±‚ã€‘
æå–ï¼š
- åŸºæœ¬ä¿¡æ¯ï¼ˆèŒä¸šã€æŠ€æœ¯æ ˆã€å…´è¶£ï¼‰
- å·¥ä½œä¹ æƒ¯
- åå¥½ç‰¹ç‚¹

è¿”å› Markdown æ ¼å¼çš„ç”¨æˆ·ç”»åƒï¼Œå¦‚æœæ²¡æœ‰ä¿¡æ¯åˆ™è¿”å› nullã€‚"#,
            self.format_messages(messages)
        );
        
        let response = self.llm_client.generate(&prompt).await?;
        
        if response.trim() == "null" {
            return Ok(None);
        }
        
        Ok(Some(CandidateMemory {
            category: MemoryCategory::Profile,
            abstract_text: self.extract_first_line(&response),
            overview: self.extract_summary(&response, 500),
            content: response,
        }))
    }
    
    /// åˆå¹¶åˆ°ç°æœ‰ Profile
    async fn merge_profile(
        &self,
        existing: &str,
        new: &str,
    ) -> Result<String> {
        let prompt = format!(
            r#"åˆå¹¶ä¸¤ä¸ªç”¨æˆ·ç”»åƒï¼Œä¿ç•™å®Œæ•´ä¿¡æ¯ï¼Œå»é™¤é‡å¤ã€‚

ã€ç°æœ‰ç”»åƒã€‘
{}

ã€æ–°å¢ä¿¡æ¯ã€‘
{}

è¿”å›åˆå¹¶åçš„ Markdown æ ¼å¼ç”»åƒã€‚"#,
            existing, new
        );
        
        self.llm_client.generate(&prompt).await
    }
}
```

**Deliverables**:
- [ ] `extract_profile()` å®ç°
- [ ] `merge_profile()` å®ç°
- [ ] Prompt æ¨¡æ¿
- [ ] å•å…ƒæµ‹è¯•

---

#### Task 2.1.3: å®ç° Pattern æå–

**ä»£ç éª¨æ¶**:
```rust
impl MemoryExtractor {
    async fn extract_patterns(
        &self,
        messages: &[Message],
    ) -> Result<Vec<CandidateMemory>> {
        let prompt = format!(
            r#"ä»å¯¹è¯ä¸­æç‚¼å¯å¤ç”¨çš„æ¨¡å¼ã€æµç¨‹å’Œæœ€ä½³å®è·µã€‚

ã€å¯¹è¯ã€‘
{}

ã€è¦æ±‚ã€‘
æç‚¼ï¼š
- é€šç”¨çš„è§£å†³æµç¨‹
- å¯å¤ç”¨çš„æ–¹æ³•è®º
- æœ€ä½³å®è·µ

è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªæ¨¡å¼åŒ…å«ï¼š
- name: æ¨¡å¼åç§°
- applicability: é€‚ç”¨åœºæ™¯
- steps: æ­¥éª¤åˆ—è¡¨
- examples: ç¤ºä¾‹

å¦‚æœæ²¡æœ‰æ¨¡å¼åˆ™è¿”å›ç©ºæ•°ç»„ã€‚"#,
            self.format_messages(messages)
        );
        
        let response = self.llm_client.generate(&prompt).await?;
        let patterns: Vec<PatternData> = serde_json::from_str(&response)?;
        
        Ok(patterns.into_iter().map(|p| self.pattern_to_candidate(p)).collect())
    }
    
    fn pattern_to_candidate(&self, pattern: PatternData) -> CandidateMemory {
        let content = format!(
            "# æ¨¡å¼: {}\n\n## é€‚ç”¨åœºæ™¯\n{}\n\n## æ­¥éª¤\n{}\n\n## ç¤ºä¾‹\n{}",
            pattern.name,
            pattern.applicability,
            pattern.steps.join("\n"),
            pattern.examples.join("\n\n")
        );
        
        CandidateMemory {
            category: MemoryCategory::Pattern,
            abstract_text: pattern.name.clone(),
            overview: pattern.applicability.clone(),
            content,
        }
    }
}
```

**Deliverables**:
- [ ] `extract_patterns()` å®ç°
- [ ] Prompt æ¨¡æ¿
- [ ] å•å…ƒæµ‹è¯•

---

### Sprint 2.2: è®°å¿†å»é‡ä¼˜åŒ–ï¼ˆ2å‘¨ï¼‰

#### Task 2.2.1: å®ç°å»é‡æ£€æµ‹å™¨

**ä»£ç éª¨æ¶**:
```rust
// cortex-mem-core/src/session/deduplicator.rs (æ–°æ–‡ä»¶)
pub struct MemoryDeduplicator {
    vector_store: Arc<dyn VectorStore>,
    embedding_client: Arc<dyn EmbeddingClient>,
    llm_client: Arc<dyn LLMClient>,
    config: DeduplicatorConfig,
}

pub struct DeduplicatorConfig {
    pub similarity_threshold: f32, // é»˜è®¤ 0.85
    pub enable_llm_check: bool,    // é»˜è®¤ true
}

pub enum DeduplicationResult {
    NoDuplicate,
    Duplicate { existing_uri: String },
}

impl MemoryDeduplicator {
    pub async fn check_duplicate(
        &self,
        candidate: &CandidateMemory,
    ) -> Result<DeduplicationResult> {
        // 1. å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢
        let vector = self.embedding_client.embed(&candidate.abstract_text).await?;
        
        let similar = self.vector_store.search(&vector, &SearchOptions {
            limit: 5,
            filters: vec![
                ("category", &candidate.category.to_string()),
            ],
            score_threshold: Some(self.config.similarity_threshold),
        }).await?;
        
        if similar.is_empty() {
            return Ok(DeduplicationResult::NoDuplicate);
        }
        
        // 2. LLM ç²¾ç¡®åˆ¤æ–­
        if self.config.enable_llm_check {
            for existing in similar {
                let is_dup = self.is_duplicate_by_llm(candidate, &existing).await?;
                if is_dup {
                    return Ok(DeduplicationResult::Duplicate {
                        existing_uri: existing.uri,
                    });
                }
            }
        }
        
        Ok(DeduplicationResult::NoDuplicate)
    }
    
    async fn is_duplicate_by_llm(
        &self,
        candidate: &CandidateMemory,
        existing: &SearchResult,
    ) -> Result<bool> {
        // è¯»å–ç°æœ‰è®°å¿†å†…å®¹
        let existing_content = self.filesystem.read(&existing.uri).await?;
        
        let prompt = format!(
            r#"åˆ¤æ–­ä¸¤ä¸ªè®°å¿†æ˜¯å¦é‡å¤ï¼ˆå†…å®¹å®è´¨ç›¸åŒï¼‰ã€‚

ã€ç°æœ‰è®°å¿†ã€‘
{}

ã€æ–°è®°å¿†ã€‘
{}

è¿”å› JSON: {{"is_duplicate": true/false, "reason": "åŸå› "}}"#,
            existing_content,
            candidate.content
        );
        
        let response = self.llm_client.generate(&prompt).await?;
        let result: DuplicateCheckResult = serde_json::from_str(&response)?;
        
        Ok(result.is_duplicate)
    }
}
```

**Deliverables**:
- [ ] `MemoryDeduplicator` å®ç°
- [ ] å•å…ƒæµ‹è¯•
- [ ] é›†æˆæµ‹è¯•

---

#### Task 2.2.2: å®ç°è®°å¿†åˆå¹¶

**ä»£ç éª¨æ¶**:
```rust
impl MemoryDeduplicator {
    pub async fn merge_memory(
        &self,
        existing_uri: &str,
        new_content: &str,
        category: &MemoryCategory,
    ) -> Result<MergedMemory> {
        let existing_content = self.filesystem.read(existing_uri).await?;
        
        let prompt = format!(
            r#"åˆå¹¶ä¸¤ä¸ªè®°å¿†ï¼Œä¿ç•™å®Œæ•´ä¿¡æ¯ï¼Œå»é™¤é‡å¤ã€‚

ã€ç°æœ‰è®°å¿†ã€‘
{}

ã€æ–°å¢è®°å¿†ã€‘
{}

è¿”å› JSON:
{{
  "abstract": "ä¸€å¥è¯æ‘˜è¦ï¼ˆ< 200 å­—ç¬¦ï¼‰",
  "overview": "æ¦‚è§ˆï¼ˆ< 2000 å­—ç¬¦ï¼‰",
  "content": "å®Œæ•´å†…å®¹ï¼ˆMarkdown æ ¼å¼ï¼‰"
}}"#,
            existing_content, new_content
        );
        
        let response = self.llm_client.generate(&prompt).await?;
        let merged: MergedMemory = serde_json::from_str(&response)?;
        
        // æ›´æ–°æ–‡ä»¶
        self.filesystem.write(existing_uri, &merged.content).await?;
        self.filesystem.write(&format!("{}/.abstract", self.get_parent(existing_uri)), &merged.abstract_text).await?;
        self.filesystem.write(&format!("{}/.overview", self.get_parent(existing_uri)), &merged.overview).await?;
        
        Ok(merged)
    }
}
```

**Deliverables**:
- [ ] `merge_memory()` å®ç°
- [ ] å•å…ƒæµ‹è¯•
- [ ] é›†æˆæµ‹è¯•

---

#### Task 2.2.3: é›†æˆåˆ°æå–æµç¨‹

**ä»£ç éª¨æ¶**:
```rust
impl MemoryExtractor {
    pub async fn extract_and_deduplicate(
        &self,
        messages: &[Message],
        session_id: &str,
    ) -> Result<ExtractionResult> {
        // 1. æå–å€™é€‰è®°å¿†
        let candidates = self.extract(messages).await?;
        
        let mut created = vec![];
        let mut merged = vec![];
        let mut skipped = vec![];
        
        // 2. å»é‡æ£€æŸ¥
        for candidate in candidates {
            match self.deduplicator.check_duplicate(&candidate).await? {
                DeduplicationResult::NoDuplicate => {
                    // åˆ›å»ºæ–°è®°å¿†
                    let uri = self.create_memory(&candidate, session_id).await?;
                    created.push(uri);
                }
                
                DeduplicationResult::Duplicate { existing_uri } => {
                    if candidate.category.should_merge() {
                        // åˆå¹¶è®°å¿†
                        self.deduplicator.merge_memory(
                            &existing_uri,
                            &candidate.content,
                            &candidate.category,
                        ).await?;
                        merged.push(existing_uri);
                    } else {
                        // ç‹¬ç«‹ä¿å­˜ï¼ˆEvent/Case/Patternï¼‰
                        let uri = self.create_memory(&candidate, session_id).await?;
                        created.push(uri);
                    }
                }
            }
        }
        
        Ok(ExtractionResult {
            created,
            merged,
            skipped,
        })
    }
}
```

**Deliverables**:
- [ ] `extract_and_deduplicate()` å®ç°
- [ ] é›†æˆæµ‹è¯•
- [ ] æ–‡æ¡£æ›´æ–°

---

## é˜¶æ®µ 3: å¯è§‚æµ‹æ€§å¢å¼ºï¼ˆå¯é€‰ï¼Œ2å‘¨ï¼‰

### Task 3.1: è½»é‡çº§æ£€ç´¢è½¨è¿¹

**ä»£ç éª¨æ¶**:
```rust
// cortex-mem-core/src/search/trace.rs (æ–°æ–‡ä»¶)
pub struct SearchTrace {
    pub query: String,
    pub steps: Vec<String>,
    pub final_count: usize,
    pub duration_ms: u64,
}

impl SearchTrace {
    pub fn new(query: &str) -> Self {
        Self {
            query: query.to_string(),
            steps: vec![],
            final_count: 0,
            duration_ms: 0,
        }
    }
    
    pub fn add_step(&mut self, description: String) {
        self.steps.push(description);
    }
    
    pub fn to_json(&self) -> String {
        serde_json::to_string_pretty(self).unwrap()
    }
}

impl HierarchicalRetriever {
    pub async fn retrieve_with_trace(
        &self,
        query: &TypedQuery,
    ) -> Result<(HierarchicalResult, SearchTrace)> {
        let mut trace = SearchTrace::new(&query.query);
        let start = Instant::now();
        
        trace.add_step(format!("å…¨å±€æœç´¢: å®šä½é«˜åˆ†ç›®å½•"));
        let top_dirs = self.global_search(query, self.config.global_search_topk).await?;
        trace.add_step(format!("æ‰¾åˆ° {} ä¸ªé«˜åˆ†ç›®å½•", top_dirs.len()));
        
        trace.add_step(format!("é€’å½’æœç´¢: æ¢ç´¢å­ç›®å½•ï¼ˆæœ€å¤§æ·±åº¦ {}ï¼‰", self.config.max_depth));
        let candidates = self.recursive_search_all(&top_dirs, query).await?;
        trace.add_step(format!("æ”¶é›†åˆ° {} ä¸ªå€™é€‰", candidates.len()));
        
        trace.add_step(format!("åˆ†æ•°ä¼ æ’­ä¸æ’åº"));
        let results = self.apply_score_propagation_and_sort(candidates, query.limit);
        trace.add_step(format!("æœ€ç»ˆè¿”å› {} ä¸ªç»“æœ", results.len()));
        
        trace.final_count = results.len();
        trace.duration_ms = start.elapsed().as_millis() as u64;
        
        Ok((HierarchicalResult { results, trace: None }, trace))
    }
}
```

**Deliverables**:
- [ ] `SearchTrace` å®ç°
- [ ] `retrieve_with_trace()` å®ç°
- [ ] å¯é€‰å¼€å…³é…ç½®
- [ ] JSON å¯¼å‡º

**éªŒæ”¶æ ‡å‡†**:
- æ€§èƒ½å½±å“ < 5ms
- å¯é€‰å¼€å…³ç”Ÿæ•ˆ
- JSON æ ¼å¼æ­£ç¡®

---

## æ€»ç»“

### å…³é”®é‡Œç¨‹ç¢‘

| é‡Œç¨‹ç¢‘ | æ—¶é—´ç‚¹ | éªŒæ”¶æ ‡å‡† |
|--------|--------|----------|
| M0 | ç¬¬ 2 å‘¨ | ä¸‰å±‚æ–‡ä»¶ 100%<br/>.abstract < 2K<br/>æŸ¥è¯¢ < 80ms |
| M1 | ç¬¬ 8 å‘¨ | Recall@1 > 95%<br/>é€’å½’æ£€ç´¢ç”Ÿæ•ˆ |
| M2 | ç¬¬ 12 å‘¨ | å…­åˆ†ç±»æ”¯æŒ<br/>å»é‡å‡†ç¡®ç‡ > 90% |
| M3 | ç¬¬ 14 å‘¨ | 3.0 æ­£å¼å‘å¸ƒ |

### é£é™©ç®¡ç†

1. **æŠ€æœ¯é£é™©**: å……åˆ†æµ‹è¯•ï¼Œç°åº¦å‘å¸ƒ
2. **æ€§èƒ½é£é™©**: æŒç»­åŸºå‡†æµ‹è¯•ï¼Œæ€§èƒ½ç›‘æ§
3. **å…¼å®¹æ€§é£é™©**: æ•°æ®è¿ç§»è„šæœ¬ï¼Œæ–‡æ¡£æŒ‡å—

**å‡†å¤‡å°±ç»ªï¼Œå¼€å§‹å®æ–½ï¼ğŸš€**
