# Cortex-Memory 3.0 æ¼”è¿›è§„åˆ’

> åŸºäº OpenViking æ·±åº¦è°ƒç ”çš„æŠ€æœ¯æ¼”è¿›è·¯çº¿å›¾ï¼ˆè½»é‡åŒ–ã€é«˜æ€§èƒ½ç‰ˆæœ¬ï¼‰

---

## ä¸€ã€æ¼”è¿›æ„¿æ™¯

### 1.1 ç›®æ ‡å®šä½

**Cortex-Memory 3.0** å°†ä»"é«˜æ€§èƒ½å†…å­˜æ¡†æ¶"æ¼”è¿›ä¸º **"è½»é‡çº§ã€é«˜æ€§èƒ½ã€æ™ºèƒ½åŒ–çš„AIä¸Šä¸‹æ–‡æ•°æ®åº“"**ï¼Œèåˆ Rust åŸç”Ÿæ€§èƒ½ä¼˜åŠ¿ä¸ OpenViking çš„å…ˆè¿›æ¶æ„ç†å¿µï¼ŒåŒæ—¶ä¿æŒç®€æ´ã€æ˜“ç”¨ã€é«˜æ•ˆçš„æ ¸å¿ƒä¼˜åŠ¿ã€‚

### 1.2 æ ¸å¿ƒä»·å€¼ä¸»å¼ 

- **è½»é‡è‡³ä¸Š**: é›¶é¢å¤–ä¾èµ–ï¼Œç®€å•éƒ¨ç½²ï¼Œå¼€ç®±å³ç”¨
- **æ€§èƒ½å“è¶Š**: ä¿æŒ Rust åŸç”Ÿæ€§èƒ½ä¼˜åŠ¿ï¼ˆ93.33% Recall@1ï¼‰ï¼Œä¼˜åŒ–æŸ¥è¯¢å»¶è¿Ÿ
- **Tokené«˜æ•ˆ**: æ™ºèƒ½åˆ†å±‚åŠ è½½ï¼Œç²¾å‡†æ§åˆ¶ä¸Šä¸‹æ–‡å¤§å°ï¼ˆ.abstract < 2Kï¼‰
- **æ¶æ„å…ˆè¿›**: å€Ÿé‰´ OpenViking ç›®å½•é€’å½’æ£€ç´¢ã€æ™ºèƒ½å»é‡
- **ç”Ÿæ€å®Œæ•´**: å¼ºåŒ– REST API + MCP + Web ä»ªè¡¨æ¿

### 1.3 éç›®æ ‡ï¼ˆæ˜ç¡®ä¸åšï¼‰

- âŒ åˆ†å¸ƒå¼å­˜å‚¨ï¼ˆä¿æŒå•æœºéƒ¨ç½²ç®€æ´æ€§ï¼‰
- âŒ å†å²æ“ä½œè®°å½•å›æº¯ï¼ˆé¿å…å¤æ‚æ€§ï¼‰
- âŒ ä¼ä¸šçº§å®¡è®¡æ—¥å¿—ï¼ˆèšç„¦æ ¸å¿ƒåŠŸèƒ½ï¼‰
- âŒ å¤šå‰¯æœ¬é«˜å¯ç”¨ï¼ˆä¿æŒè½»é‡ï¼‰

---

## äºŒã€å½“å‰é—ç•™é—®é¢˜ä¿®å¤ï¼ˆä¼˜å…ˆçº§ï¼šğŸ”¥ğŸ”¥ğŸ”¥ï¼‰

> åœ¨å®æ–½æ–°åŠŸèƒ½å‰ï¼Œå¿…é¡»å…ˆè§£å†³ 2.0 ç‰ˆæœ¬çš„ç°å­˜é—®é¢˜

### 2.1 ä¸‰å±‚é€’è¿›æ–‡ä»¶ç¼ºå¤±é—®é¢˜

**é—®é¢˜æè¿°**: å½“å‰å®ç°ä¸­ï¼Œå¹¶éæ¯ä¸ªç›®å½•éƒ½ç”Ÿæˆäº† `.abstract` å’Œ `.overview` æ–‡ä»¶ï¼Œå¯¼è‡´åˆ†å±‚æ£€ç´¢ä¸å®Œæ•´ã€‚

**æ ¹æœ¬åŸå› åˆ†æ**:
```rust
// å½“å‰å®ç°ï¼šæ‡’ç”Ÿæˆç­–ç•¥
// ä»…åœ¨é¦–æ¬¡è®¿é—®æ—¶ç”Ÿæˆï¼Œä½†å¾ˆå¤šç›®å½•ä»æœªè¢«è®¿é—®è¿‡
pub async fn get_abstract(&self, uri: &str) -> Result<String> {
    if let Some(cached) = self.cache.get(uri) {
        return Ok(cached);
    }
    // é—®é¢˜ï¼šå¦‚æœä»æœªè¢«è°ƒç”¨ï¼ŒL0/L1 æ°¸è¿œä¸ä¼šç”Ÿæˆ
    let abstract_text = self.generate_abstract(uri).await?;
    Ok(abstract_text)
}
```

**è§£å†³æ–¹æ¡ˆ**:

#### æ–¹æ¡ˆ1: æ¸è¿›å¼ä¸»åŠ¨ç”Ÿæˆï¼ˆæ¨èï¼‰

```rust
pub struct LayerGenerationStrategy {
    // æ–°å¢ï¼šæ¸è¿›å¼ç”Ÿæˆé…ç½®
    pub enable_progressive_generation: bool,
    pub batch_size: usize,  // æ¯æ‰¹ç”Ÿæˆæ•°é‡
    pub delay_ms: u64,      // æ‰¹æ¬¡é—´å»¶è¿Ÿ
}

impl AutoIndexer {
    /// åœ¨åå°æ¸è¿›å¼ç”Ÿæˆæ‰€æœ‰ç¼ºå¤±çš„ L0/L1
    pub async fn ensure_all_layers(&self) -> Result<GenerationStats> {
        // 1. æ‰«ææ‰€æœ‰ç›®å½•
        let directories = self.scan_all_directories().await?;
        
        // 2. è¿‡æ»¤å‡ºç¼ºå¤± L0/L1 çš„ç›®å½•
        let missing = self.filter_missing_layers(&directories).await?;
        
        // 3. åˆ†æ‰¹ç”Ÿæˆï¼Œé¿å…è¿‡è½½
        let mut generated = 0;
        for batch in missing.chunks(self.config.batch_size) {
            for dir in batch {
                if let Err(e) = self.generate_layers_for_directory(dir).await {
                    warn!("Failed to generate layers for {}: {}", dir, e);
                } else {
                    generated += 1;
                }
            }
            // æ‰¹æ¬¡é—´å»¶è¿Ÿï¼Œé¿å… LLM API é™æµ
            tokio::time::sleep(Duration::from_millis(self.config.delay_ms)).await;
        }
        
        Ok(GenerationStats { 
            total: missing.len(),
            generated,
            failed: missing.len() - generated,
        })
    }
    
    /// æ£€æµ‹ç›®å½•æ˜¯å¦ç¼ºå¤± L0/L1
    async fn has_layers(&self, uri: &str) -> Result<bool> {
        let abstract_path = format!("{}/.abstract", uri);
        let overview_path = format!("{}/.overview", uri);
        
        Ok(
            self.filesystem.exists(&abstract_path).await? &&
            self.filesystem.exists(&overview_path).await?
        )
    }
}
```

**é…ç½®**:
```toml
[layers.generation]
# å¯ç”¨æ¸è¿›å¼ç”Ÿæˆ
enable_progressive_generation = true
# æ¯æ‰¹ç”Ÿæˆ 10 ä¸ªç›®å½•
batch_size = 10
# æ‰¹æ¬¡é—´å»¶è¿Ÿ 2 ç§’
delay_ms = 2000
# å¯åŠ¨æ—¶è‡ªåŠ¨æ£€æŸ¥å¹¶ç”Ÿæˆ
auto_generate_on_startup = true
```

**CLI æ”¯æŒ**:
```bash
# æ‰‹åŠ¨è§¦å‘å…¨é‡ç”Ÿæˆ
cortex-mem-cli layers ensure-all --tenant acme

# æŸ¥çœ‹ç”Ÿæˆè¿›åº¦
cortex-mem-cli layers status --tenant acme
```

**å®ç°è®¡åˆ’**:
- [ ] æ‰©å±• `AutoIndexer` æ”¯æŒå±‚çº§ç”Ÿæˆ
- [ ] å®ç°ç›®å½•æ‰«æå’Œç¼ºå¤±æ£€æµ‹
- [ ] å®ç°åˆ†æ‰¹æ¸è¿›å¼ç”Ÿæˆ
- [ ] æ·»åŠ  CLI å‘½ä»¤
- [ ] æ·»åŠ å¯åŠ¨æ—¶è‡ªåŠ¨æ£€æŸ¥
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•

**é¢„æœŸæ”¶ç›Š**:
- 100% ç›®å½•è¦†ç›– L0/L1
- é€’å½’æ£€ç´¢å®Œæ•´æ€§ä¿éšœ
- ç”¨æˆ·æ— æ„ŸçŸ¥åå°ç”Ÿæˆ

---

### 2.2 .abstract æ–‡ä»¶è¿‡å¤§é—®é¢˜

**é—®é¢˜æè¿°**: ç”Ÿæˆçš„ `.abstract` æ–‡ä»¶æœ‰æ—¶æ¥è¿‘ 5Kï¼Œè¿œè¶… 500-2K çš„ç›®æ ‡èŒƒå›´ï¼Œå¯¼è‡´ Token æ¶ˆè€—è¿‡å¤§ã€‚

**æ ¹æœ¬åŸå› åˆ†æ**:
```rust
// å½“å‰ Prompt ç¼ºä¹æ˜ç¡®çš„é•¿åº¦çº¦æŸ
let prompt = format!(
    "è¯·ä¸ºä»¥ä¸‹å†…å®¹ç”Ÿæˆä¸€å¥è¯æ‘˜è¦ï¼š\n\n{}",
    content
);
// é—®é¢˜ï¼šLLM å¯èƒ½ç”Ÿæˆå†—é•¿çš„æ‘˜è¦
```

**è§£å†³æ–¹æ¡ˆ**:

#### æ–¹æ¡ˆ1: å¼ºåŒ– Prompt çº¦æŸï¼ˆæ¨èï¼‰

```rust
pub struct AbstractGenerationConfig {
    pub max_tokens: usize,     // æœ€å¤§ Token æ•°ï¼ˆé»˜è®¤ 400ï¼‰
    pub max_chars: usize,      // æœ€å¤§å­—ç¬¦æ•°ï¼ˆé»˜è®¤ 2000ï¼‰
    pub target_sentences: usize, // ç›®æ ‡å¥å­æ•°ï¼ˆé»˜è®¤ 1-3ï¼‰
}

impl LayerGenerator {
    async fn generate_abstract_v2(
        &self,
        content: &str,
        category: &str,
    ) -> Result<String> {
        let prompt = format!(
            r#"è¯·ä¸ºä»¥ä¸‹{category}å†…å®¹ç”Ÿæˆç®€æ´çš„ä¸€å¥è¯æ‘˜è¦ã€‚

ã€ä¸¥æ ¼è¦æ±‚ã€‘
- æœ€å¤š {max_tokens} tokensï¼ˆçº¦ {max_chars} å­—ç¬¦ï¼‰
- 1-3 ä¸ªå®Œæ•´å¥å­
- æç‚¼æ ¸å¿ƒè¦ç‚¹ï¼Œåˆ é™¤ç»†èŠ‚æè¿°
- ä½¿ç”¨ç²¾ç‚¼è¯­è¨€ï¼Œé¿å…å†—ä½™

ã€å†…å®¹ã€‘
{content}

ã€è¾“å‡ºæ ¼å¼ã€‘
ä»…è¿”å›æ‘˜è¦æ–‡æœ¬ï¼Œä¸è¦åŒ…å«ä»»ä½•å‰ç¼€ã€åç¼€æˆ–è§£é‡Šã€‚"#,
            category = category,
            max_tokens = self.config.max_tokens,
            max_chars = self.config.max_chars,
            content = self.truncate_content(content, 4000), // è¾“å…¥ä¹Ÿæˆªæ–­
        );
        
        // è°ƒç”¨ LLM
        let response = self.llm_client.generate(&prompt).await?;
        
        // åå¤„ç†ï¼šå¼ºåˆ¶æˆªæ–­
        let abstract_text = self.enforce_limits(response)?;
        
        Ok(abstract_text)
    }
    
    /// å¼ºåˆ¶æ‰§è¡Œé•¿åº¦é™åˆ¶
    fn enforce_limits(&self, text: String) -> Result<String> {
        let mut result = text.trim().to_string();
        
        // 1. å­—ç¬¦æ•°é™åˆ¶
        if result.len() > self.config.max_chars {
            // æˆªæ–­åˆ°æœ€åä¸€ä¸ªå¥å·/é—®å·/å¹å·
            if let Some(pos) = result[..self.config.max_chars]
                .rfind(|c| c == 'ã€‚' || c == '.' || c == '?' || c == '!') 
            {
                result.truncate(pos + 1);
            } else {
                result.truncate(self.config.max_chars);
                result.push_str("...");
            }
        }
        
        // 2. éªŒè¯ Token æ•°ï¼ˆä½¿ç”¨ tiktoken æˆ–ä¼°ç®—ï¼‰
        let token_count = self.estimate_tokens(&result);
        if token_count > self.config.max_tokens {
            // å†æ¬¡å‹ç¼©
            result = self.compress_to_tokens(result, self.config.max_tokens)?;
        }
        
        Ok(result)
    }
    
    /// ä¼°ç®— Token æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰
    fn estimate_tokens(&self, text: &str) -> usize {
        // ä¸­æ–‡ï¼š1å­—ç¬¦ â‰ˆ 1.5 tokens
        // è‹±æ–‡ï¼š1å•è¯ â‰ˆ 1.3 tokens
        // ç®€åŒ–ä¼°ç®—ï¼šå¹³å‡ 1 å­—ç¬¦ â‰ˆ 1.2 tokens
        (text.len() as f32 * 1.2) as usize
    }
}
```

**é…ç½®**:
```toml
[layers.abstract]
# æœ€å¤§ Token æ•°
max_tokens = 400
# æœ€å¤§å­—ç¬¦æ•°ï¼ˆçº¦ 500 tokensï¼‰
max_chars = 2000
# ç›®æ ‡å¥å­æ•°
target_sentences = 2

[layers.overview]
# Overview å…è®¸ç¨é•¿
max_tokens = 1500
max_chars = 6000
```

**å®ç°è®¡åˆ’**:
- [ ] æ›´æ–° Prompt æ¨¡æ¿ï¼Œå¢åŠ æ˜ç¡®çš„é•¿åº¦çº¦æŸ
- [ ] å®ç°åå¤„ç†æˆªæ–­é€»è¾‘
- [ ] é›†æˆ Token ä¼°ç®—ï¼ˆæˆ–tiktokenåº“ï¼‰
- [ ] æ·»åŠ é…ç½®æ”¯æŒ
- [ ] ç¼–å†™éªŒè¯æµ‹è¯•ï¼ˆç¡®ä¿ 100% ç¬¦åˆé•¿åº¦è¦æ±‚ï¼‰
- [ ] æ›´æ–°ç°æœ‰ `.abstract` æ–‡ä»¶ï¼ˆé‡æ–°ç”Ÿæˆï¼‰

**é¢„æœŸæ”¶ç›Š**:
- `.abstract` ä¸¥æ ¼æ§åˆ¶åœ¨ 500-2K å­—ç¬¦
- Token æ¶ˆè€—é™ä½ 50%+
- æ£€ç´¢é€Ÿåº¦æå‡

---

### 2.3 æ€§èƒ½ä¼˜åŒ–

**é—®é¢˜æè¿°**: å½“å‰è®°å¿†æŸ¥è¯¢æ—¶é—´è¾ƒé•¿ï¼Œéœ€è¦é€šè¿‡å¹¶å‘ã€ç¼“å­˜ç­‰æ‰‹æ®µä¼˜åŒ–ã€‚

**æ€§èƒ½ç“¶é¢ˆåˆ†æ**:

```rust
// å½“å‰å®ç°çš„ä¸»è¦æ€§èƒ½ç“¶é¢ˆï¼š

// 1. ä¸²è¡Œ L0/L1/L2 è¯»å–
let l0 = self.read_abstract(uri).await?;  // 20ms
let l1 = self.read_overview(uri).await?;  // 30ms
let l2 = self.read_content(uri).await?;   // 50ms
// æ€»è®¡ï¼š100ms

// 2. é‡å¤ Embedding ç”Ÿæˆ
for query in queries {
    let vector = self.embed(query).await?; // æ¯æ¬¡ 50ms
}

// 3. åŒæ­¥ç­‰å¾…å‘é‡æœç´¢
let results = self.vector_store.search(vector).await?; // 30ms
```

**è§£å†³æ–¹æ¡ˆ**:

#### ä¼˜åŒ–1: å¹¶å‘ L0/L1/L2 è¯»å–

```rust
use futures::future::try_join_all;

impl LayerReader {
    /// å¹¶å‘è¯»å–æ‰€æœ‰å±‚çº§
    pub async fn read_all_layers_concurrent(
        &self,
        uris: &[String],
    ) -> Result<HashMap<String, LayerBundle>> {
        let tasks: Vec<_> = uris.iter().map(|uri| {
            let uri = uri.clone();
            let reader = self.clone();
            async move {
                // å¹¶å‘è¯»å– L0/L1/L2
                let (l0, l1, l2) = tokio::join!(
                    reader.read_abstract(&uri),
                    reader.read_overview(&uri),
                    reader.read_content(&uri),
                );
                
                Ok::<_, Error>((uri, LayerBundle {
                    abstract_text: l0.ok(),
                    overview: l1.ok(),
                    content: l2.ok(),
                }))
            }
        }).collect();
        
        let results = try_join_all(tasks).await?;
        Ok(results.into_iter().collect())
    }
}

// æ€§èƒ½æå‡ï¼š100ms -> 50msï¼ˆç†è®ºï¼‰
```

#### ä¼˜åŒ–2: Embedding ç¼“å­˜

```rust
use lru::LruCache;
use std::sync::Arc;
use tokio::sync::Mutex;

pub struct CachedEmbeddingClient {
    inner: Arc<dyn EmbeddingClient>,
    cache: Arc<Mutex<LruCache<String, Vec<f32>>>>,
}

impl CachedEmbeddingClient {
    pub fn new(client: Arc<dyn EmbeddingClient>, capacity: usize) -> Self {
        Self {
            inner: client,
            cache: Arc::new(Mutex::new(LruCache::new(capacity))),
        }
    }
    
    pub async fn embed_with_cache(&self, text: &str) -> Result<Vec<f32>> {
        // 1. æ£€æŸ¥ç¼“å­˜
        {
            let mut cache = self.cache.lock().await;
            if let Some(vector) = cache.get(text) {
                return Ok(vector.clone());
            }
        }
        
        // 2. ç”Ÿæˆ Embedding
        let vector = self.inner.embed(text).await?;
        
        // 3. å†™å…¥ç¼“å­˜
        {
            let mut cache = self.cache.lock().await;
            cache.put(text.to_string(), vector.clone());
        }
        
        Ok(vector)
    }
}

// æ€§èƒ½æå‡ï¼šé‡å¤æŸ¥è¯¢ä» 50ms -> 0.1ms
```

#### ä¼˜åŒ–3: æ‰¹é‡ Embedding ç”Ÿæˆ

```rust
impl EmbeddingClient {
    /// æ‰¹é‡ç”Ÿæˆ Embeddingï¼ˆåˆ©ç”¨ API æ‰¹é‡æ¥å£ï¼‰
    pub async fn embed_batch(&self, texts: &[String]) -> Result<Vec<Vec<f32>>> {
        if texts.is_empty() {
            return Ok(vec![]);
        }
        
        // OpenAI API æ”¯æŒæ‰¹é‡ï¼ˆæœ€å¤š 2048 ä¸ªï¼‰
        let response = self.client.post("/embeddings")
            .json(&serde_json::json!({
                "model": self.config.model_name,
                "input": texts,
            }))
            .send()
            .await?;
        
        // è§£ææ‰¹é‡å“åº”
        let data: EmbeddingResponse = response.json().await?;
        Ok(data.data.into_iter().map(|d| d.embedding).collect())
    }
}

// æ€§èƒ½æå‡ï¼š10ä¸ªæŸ¥è¯¢ä» 500ms -> 80ms
```

#### ä¼˜åŒ–4: å‘é‡æœç´¢ç»“æœç¼“å­˜

```rust
pub struct SearchCache {
    cache: Arc<Mutex<LruCache<SearchCacheKey, Vec<SearchResult>>>>,
    ttl: Duration,
}

#[derive(Hash, Eq, PartialEq)]
struct SearchCacheKey {
    query_hash: u64,
    limit: usize,
    filters: String, // JSON åºåˆ—åŒ–çš„è¿‡æ»¤æ¡ä»¶
}

impl VectorSearchEngine {
    pub async fn search_with_cache(
        &self,
        query: &str,
        options: &SearchOptions,
    ) -> Result<Vec<SearchResult>> {
        let cache_key = SearchCacheKey {
            query_hash: self.hash_query(query),
            limit: options.limit,
            filters: serde_json::to_string(&options.filters)?,
        };
        
        // æ£€æŸ¥ç¼“å­˜
        if let Some(cached) = self.cache.get(&cache_key).await {
            if !cached.is_expired() {
                return Ok(cached.results.clone());
            }
        }
        
        // æ‰§è¡Œæœç´¢
        let results = self.inner_search(query, options).await?;
        
        // å†™å…¥ç¼“å­˜
        self.cache.put(cache_key, CachedResult {
            results: results.clone(),
            timestamp: Utc::now(),
        }).await;
        
        Ok(results)
    }
}
```

**é…ç½®**:
```toml
[performance]
# å¹¶å‘è¯»å–
enable_concurrent_layer_reading = true
max_concurrent_reads = 10

# Embedding ç¼“å­˜
enable_embedding_cache = true
embedding_cache_size = 1000

# æ‰¹é‡ Embedding
enable_batch_embedding = true
batch_size = 32

# æœç´¢ç»“æœç¼“å­˜
enable_search_cache = true
search_cache_size = 500
search_cache_ttl_secs = 300
```

**å®ç°è®¡åˆ’**:
- [ ] å®ç°å¹¶å‘ L0/L1/L2 è¯»å–
- [ ] å®ç° Embedding ç¼“å­˜å±‚
- [ ] å®ç°æ‰¹é‡ Embedding æ¥å£
- [ ] å®ç°æœç´¢ç»“æœç¼“å­˜
- [ ] æ·»åŠ æ€§èƒ½ç›‘æ§æŒ‡æ ‡
- [ ] ç¼–å†™æ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] æ–‡æ¡£æ›´æ–°

**é¢„æœŸæ”¶ç›Š**:

| ä¼˜åŒ–é¡¹ | å½“å‰ | ä¼˜åŒ–å | æå‡ |
|--------|------|--------|------|
| å•æ¬¡æŸ¥è¯¢å»¶è¿Ÿ | ~200ms | ~80ms | 60% |
| é‡å¤æŸ¥è¯¢ | ~200ms | ~10ms | 95% |
| æ‰¹é‡æŸ¥è¯¢ (10ä¸ª) | ~2000ms | ~300ms | 85% |
| å†…å­˜å ç”¨ | 50MB | 100MB | -50MB (å¯æ¥å—) |

---

## ä¸‰ã€æ ¸å¿ƒåŠŸèƒ½æ¼”è¿›

> åœ¨ä¿®å¤å½“å‰é—®é¢˜åï¼Œå®æ–½ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½

### 3.1 æ£€ç´¢å¼•æ“å‡çº§ï¼ˆä¼˜å…ˆçº§ï¼šğŸ”¥ğŸ”¥ğŸ”¥ï¼‰

#### 3.1.1 ç›®å½•é€’å½’æ£€ç´¢ (Hierarchical Retrieval)

**ç›®æ ‡**: ä»å¹³é“ºå¼å‘é‡æ£€ç´¢å‡çº§ä¸ºå±‚çº§åŒ–ç›®å½•é€’å½’æ£€ç´¢ï¼ˆå€Ÿé‰´ OpenVikingï¼Œä½†ä¿æŒè½»é‡ï¼‰

**å½“å‰å®ç°:**
```rust
// cortex-mem-core/src/search/mod.rs
// å¹³é“ºå¼æ£€ç´¢ï¼šç›´æ¥å‘é‡æœç´¢ + L0/L1/L2 åŠ æƒ
pub async fn search(&self, query: &str) -> Vec<SearchResult> {
    let vector = self.embedding_client.embed(query).await?;
    let results = self.vector_store.search(vector, limit).await?;
    // åŠ æƒè¯„åˆ†
    self.apply_weighted_scoring(results)
}
```

**ç›®æ ‡å®ç°:**
```rust
// æ–°å¢ hierarchical_retriever.rs
pub struct HierarchicalRetriever {
    vector_store: Arc<dyn VectorStore>,
    embedder: Arc<dyn EmbeddingClient>,
    config: HierarchicalConfig,
}

impl HierarchicalRetriever {
    /// ç›®å½•é€’å½’æ£€ç´¢
    pub async fn retrieve(&self, query: &TypedQuery) -> QueryResult {
        // 1. å…¨å±€æœç´¢å®šä½é«˜åˆ†ç›®å½•
        let global_results = self.global_search(query).await?;
        
        // 2. é€’å½’æœç´¢å­ç›®å½•
        let candidates = self.recursive_search(
            query,
            global_results,
            self.config.max_depth,
        ).await?;
        
        // 3. åˆ†æ•°ä¼ æ’­ä¸æ”¶æ•›
        let scored = self.apply_score_propagation(candidates);
        
        // 4. å¯é€‰ Rerank
        if let Some(reranker) = &self.reranker {
            reranker.rerank(query, scored).await
        } else {
            Ok(scored)
        }
    }
    
    /// åˆ†æ•°ä¼ æ’­æœºåˆ¶
    fn apply_score_propagation(&self, candidates: Vec<Candidate>) -> Vec<Candidate> {
        let alpha = 0.5; // å¯é…ç½®
        candidates.into_iter().map(|mut c| {
            c.final_score = alpha * c.current_score 
                          + (1.0 - alpha) * c.parent_score;
            c
        }).collect()
    }
}
```

**é…ç½®å‚æ•°:**
```toml
[search.hierarchical]
enabled = true
max_depth = 3
score_propagation_alpha = 0.5
convergence_rounds = 3
global_search_topk = 3
```

**å®ç°è®¡åˆ’:**
- [ ] å®šä¹‰ `TypedQuery` ç»“æ„ä½“ï¼ˆæ”¯æŒ context_typeã€target_directoriesï¼‰
- [ ] å®ç° `HierarchicalRetriever` æ ¸å¿ƒé€»è¾‘
- [ ] å®ç°åˆ†æ•°ä¼ æ’­ç®—æ³•
- [ ] å®ç°æ”¶æ•›æ£€æµ‹æœºåˆ¶
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•å’ŒåŸºå‡†æµ‹è¯•
- [ ] é›†æˆåˆ°ç°æœ‰ `VectorSearchEngine`

**é¢„æœŸæ”¶ç›Š:**
- æ£€ç´¢ç²¾åº¦æå‡ 10-15%
- æ›´å¥½çš„å…¨å±€ç†è§£èƒ½åŠ›
- å‡å°‘è¯¯å¬å›
- **ä¿æŒè½»é‡**: æ— éœ€é¢å¤–ä¾èµ–ï¼Œæ ¸å¿ƒç®—æ³• < 500 è¡Œä»£ç 

---

#### 3.1.2 æ„å›¾åˆ†æå¢å¼º (Intent Analysis)

**ç›®æ ‡**: è‡ªåŠ¨åˆ†æç”¨æˆ·æŸ¥è¯¢æ„å›¾ï¼Œç”Ÿæˆæ›´ç²¾å‡†çš„ç±»å‹åŒ–æŸ¥è¯¢ï¼ˆç®€åŒ–ç‰ˆï¼Œé¿å…è¿‡åº¦å¤æ‚ï¼‰

**å®ç°:**
```rust
pub struct IntentAnalyzer {
    llm_client: Arc<dyn LLMClient>,
}

pub struct QueryPlan {
    queries: Vec<TypedQuery>,
}

pub struct TypedQuery {
    query: String,
    context_type: ContextType,  // Memory/Resource/Skill
    intent: String,
    priority: u8,
    target_directories: Vec<String>,
}

impl IntentAnalyzer {
    pub async fn analyze(
        &self,
        query: &str,
        session_context: Option<&SessionContext>,
    ) -> Result<QueryPlan> {
        let prompt = format!(
            "åˆ†æç”¨æˆ·æŸ¥è¯¢æ„å›¾ï¼Œç”Ÿæˆå¤šä¸ªç±»å‹åŒ–æŸ¥è¯¢ï¼š\n\
             ç”¨æˆ·æŸ¥è¯¢: {}\n\
             ä¼šè¯ä¸Šä¸‹æ–‡: {:?}\n\
             è¿”å› JSON æ ¼å¼çš„ QueryPlan",
            query, session_context
        );
        
        let response = self.llm_client.generate(&prompt).await?;
        let plan: QueryPlan = serde_json::from_str(&response)?;
        Ok(plan)
    }
}
```

**ä½¿ç”¨åœºæ™¯:**
```rust
// ç”¨æˆ·æŸ¥è¯¢: "æˆ‘ä¹‹å‰æåˆ°çš„é‚£ä¸ªé¡¹ç›®ç°åœ¨è¿›å±•å¦‚ä½•?"
let plan = intent_analyzer.analyze(query, Some(&session)).await?;
// ç”Ÿæˆ:
// - TypedQuery { context_type: Memory, query: "ç”¨æˆ·æåˆ°çš„é¡¹ç›®", ... }
// - TypedQuery { context_type: Session, query: "é¡¹ç›®è¿›å±•", ... }
```

**å®ç°è®¡åˆ’:**
- [ ] å®šä¹‰ `IntentAnalyzer` å’Œ `QueryPlan`
- [ ] ç¼–å†™ Prompt æ¨¡æ¿
- [ ] é›†æˆåˆ°æœç´¢æµç¨‹
- [ ] æ”¯æŒä¼šè¯ä¸Šä¸‹æ–‡æ³¨å…¥

---

### 2.2 ä¼šè¯ç®¡ç†å¢å¼ºï¼ˆä¼˜å…ˆçº§ï¼šğŸ”¥ğŸ”¥ï¼‰

#### 2.2.1 ä¼šè¯å‹ç¼©ä¸å½’æ¡£

**ç›®æ ‡**: å€Ÿé‰´ OpenViking çš„è‡ªåŠ¨å‹ç¼©å½’æ¡£æœºåˆ¶ï¼Œæ§åˆ¶ä¸Šä¸‹æ–‡çª—å£

**å½“å‰å®ç°:**
```rust
// ä¿ç•™å®Œæ•´ä¼šè¯å†å²
session_manager.add_message(thread_id, message).await?;
// ä¼šè¯å…³é—­æ—¶æå–è®°å¿†
session_manager.close(thread_id).await?;
```

**ç›®æ ‡å®ç°:**
```rust
pub struct SessionCompressionConfig {
    pub auto_threshold_tokens: usize,  // é»˜è®¤ 8000
    pub auto_threshold_messages: usize, // é»˜è®¤ 100
    pub archive_enabled: bool,
    pub max_archives: usize,  // æœ€å¤šä¿ç•™å½’æ¡£æ•°
}

pub struct SessionCompression {
    pub summary: String,
    pub original_count: usize,
    pub compressed_count: usize,
    pub compression_index: usize,
}

impl SessionManager {
    /// æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©
    async fn check_compression_needed(&self, thread_id: &str) -> bool {
        let stats = self.get_session_stats(thread_id).await?;
        stats.total_tokens > self.config.auto_threshold_tokens
            || stats.message_count > self.config.auto_threshold_messages
    }
    
    /// è‡ªåŠ¨å‹ç¼©å½’æ¡£
    pub async fn auto_compress(&self, thread_id: &str) -> Result<CompressionResult> {
        // 1. è¯»å–å½“å‰æ¶ˆæ¯
        let messages = self.get_messages(thread_id).await?;
        
        // 2. ç”Ÿæˆç»“æ„åŒ–æ‘˜è¦ (LLM)
        let summary = self.generate_summary(&messages).await?;
        let abstract_text = self.extract_abstract(&summary);
        
        // 3. åˆ›å»ºå½’æ¡£
        let compression_idx = self.get_next_compression_index(thread_id).await?;
        let archive_uri = format!(
            "cortex://session/{}/history/archive_{:03}",
            thread_id, compression_idx
        );
        
        // å†™å…¥å½’æ¡£
        self.filesystem.write(
            &format!("{}/messages.jsonl", archive_uri),
            &serde_json::to_string(&messages)?,
        ).await?;
        
        self.filesystem.write(
            &format!("{}/.abstract.md", archive_uri),
            &abstract_text,
        ).await?;
        
        self.filesystem.write(
            &format!("{}/.overview.md", archive_uri),
            &summary,
        ).await?;
        
        // 4. æå–é•¿æœŸè®°å¿†
        let memories = self.memory_extractor.extract(&messages, thread_id).await?;
        
        // 5. æ¸…ç©ºå½“å‰æ¶ˆæ¯
        self.clear_current_messages(thread_id).await?;
        
        Ok(CompressionResult {
            compression_index: compression_idx,
            archive_uri,
            memories_extracted: memories.len(),
        })
    }
    
    /// è·å–ä¼šè¯ä¸Šä¸‹æ–‡ç”¨äºæ£€ç´¢
    pub async fn get_context_for_search(
        &self,
        thread_id: &str,
        query: &str,
        max_archives: usize,
    ) -> Result<SessionContext> {
        // 1. å½“å‰æ¶ˆæ¯
        let recent_messages = self.get_recent_messages(thread_id, 20).await?;
        
        // 2. ç›¸å…³å½’æ¡£æ‘˜è¦ï¼ˆåŸºäº query åŒ¹é…ï¼‰
        let summaries = self.find_relevant_archives(
            thread_id,
            query,
            max_archives,
        ).await?;
        
        Ok(SessionContext {
            recent_messages,
            summaries,
        })
    }
}
```

**é…ç½®:**
```toml
[session.compression]
enabled = true
auto_threshold_tokens = 8000
auto_threshold_messages = 100
archive_enabled = true
max_archives = 10  # è‡ªåŠ¨åˆ é™¤æ—§å½’æ¡£
```

**å®ç°è®¡åˆ’:**
- [ ] å®šä¹‰ `SessionCompressionConfig` å’Œç›¸å…³ç»“æ„ä½“
- [ ] å®ç°è‡ªåŠ¨å‹ç¼©è§¦å‘é€»è¾‘
- [ ] å®ç°å½’æ¡£å†™å…¥å’Œç®¡ç†
- [ ] å®ç°å½’æ¡£æ£€ç´¢å’Œä¸Šä¸‹æ–‡æ³¨å…¥
- [ ] ç¼–å†™å‹ç¼©ç»Ÿè®¡å’Œç›‘æ§

**é¢„æœŸæ”¶ç›Š:**
- ä¸Šä¸‹æ–‡çª—å£å¯æ§
- æ”¯æŒè¶…é•¿å¯¹è¯
- é™ä½ LLM æˆæœ¬

---

#### 2.2.2 è®°å¿†åˆ†ç±»æ‰©å±•

**ç›®æ ‡**: æ‰©å±•è®°å¿†åˆ†ç±»ï¼Œæ”¯æŒ Profile å’Œ Pattern

**å½“å‰åˆ†ç±»:**
```rust
pub enum MemoryCategory {
    Preference,  // ç”¨æˆ·åå¥½
    Entity,      // å®ä½“è®°å¿†
    Event,       // äº‹ä»¶è®°å½•
    Case,        // Agentæ¡ˆä¾‹
}
```

**ç›®æ ‡åˆ†ç±»:**
```rust
pub enum MemoryCategory {
    // ç”¨æˆ·è®°å¿†
    Profile,     // ğŸ†• ç”¨æˆ·ç”»åƒ
    Preference,  // ç”¨æˆ·åå¥½
    Entity,      // å®ä½“è®°å¿†
    Event,       // äº‹ä»¶è®°å½•
    
    // Agentè®°å¿†
    Case,        // æ¡ˆä¾‹åº“
    Pattern,     // ğŸ†• æ¨¡å¼åº“
}
```

**Profile å®ç°:**
```rust
impl MemoryExtractor {
    async fn extract_profile(
        &self,
        messages: &[Message],
    ) -> Result<Option<ProfileMemory>> {
        // åˆ†æç”¨æˆ·åŸºæœ¬ä¿¡æ¯ã€èŒä¸šã€å…´è¶£ç­‰
        let prompt = "ä»å¯¹è¯ä¸­æå–ç”¨æˆ·ç”»åƒ...";
        let response = self.llm_client.generate(prompt).await?;
        
        // åˆå¹¶åˆ°ç°æœ‰ Profile
        let existing = self.filesystem.read(
            "cortex://user/profile.md"
        ).await.ok();
        
        if let Some(existing) = existing {
            // LLM åˆå¹¶
            self.merge_profile(existing, response).await
        } else {
            Ok(Some(ProfileMemory { content: response }))
        }
    }
}
```

**Pattern å®ç°:**
```rust
pub struct PatternMemory {
    pub abstract_text: String,
    pub overview: String,
    pub content: String,      // Markdownæ ¼å¼çš„æ¨¡å¼æè¿°
    pub applicability: String, // é€‚ç”¨åœºæ™¯
    pub examples: Vec<String>, // ç¤ºä¾‹
}

impl MemoryExtractor {
    async fn extract_patterns(
        &self,
        messages: &[Message],
    ) -> Result<Vec<PatternMemory>> {
        // ä»å¤šæ¬¡äº¤äº’ä¸­æç‚¼å¯å¤ç”¨æ¨¡å¼
        let prompt = "æç‚¼å¯å¤ç”¨çš„æµç¨‹ã€æ–¹æ³•å’Œæœ€ä½³å®è·µ...";
        let response = self.llm_client.generate(prompt).await?;
        // è§£æä¸º PatternMemory åˆ—è¡¨
        self.parse_patterns(response).await
    }
}
```

**å®ç°è®¡åˆ’:**
- [ ] æ‰©å±• `MemoryCategory` æšä¸¾
- [ ] å®ç° Profile æå–å’Œåˆå¹¶é€»è¾‘
- [ ] å®ç° Pattern æå–å’Œå­˜å‚¨
- [ ] æ›´æ–°æå– Prompt æ¨¡æ¿
- [ ] æ›´æ–°å­˜å‚¨è·¯å¾„æ˜ å°„

---

#### 2.2.3 è®°å¿†å»é‡ä¸åˆå¹¶

**ç›®æ ‡**: å€Ÿé‰´ OpenViking çš„æ™ºèƒ½å»é‡æœºåˆ¶

**å®ç°:**
```rust
pub struct MemoryDeduplicator {
    vector_store: Arc<dyn VectorStore>,
    llm_client: Arc<dyn LLMClient>,
    similarity_threshold: f32, // 0.85
}

impl MemoryDeduplicator {
    pub async fn check_duplicate(
        &self,
        candidate: &CandidateMemory,
        category: MemoryCategory,
    ) -> Result<DeduplicationResult> {
        // 1. å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢
        let vector = self.embedding_client.embed(&candidate.abstract).await?;
        let similar = self.vector_store.search(
            vector,
            Filter::category(category),
            limit: 5,
        ).await?;
        
        // 2. è¿‡æ»¤é«˜ç›¸ä¼¼åº¦å€™é€‰
        let high_similar: Vec<_> = similar.into_iter()
            .filter(|r| r.score > self.similarity_threshold)
            .collect();
        
        if high_similar.is_empty() {
            return Ok(DeduplicationResult::NoDuplicate);
        }
        
        // 3. LLM ç²¾ç¡®åˆ¤æ–­
        for existing in high_similar {
            let prompt = format!(
                "åˆ¤æ–­ä»¥ä¸‹ä¸¤ä¸ªè®°å¿†æ˜¯å¦é‡å¤ï¼š\n\
                 ç°æœ‰è®°å¿†: {}\n\
                 æ–°è®°å¿†: {}\n\
                 è¿”å› JSON: {{\"is_duplicate\": bool, \"reason\": string}}",
                existing.content,
                candidate.content
            );
            
            let response = self.llm_client.generate(&prompt).await?;
            let result: DuplicateCheckResult = serde_json::from_str(&response)?;
            
            if result.is_duplicate {
                return Ok(DeduplicationResult::Duplicate {
                    existing_uri: existing.uri,
                    should_merge: self.should_merge(category),
                });
            }
        }
        
        Ok(DeduplicationResult::NoDuplicate)
    }
    
    /// åˆå¹¶è®°å¿†
    pub async fn merge_memory(
        &self,
        existing_uri: &str,
        new_content: &str,
        category: MemoryCategory,
    ) -> Result<MergedMemory> {
        let existing_content = self.filesystem.read(existing_uri).await?;
        
        let prompt = format!(
            "åˆå¹¶ä»¥ä¸‹ä¸¤ä¸ªè®°å¿†ï¼Œä¿ç•™å®Œæ•´ä¿¡æ¯ï¼š\n\
             ç°æœ‰: {}\n\
             æ–°å¢: {}\n\
             è¿”å› JSON: {{\"abstract\": string, \"overview\": string, \"content\": string}}",
            existing_content, new_content
        );
        
        let response = self.llm_client.generate(&prompt).await?;
        let merged: MergedMemory = serde_json::from_str(&response)?;
        
        // æ›´æ–°æ–‡ä»¶
        self.filesystem.write(existing_uri, &merged.content).await?;
        
        Ok(merged)
    }
}
```

**å®ç°è®¡åˆ’:**
- [ ] å®šä¹‰ `MemoryDeduplicator` ç»“æ„ä½“
- [ ] å®ç°å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢
- [ ] å®ç° LLM ç²¾ç¡®åˆ¤æ–­
- [ ] å®ç°åˆå¹¶é€»è¾‘
- [ ] é›†æˆåˆ°æå–æµç¨‹

---

### 2.3 åˆ†å±‚å†…å­˜ä¼˜åŒ–ï¼ˆä¼˜å…ˆçº§ï¼šğŸ”¥ï¼‰

#### 2.3.1 ä¸»åŠ¨ç”Ÿæˆ vs æ‡’ç”Ÿæˆç­–ç•¥

**ç›®æ ‡**: æä¾›å¯é…ç½®çš„ L0/L1 ç”Ÿæˆç­–ç•¥

**å½“å‰å®ç°:** æ‡’ç”Ÿæˆ
```rust
// ä»…åœ¨é¦–æ¬¡è®¿é—®æ—¶ç”Ÿæˆ
pub async fn get_abstract(&self, uri: &str) -> Result<String> {
    if let Some(cached) = self.cache.get(uri) {
        return Ok(cached);
    }
    // ç”Ÿæˆå¹¶ç¼“å­˜
    let abstract_text = self.generate_abstract(uri).await?;
    self.cache.insert(uri, abstract_text.clone());
    Ok(abstract_text)
}
```

**ç›®æ ‡å®ç°:** æ”¯æŒä¸»åŠ¨ç”Ÿæˆ
```rust
pub enum LayerGenerationStrategy {
    Lazy,     // æ‡’ç”Ÿæˆï¼ˆæŒ‰éœ€ï¼‰
    Eager,    // ä¸»åŠ¨ç”Ÿæˆï¼ˆå†™å…¥æ—¶ï¼‰
    Hybrid,   // æ··åˆï¼ˆé«˜é¢‘è®¿é—®ä¸»åŠ¨ï¼Œä½é¢‘æ‡’åŠ è½½ï¼‰
}

impl LayerManager {
    pub async fn write_with_layers(
        &self,
        uri: &str,
        content: &str,
        strategy: LayerGenerationStrategy,
    ) -> Result<()> {
        // 1. å†™å…¥åŸå§‹å†…å®¹
        self.filesystem.write(uri, content).await?;
        
        match strategy {
            LayerGenerationStrategy::Eager => {
                // ç«‹å³ç”Ÿæˆ L0/L1
                let (abstract_text, overview) = self.generate_layers(content).await?;
                
                // å†™å…¥ç‹¬ç«‹æ–‡ä»¶
                let parent = self.get_parent_uri(uri);
                self.filesystem.write(
                    &format!("{}/.abstract.md", parent),
                    &abstract_text,
                ).await?;
                
                self.filesystem.write(
                    &format!("{}/.overview.md", parent),
                    &overview,
                ).await?;
            }
            
            LayerGenerationStrategy::Lazy => {
                // ä»€ä¹ˆéƒ½ä¸åšï¼Œç­‰å¾…é¦–æ¬¡è®¿é—®
            }
            
            LayerGenerationStrategy::Hybrid => {
                // å¼‚æ­¥é˜Ÿåˆ—ç”Ÿæˆ
                self.enqueue_layer_generation(uri).await?;
            }
        }
        
        Ok(())
    }
}
```

**é…ç½®:**
```toml
[layers]
generation_strategy = "hybrid"  # lazy | eager | hybrid
cache_enabled = true
cache_ttl_secs = 3600
```

**å®ç°è®¡åˆ’:**
- [ ] å®šä¹‰ç”Ÿæˆç­–ç•¥æšä¸¾
- [ ] å®ç°ä¸»åŠ¨ç”Ÿæˆé€»è¾‘
- [ ] å®ç°æ··åˆç­–ç•¥ï¼ˆå¼‚æ­¥é˜Ÿåˆ—ï¼‰
- [ ] æ‰©å±•é…ç½®æ”¯æŒ
- [ ] æ€§èƒ½æµ‹è¯•å¯¹æ¯”

---

#### 2.3.2 æ‰¹é‡æŠ½è±¡è·å–ä¼˜åŒ–

**ç›®æ ‡**: å€Ÿé‰´ OpenViking çš„å¹¶å‘æ‰¹é‡æŠ½è±¡è·å–

**å®ç°:**
```rust
impl LayerManager {
    /// æ‰¹é‡å¹¶å‘è·å–æŠ½è±¡
    pub async fn batch_get_abstracts(
        &self,
        uris: &[String],
        concurrency: usize,
    ) -> Result<HashMap<String, String>> {
        use futures::stream::{self, StreamExt};
        
        let results: Vec<_> = stream::iter(uris)
            .map(|uri| async move {
                let abstract_text = self.get_abstract(uri).await?;
                Ok::<_, Error>((uri.clone(), abstract_text))
            })
            .buffer_unordered(concurrency)
            .collect()
            .await;
        
        let mut map = HashMap::new();
        for result in results {
            let (uri, abstract_text) = result?;
            map.insert(uri, abstract_text);
        }
        
        Ok(map)
    }
}
```

**ä½¿ç”¨åœºæ™¯:**
```rust
// ç›®å½•åˆ—è¡¨å±•ç¤ºæŠ½è±¡
let uris = filesystem.list("cortex://user/memories/").await?;
let abstracts = layer_manager.batch_get_abstracts(&uris, 6).await?;

for uri in uris {
    println!("{}: {}", uri, abstracts.get(&uri).unwrap_or(&"".to_string()));
}
```

**å®ç°è®¡åˆ’:**
- [ ] å®ç°æ‰¹é‡å¹¶å‘è·å–
- [ ] æ·»åŠ ä¿¡å·é‡é™æµ
- [ ] é›†æˆåˆ° CLI `list` å‘½ä»¤
- [ ] é›†æˆåˆ° REST API

---

### 2.4 å¯è§‚æµ‹æ€§å¢å¼ºï¼ˆä¼˜å…ˆçº§ï¼šğŸ”¥ï¼‰

#### 2.4.1 æ£€ç´¢è½¨è¿¹è®°å½•

**ç›®æ ‡**: è®°å½•å®Œæ•´çš„æ£€ç´¢è¿‡ç¨‹ï¼Œæ”¯æŒå¯è§†åŒ–åˆ†æ

**å®ç°:**
```rust
pub struct SearchTrace {
    pub query: String,
    pub timestamp: DateTime<Utc>,
    pub steps: Vec<SearchStep>,
    pub final_results: Vec<SearchResult>,
    pub total_duration_ms: u64,
}

pub struct SearchStep {
    pub step_type: SearchStepType,
    pub description: String,
    pub directory: Option<String>,
    pub candidates_count: usize,
    pub top_scores: Vec<f32>,
    pub duration_ms: u64,
}

pub enum SearchStepType {
    GlobalSearch,
    DirectorySearch,
    ScorePropagation,
    Rerank,
}

impl HierarchicalRetriever {
    pub async fn retrieve_with_trace(
        &self,
        query: &TypedQuery,
    ) -> Result<(QueryResult, SearchTrace)> {
        let mut trace = SearchTrace::new(query.query.clone());
        let start = Instant::now();
        
        // 1. å…¨å±€æœç´¢
        let global_start = Instant::now();
        let global_results = self.global_search(query).await?;
        trace.add_step(SearchStep {
            step_type: SearchStepType::GlobalSearch,
            description: "å…¨å±€å‘é‡æœç´¢å®šä½é«˜åˆ†ç›®å½•".to_string(),
            directory: None,
            candidates_count: global_results.len(),
            top_scores: global_results.iter().take(3).map(|r| r.score).collect(),
            duration_ms: global_start.elapsed().as_millis() as u64,
        });
        
        // 2. é€’å½’æœç´¢
        let recursive_start = Instant::now();
        let candidates = self.recursive_search_with_trace(
            query,
            global_results,
            &mut trace,
        ).await?;
        
        // 3. åˆ†æ•°ä¼ æ’­
        let prop_start = Instant::now();
        let scored = self.apply_score_propagation(candidates);
        trace.add_step(SearchStep {
            step_type: SearchStepType::ScorePropagation,
            description: "åº”ç”¨åˆ†æ•°ä¼ æ’­ç®—æ³•".to_string(),
            directory: None,
            candidates_count: scored.len(),
            top_scores: scored.iter().take(5).map(|c| c.final_score).collect(),
            duration_ms: prop_start.elapsed().as_millis() as u64,
        });
        
        trace.total_duration_ms = start.elapsed().as_millis() as u64;
        trace.final_results = scored.clone();
        
        Ok((QueryResult { results: scored }, trace))
    }
}
```

**å­˜å‚¨:**
```rust
// ä¿å­˜æ£€ç´¢è½¨è¿¹åˆ°æ–‡ä»¶
let trace_uri = format!(
    "cortex://session/{}/traces/search_{}.json",
    thread_id,
    Uuid::new_v4()
);
filesystem.write(&trace_uri, &serde_json::to_string(&trace)?).await?;
```

**å¯è§†åŒ–é›†æˆ:**
```typescript
// cortex-mem-insights/src/components/SearchTraceViewer.svelte
export interface SearchTrace {
  query: string;
  timestamp: string;
  steps: SearchStep[];
  finalResults: SearchResult[];
  totalDurationMs: number;
}

// å±•ç¤ºæ£€ç´¢æµç¨‹å›¾ã€åˆ†æ•°åˆ†å¸ƒç­‰
```

**å®ç°è®¡åˆ’:**
- [ ] å®šä¹‰ `SearchTrace` ç»“æ„ä½“
- [ ] é›†æˆåˆ°æ£€ç´¢æµç¨‹
- [ ] å®ç°è½¨è¿¹æŒä¹…åŒ–
- [ ] Web ä»ªè¡¨æ¿å¯è§†åŒ–
- [ ] REST API æš´éœ²è½¨è¿¹æŸ¥è¯¢

---

#### 2.4.2 IO å½•åˆ¶ä¸å›æ”¾

**ç›®æ ‡**: è®°å½•æ–‡ä»¶ç³»ç»Ÿæ“ä½œï¼Œç”¨äºè°ƒè¯•å’Œè¯„ä¼°

**å®ç°:**
```rust
pub struct IORecorder {
    enabled: bool,
    operations: Arc<Mutex<Vec<IOOperation>>>,
}

pub struct IOOperation {
    pub op_type: IOOpType,
    pub uri: String,
    pub timestamp: DateTime<Utc>,
    pub content_hash: Option<String>,
    pub metadata: HashMap<String, String>,
}

pub enum IOOpType {
    Read,
    Write,
    Delete,
    List,
}

impl CortexFilesystem {
    pub async fn read_with_record(&self, uri: &str) -> Result<String> {
        let content = self.inner_read(uri).await?;
        
        if self.recorder.enabled {
            self.recorder.record(IOOperation {
                op_type: IOOpType::Read,
                uri: uri.to_string(),
                timestamp: Utc::now(),
                content_hash: Some(self.hash(&content)),
                metadata: HashMap::new(),
            });
        }
        
        Ok(content)
    }
}
```

**ä½¿ç”¨åœºæ™¯:**
```rust
// æµ‹è¯•å’Œè¯„ä¼°
recorder.start_recording();
let result = search_engine.search(query).await?;
let operations = recorder.stop_and_get_operations();

// åˆ†æ IO æ¨¡å¼
println!("Total reads: {}", operations.iter().filter(|op| op.op_type == IOOpType::Read).count());
println!("Total writes: {}", operations.iter().filter(|op| op.op_type == IOOpType::Write).count());
```

**å®ç°è®¡åˆ’:**
- [ ] å®šä¹‰ `IORecorder` å’Œ `IOOperation`
- [ ] é›†æˆåˆ° `CortexFilesystem`
- [ ] å®ç°å½•åˆ¶å¼€å…³
- [ ] å¯¼å‡ºä¸º JSON/CSV
- [ ] ç”¨äºæ€§èƒ½åˆ†æå’Œä¼˜åŒ–

---

### 2.5 èµ„æºè§£æå¢å¼ºï¼ˆä¼˜å…ˆçº§ï¼šâ­ï¼‰

#### 2.5.1 ä¸°å¯Œè§£æå™¨ç”Ÿæ€

**ç›®æ ‡**: å‚è€ƒ OpenViking æ‰©å±•è§£æå™¨ç±»å‹

**å½“å‰è§£æå™¨:**
- Markdown
- Text
- (åŸºç¡€)

**ç›®æ ‡è§£æå™¨:**
- PDF
- HTML
- Code Repository (æ”¯æŒå¤šè¯­è¨€)
- Office æ–‡æ¡£ (Word, Excel, PPT)
- å›¾ç‰‡ (OCR + VLM)

**å®ç°æ¡†æ¶:**
```rust
pub trait ResourceParser: Send + Sync {
    fn supported_extensions(&self) -> Vec<&str>;
    async fn parse(&self, path: &Path) -> Result<ParseResult>;
}

pub struct ParseResult {
    pub root: ResourceNode,
    pub metadata: HashMap<String, String>,
}

pub struct ResourceNode {
    pub uri: String,
    pub node_type: NodeType,
    pub content: String,
    pub children: Vec<ResourceNode>,
}

// æ’ä»¶åŒ–æ³¨å†Œ
pub struct ParserRegistry {
    parsers: HashMap<String, Box<dyn ResourceParser>>,
}

impl ParserRegistry {
    pub fn register(&mut self, parser: Box<dyn ResourceParser>) {
        for ext in parser.supported_extensions() {
            self.parsers.insert(ext.to_string(), parser.clone());
        }
    }
}
```

**å®ç°è®¡åˆ’:**
- [ ] å®šä¹‰ `ResourceParser` trait
- [ ] å®ç° `PDFParser` (ä½¿ç”¨ pdf-extract)
- [ ] å®ç° `HTMLParser` (ä½¿ç”¨ scraper)
- [ ] å®ç° `CodeRepositoryParser` (ä½¿ç”¨ tree-sitter)
- [ ] å®ç°æ’ä»¶æ³¨å†Œæœºåˆ¶

---

## ä¸‰ã€æŠ€æœ¯å€ºåŠ¡æ¸…ç†

### 3.1 ä»£ç è´¨é‡æå‡

- [ ] å¢åŠ å•å…ƒæµ‹è¯•è¦†ç›–ç‡ï¼ˆç›®æ ‡ 80%+ï¼‰
- [ ] å¢åŠ é›†æˆæµ‹è¯•
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•è‡ªåŠ¨åŒ–
- [ ] ä»£ç é™æ€åˆ†æ (clippy --all-features)
- [ ] ä¾èµ–å®‰å…¨æ‰«æ

### 3.2 æ–‡æ¡£å®Œå–„

- [ ] è‹±æ–‡æ–‡æ¡£è¡¥å……
- [ ] æ¶æ„è®¾è®¡æ–‡æ¡£
- [ ] API å‚è€ƒæ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆ
- [ ] æœ€ä½³å®è·µæŒ‡å—
- [ ] æ•…éšœæ’æŸ¥æŒ‡å—

### 3.3 CI/CD ä¼˜åŒ–

- [ ] è‡ªåŠ¨å‘å¸ƒ Crate
- [ ] Docker é•œåƒè‡ªåŠ¨æ„å»º
- [ ] æ€§èƒ½å›å½’æ£€æµ‹
- [ ] å…¼å®¹æ€§æµ‹è¯•çŸ©é˜µ

---

## å››ã€å®æ–½è·¯çº¿å›¾

### é˜¶æ®µä¸€ï¼šæ ¸å¿ƒæ£€ç´¢å‡çº§ï¼ˆ1-2ä¸ªæœˆï¼‰

**ç›®æ ‡**: å®ç°ç›®å½•é€’å½’æ£€ç´¢å’Œæ··åˆå‘é‡æ£€ç´¢

- âœ… å®šä¹‰æ ¸å¿ƒæ•°æ®ç»“æ„
- âœ… å®ç° HierarchicalRetriever
- âœ… å®ç°åˆ†æ•°ä¼ æ’­ç®—æ³•
- âœ… é›†æˆæ··åˆå‘é‡æ£€ç´¢
- âœ… ç¼–å†™æµ‹è¯•å’ŒåŸºå‡†
- âœ… æ–‡æ¡£æ›´æ–°

### é˜¶æ®µäºŒï¼šä¼šè¯ç®¡ç†å¢å¼ºï¼ˆ1ä¸ªæœˆï¼‰

**ç›®æ ‡**: å®ç°ä¼šè¯å‹ç¼©å½’æ¡£å’Œè®°å¿†å»é‡

- âœ… å®ç°è‡ªåŠ¨å‹ç¼©è§¦å‘
- âœ… å®ç°å½’æ¡£å†™å…¥å’Œç®¡ç†
- âœ… å®ç°è®°å¿†å»é‡
- âœ… æ‰©å±•è®°å¿†åˆ†ç±»ï¼ˆProfile/Patternï¼‰
- âœ… ç¼–å†™æµ‹è¯•
- âœ… æ–‡æ¡£æ›´æ–°

### é˜¶æ®µä¸‰ï¼šå¯è§‚æµ‹æ€§å’Œåˆ†å±‚ä¼˜åŒ–ï¼ˆ1ä¸ªæœˆï¼‰

**ç›®æ ‡**: å¢å¼ºå¯è§‚æµ‹æ€§å’Œåˆ†å±‚å†…å­˜ç­–ç•¥

- âœ… å®ç°æ£€ç´¢è½¨è¿¹è®°å½•
- âœ… å®ç° IO å½•åˆ¶
- âœ… å®ç°ä¸»åŠ¨ç”Ÿæˆç­–ç•¥
- âœ… å®ç°æ‰¹é‡æŠ½è±¡è·å–
- âœ… Web ä»ªè¡¨æ¿é›†æˆ
- âœ… æ–‡æ¡£æ›´æ–°

### é˜¶æ®µå››ï¼šèµ„æºè§£æå’Œç”Ÿæ€ï¼ˆ1-2ä¸ªæœˆï¼‰

**ç›®æ ‡**: ä¸°å¯Œè§£æå™¨å’Œé›†æˆç”Ÿæ€

- âœ… å®ç°å¤šç§è§£æå™¨
- âœ… æ’ä»¶åŒ–æ¶æ„
- âœ… MCP é›†æˆå¢å¼º
- âœ… Rig é›†æˆå¢å¼º
- âœ… ç¤ºä¾‹å’Œæ•™ç¨‹

### é˜¶æ®µäº”ï¼šæ€§èƒ½ä¼˜åŒ–å’Œå‘å¸ƒï¼ˆæŒç»­ï¼‰

**ç›®æ ‡**: æ€§èƒ½è°ƒä¼˜å’Œç¨³å®šæ€§æå‡

- âœ… æ€§èƒ½åŸºå‡†å¯¹æ¯”
- âœ… å†…å­˜ä¼˜åŒ–
- âœ… å¹¶å‘ä¼˜åŒ–
- âœ… ä»£ç è´¨é‡æå‡
- âœ… æ–‡æ¡£å®Œå–„
- âœ… æ­£å¼å‘å¸ƒ 3.0

---

## äº”ã€é¢„æœŸæˆæœ

### 5.1 æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | å½“å‰ (2.x) | ç›®æ ‡ (3.0) | æå‡ |
|------|-----------|-----------|------|
| Recall@1 | 93.33% | 95%+ | +1.67pp |
| MRR | 93.72% | 95%+ | +1.28pp |
| NDCG@5 | 80.73% | 85%+ | +4.27pp |
| æ£€ç´¢å»¶è¿Ÿ | ~50ms | ~60ms | -10ms (é€’å½’æ£€ç´¢æˆæœ¬) |
| ç´¢å¼•åå | ~1000/s | ~1200/s | +20% |

### 5.2 åŠŸèƒ½å®Œæ•´æ€§

- âœ… ç›®å½•é€’å½’æ£€ç´¢
- âœ… æ··åˆå‘é‡æ£€ç´¢
- âœ… æ„å›¾åˆ†æ
- âœ… ä¼šè¯å‹ç¼©å½’æ¡£
- âœ… è®°å¿†å»é‡åˆå¹¶
- âœ… å…­åˆ†ç±»è®°å¿†
- âœ… æ£€ç´¢è½¨è¿¹å¯è§†åŒ–
- âœ… IO å½•åˆ¶ä¸å›æ”¾
- âœ… ä¸°å¯Œè§£æå™¨ç”Ÿæ€

### 5.3 ç”Ÿæ€å®Œæ•´æ€§

- âœ… REST API 2.0
- âœ… MCP Server
- âœ… Rig Framework é›†æˆ
- âœ… Web ä»ªè¡¨æ¿
- âœ… CLI å·¥å…·
- âœ… Docker é•œåƒ
- âœ… å®Œæ•´æ–‡æ¡£

---

## å…­ã€é£é™©ä¸åº”å¯¹

### 6.1 æŠ€æœ¯é£é™©

**é£é™©**: é€’å½’æ£€ç´¢å¢åŠ å¤æ‚åº¦å’Œå»¶è¿Ÿ

**åº”å¯¹**:
- æ”¶æ•›æ£€æµ‹æ—©åœ
- å¯é…ç½®æœ€å¤§æ·±åº¦
- ç¼“å­˜ä¼˜åŒ–
- æä¾›ç®€åŒ–æ¨¡å¼å¼€å…³

**é£é™©**: ä¼šè¯å‹ç¼©å¯èƒ½ä¸¢å¤±ä¿¡æ¯

**åº”å¯¹**:
- å½’æ¡£å®Œæ•´ä¿ç•™åŸå§‹æ¶ˆæ¯
- LLM æ‘˜è¦è´¨é‡ç›‘æ§
- å¯é…ç½®å‹ç¼©ç­–ç•¥
- ç”¨æˆ·å¯æ‰‹åŠ¨å…³é—­

### 6.2 å…¼å®¹æ€§é£é™©

**é£é™©**: 3.0 å¯èƒ½ä¸å…¼å®¹ 2.x

**åº”å¯¹**:
- æä¾›æ•°æ®è¿ç§»è„šæœ¬
- ä¿æŒé…ç½®å‘åå…¼å®¹
- æ–‡æ¡£è¿ç§»æŒ‡å—
- é•¿æœŸæ”¯æŒ 2.x LTS

### 6.3 æ€§èƒ½é£é™©

**é£é™©**: æ–°åŠŸèƒ½å¯èƒ½å½±å“æ€§èƒ½

**åº”å¯¹**:
- æŒç»­æ€§èƒ½åŸºå‡†æµ‹è¯•
- æ€§èƒ½å›å½’æ£€æµ‹
- å¯é€‰åŠŸèƒ½å¼€å…³
- æ€§èƒ½è°ƒä¼˜

---

## ä¸ƒã€æ€»ç»“

### 7.1 æ ¸å¿ƒä»·å€¼

Cortex-Memory 3.0 å°†èåˆ:

1. **Rust é«˜æ€§èƒ½ä¼˜åŠ¿**: ä¿æŒæ€§èƒ½é¢†å…ˆ
2. **OpenViking å…ˆè¿›æ¶æ„**: å¼•å…¥é€’å½’æ£€ç´¢ã€åˆ†å±‚ç®¡ç†
3. **å®Œæ•´ç”Ÿæ€**: REST + MCP + Web + CLI
4. **æ˜“ç”¨æ€§**: ç®€åŒ–éƒ¨ç½²ï¼Œé™ä½é—¨æ§›
5. **ä¼ä¸šå°±ç»ª**: å¤šç§Ÿæˆ·ã€å¯è§‚æµ‹ã€å¯è¿ç»´

### 7.2 ç«äº‰åŠ›æå‡

- âœ… **æ€§èƒ½**: ç»§ç»­ä¿æŒ Rust æ€§èƒ½ä¼˜åŠ¿
- âœ… **ç²¾åº¦**: å¼•å…¥é€’å½’æ£€ç´¢æå‡æ£€ç´¢è´¨é‡
- âœ… **æ™ºèƒ½**: æ„å›¾åˆ†æã€å»é‡åˆå¹¶
- âœ… **æ•ˆç‡**: ä¼šè¯å‹ç¼©æ§åˆ¶æˆæœ¬
- âœ… **å¯è§‚æµ‹**: è½¨è¿¹è®°å½•ã€IO å›æ”¾
- âœ… **ç”Ÿæ€**: æœ€å®Œæ•´çš„é›†æˆç”Ÿæ€

### 7.3 é•¿æœŸæ„¿æ™¯

**Cortex-Memory** å°†æˆä¸º:
- AI åº”ç”¨çš„ **é¦–é€‰è®°å¿†åŸºç¡€è®¾æ–½**
- å¼€æºç¤¾åŒºçš„ **æ€§èƒ½æ ‡æ†**
- ä¼ä¸šçº§åº”ç”¨çš„ **å¯é é€‰æ‹©**

---

**Let's build the future of AI memory together! ğŸš€**
