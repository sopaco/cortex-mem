# ğŸ“ Config.toml æ›´æ–°è¯´æ˜

## æ›´æ–°å†…å®¹

å·²å°† `config.toml` ä»æ—§æ¶æ„é…ç½®æ›´æ–°ä¸º**æ–°æ¶æ„ï¼ˆCortex-Mem V2ï¼‰**é…ç½®ã€‚

---

## ğŸ”„ ä¸»è¦å˜æ›´

### 1. æ·»åŠ äº†è¯¦ç»†çš„é…ç½®è¯´æ˜

**æ–°å¢**:
- âœ… é¡¶éƒ¨æ·»åŠ æ¶æ„è¯´æ˜
- âœ… æ¯ä¸ªé…ç½®æ®µéƒ½æ ‡æ³¨æ˜¯å¦ä½¿ç”¨
- âœ… è§£é‡Šæ–°æ¶æ„çš„å·¥ä½œåŸç†

### 2. LLM é…ç½®æ›´æ–°

**å˜æ›´**:
```toml
# æ—§é…ç½®ï¼ˆå†…ç½‘ APIï¼‰
api_base_url = "https://wanqing-api.corp.kuaishou.com/api/gateway/v1/endpoints"
api_key = "fs2wzco3o7haz38df1jo4vavnvauxtuz3f0b"
model_efficient = "ep-i4abhq-1764595896785685523"

# æ–°é…ç½®ï¼ˆæœ¬åœ° Ollamaï¼‰
api_base_url = "http://localhost:11434/v1"
api_key = "ollama"
model_efficient = "qwen2.5:14b"
```

**åŸå› **:
- âœ… ä½¿ç”¨æœ¬åœ° Ollama æ›´ä¾¿äºå¼€å‘æµ‹è¯•
- âœ… å¦‚éœ€ä½¿ç”¨å…¶ä»– LLMï¼Œä¿®æ”¹ `api_base_url` å³å¯

### 3. Qdrant é…ç½®æ ‡æ³¨

**å˜æ›´**:
```toml
# âš ï¸ Qdrant å‘é‡æ•°æ®åº“é…ç½®ï¼ˆæ–°æ¶æ„ä¸ä½¿ç”¨ï¼‰
# æ–°æ¶æ„ä½¿ç”¨æ–‡ä»¶ç³»ç»Ÿå­˜å‚¨ï¼Œä¸éœ€è¦å¤–éƒ¨å‘é‡æ•°æ®åº“
[qdrant]
url = "http://localhost:6334"
collection_name = "cortex-mem-v2"  # â† æ”¹å
```

**è¯´æ˜**:
- âš ï¸ ä¿ç•™æ­¤é…ç½®æ®µä»…ä¸º `cortex-mem-config` å…¼å®¹æ€§
- âŒ æ–°æ¶æ„ä¸ä¼šä½¿ç”¨è¿™äº›é…ç½®
- âœ… ä¿®æ”¹è¿™äº›å€¼ä¸ä¼šå½±å“ç³»ç»Ÿè¿è¡Œ

### 4. Embedding é…ç½®æ ‡æ³¨

**å˜æ›´**:
```toml
# âš ï¸ Embedding æœåŠ¡é…ç½®ï¼ˆæ–°æ¶æ„ä¸ä½¿ç”¨ï¼‰
# æ–°æ¶æ„ä½¿ç”¨å…³é”®è¯åŒ¹é…ï¼Œä¸éœ€è¦å‘é‡åµŒå…¥
[embedding]
api_base_url = "http://localhost:11434/v1"
api_key = "ollama"
model_name = "nomic-embed-text"  # â† æ”¹ä¸ºæœ¬åœ°æ¨¡å‹
```

**è¯´æ˜**:
- âš ï¸ ä¿ç•™æ­¤é…ç½®æ®µä»…ä¸ºå…¼å®¹æ€§
- âŒ æ–°æ¶æ„ä¸ä½¿ç”¨å‘é‡åµŒå…¥
- âœ… ä½¿ç”¨å…³é”®è¯åŒ¹é…è¿›è¡Œæ£€ç´¢

### 5. Memory é…ç½®è¯´æ˜

**å˜æ›´**:
```toml
[memory]
# âœ… æ–°æ¶æ„ä½¿ç”¨çš„é…ç½®
max_memories = 10000
max_search_results = 50
auto_summary_threshold = 4096
auto_enhance = true
deduplicate = true

# âš ï¸ ä»¥ä¸‹é…ç½®åœ¨æ–°æ¶æ„ä¸­ä¸ä½¿ç”¨
similarity_threshold = 0.65       # âŒ ä¸ä½¿ç”¨
merge_threshold = 0.75            # âŒ ä¸ä½¿ç”¨
search_similarity_threshold = 0.5 # âŒ ä¸ä½¿ç”¨
```

**è¯´æ˜**:
- âœ… æ˜ç¡®æ ‡æ³¨å“ªäº›é…ç½®ä½¿ç”¨
- âš ï¸ ç›¸ä¼¼åº¦é˜ˆå€¼é…ç½®ä¿ç•™ä½†ä¸ä½¿ç”¨
- â„¹ï¸ æ–°æ¶æ„çš„æ£€ç´¢é˜ˆå€¼ç¡¬ç¼–ç ä¸º `0.1`

---

## âœ… é…ç½®å­—æ®µè¯´æ˜

### LLM é…ç½®ï¼ˆå¿…éœ€ï¼‰

```toml
[llm]
api_base_url = "http://localhost:11434/v1"  # LLM API åœ°å€
api_key = "ollama"                          # API å¯†é’¥
model_efficient = "qwen2.5:14b"             # æ¨¡å‹åç§°
temperature = 0.7                           # ç”Ÿæˆæ¸©åº¦
max_tokens = 4096                           # æœ€å¤§ token æ•°
```

**ç”¨é€”**:
- âœ… Agent å¯¹è¯ç”Ÿæˆ
- âœ… è‡ªåŠ¨ç”Ÿæˆ L0/L1 æ‘˜è¦
- âœ… è®°å¿†å†…å®¹å¢å¼º

**å¸¸ç”¨ LLM é…ç½®ç¤ºä¾‹**:

1. **æœ¬åœ° Ollama**ï¼ˆæ¨èå¼€å‘ï¼‰:
   ```toml
   api_base_url = "http://localhost:11434/v1"
   api_key = "ollama"
   model_efficient = "qwen2.5:14b"
   ```

2. **OpenAI**:
   ```toml
   api_base_url = "https://api.openai.com/v1"
   api_key = "sk-..."
   model_efficient = "gpt-4o-mini"
   ```

3. **å†…ç½‘ API**:
   ```toml
   api_base_url = "https://your-api.corp.example.com/v1"
   api_key = "your-api-key"
   model_efficient = "your-model-id"
   ```

---

### Server é…ç½®

```toml
[server]
host = "0.0.0.0"        # ç›‘å¬åœ°å€
port = 3000             # ç›‘å¬ç«¯å£
cors_origins = ["*"]    # CORS å…è®¸çš„æ¥æº
```

**ç”¨é€”**:
- âœ… TARS API æœåŠ¡å™¨
- âœ… HTTP æ¥å£

---

### Memory é…ç½®

```toml
[memory]
max_memories = 10000              # æœ€å¤§è®°å¿†æ•°é‡
max_search_results = 50           # æœ€å¤§æœç´¢ç»“æœæ•°
auto_summary_threshold = 4096     # è‡ªåŠ¨æ‘˜è¦é˜ˆå€¼
auto_enhance = true               # è‡ªåŠ¨å¢å¼º
deduplicate = true                # å»é‡
```

**å®é™…ä½¿ç”¨çš„å­—æ®µ**:
- âœ… `max_memories` - é™åˆ¶è®°å¿†æ€»æ•°
- âœ… `max_search_results` - é™åˆ¶æœç´¢è¿”å›æ•°é‡
- âœ… `auto_summary_threshold` - è¶…è¿‡æ­¤å­—ç¬¦æ•°è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦
- âœ… `auto_enhance` - æ˜¯å¦è‡ªåŠ¨ç”Ÿæˆ L0/L1 å±‚çº§
- âœ… `deduplicate` - æ˜¯å¦å»é‡

**ä¸ä½¿ç”¨çš„å­—æ®µ**ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰:
- âŒ `similarity_threshold` - å‘é‡ç›¸ä¼¼åº¦ï¼ˆæ–°æ¶æ„ç”¨ 0.1ï¼‰
- âŒ `merge_threshold` - è®°å¿†åˆå¹¶é˜ˆå€¼
- âŒ `search_similarity_threshold` - æœç´¢ç›¸ä¼¼åº¦

---

### Logging é…ç½®

```toml
[logging]
enabled = true           # æ˜¯å¦å¯ç”¨æ—¥å¿—
log_directory = "logs"   # æ—¥å¿—ç›®å½•
level = "debug"          # æ—¥å¿—çº§åˆ«
```

**æ—¥å¿—çº§åˆ«**:
- `error` - ä»…é”™è¯¯
- `warn` - è­¦å‘ŠåŠä»¥ä¸Š
- `info` - ä¿¡æ¯åŠä»¥ä¸Š
- `debug` - è°ƒè¯•åŠä»¥ä¸Šï¼ˆæ¨èå¼€å‘ï¼‰
- `trace` - è¿½è¸ªæ‰€æœ‰

---

## ğŸ¯ æ–°æ¶æ„ç‰¹æ€§

### 1. æ–‡ä»¶ç³»ç»Ÿå­˜å‚¨

**å­˜å‚¨ä½ç½®**:
```
~/.local/share/cortex-mem/
  threads/
    <thread-id>/
      timeline/
        2026-02/
          06/
            14_34_46_user123.md  â† å®é™…è®°å¿†
      .abstract.md                â† L0 æ‘˜è¦ï¼ˆ~100 tokensï¼‰
      .overview.md                â† L1 æ¦‚è§ˆï¼ˆ~500-2000 tokensï¼‰
```

**ä¼˜åŠ¿**:
- âœ… äººç±»å¯è¯»ï¼ˆMarkdown æ ¼å¼ï¼‰
- âœ… æ— å¤–éƒ¨ä¾èµ–
- âœ… æ˜“äºå¤‡ä»½å’Œè¿ç§»

---

### 2. åˆ†å±‚åŠ è½½

| å±‚çº§ | æ–‡ä»¶ | å¤§å° | ç”¨é€” |
|-----|------|------|------|
| L0 | `.abstract.md` | ~100 tokens | å¿«é€Ÿé¢„è§ˆ |
| L1 | `.overview.md` | ~500-2000 tokens | æ¦‚è§ˆä¿¡æ¯ |
| L2 | `*.md` | å®Œæ•´å†…å®¹ | è¯¦ç»†è®°å¿† |

**ä½¿ç”¨åœºæ™¯**:
- L0: åˆ—è¡¨å±•ç¤ºã€å¿«é€Ÿæ‰«æ
- L1: ä¸Šä¸‹æ–‡åŠ è½½ã€ç›¸å…³æ€§åˆ¤æ–­
- L2: è¯¦ç»†æŸ¥çœ‹ã€å®Œæ•´æ£€ç´¢

---

### 3. å…³é”®è¯æ£€ç´¢

**æ£€ç´¢æµç¨‹**:
1. Intent åˆ†æ â†’ æå–å…³é”®è¯
2. L0 æ‰«æ â†’ æ‰¾åˆ°å€™é€‰ç›®å½•
3. L1 æ¢ç´¢ â†’ åœ¨å€™é€‰ç›®å½•ä¸­æœç´¢
4. ç›¸å…³æ€§è¯„åˆ† â†’ TF-IDF ç®—æ³•
5. è¿”å›ç»“æœ â†’ æŒ‰åˆ†æ•°æ’åº

**é˜ˆå€¼**:
- ç©ºæŸ¥è¯¢: `0.0`ï¼ˆè¿”å›æ‰€æœ‰ï¼‰
- æ™®é€šæŸ¥è¯¢: `0.1`ï¼ˆå…è®¸ä½åˆ†ç»“æœï¼‰
- é«˜è´¨é‡: `0.3`ï¼ˆä»…é«˜åˆ†ç»“æœï¼‰

---

## ğŸš€ ä½¿ç”¨å»ºè®®

### å¼€å‘ç¯å¢ƒ

```toml
[llm]
api_base_url = "http://localhost:11434/v1"
api_key = "ollama"
model_efficient = "qwen2.5:14b"

[logging]
level = "debug"  # è¯¦ç»†æ—¥å¿—
```

### ç”Ÿäº§ç¯å¢ƒ

```toml
[llm]
api_base_url = "https://api.openai.com/v1"
api_key = "sk-..."
model_efficient = "gpt-4o-mini"

[logging]
level = "info"  # å‡å°‘æ—¥å¿—
```

---

## ğŸ“Œ æ³¨æ„äº‹é¡¹

1. **ä¸éœ€è¦å¯åŠ¨ Qdrant**
   - æ–°æ¶æ„ä¸ä½¿ç”¨å‘é‡æ•°æ®åº“
   - é…ç½®ä¸­çš„ Qdrant è®¾ç½®ä¸ä¼šè¢«è¯»å–

2. **ä¸éœ€è¦ Embedding æœåŠ¡**
   - æ–°æ¶æ„ä½¿ç”¨å…³é”®è¯åŒ¹é…
   - æ— éœ€æ‹…å¿ƒ Embedding API æˆæœ¬

3. **LLM æ˜¯å¿…éœ€çš„**
   - ç”¨äº Agent å¯¹è¯
   - ç”¨äºè‡ªåŠ¨ç”Ÿæˆæ‘˜è¦
   - ç¡®ä¿ `api_base_url` å¯è®¿é—®

4. **æ•°æ®ç›®å½•**
   - é»˜è®¤: `~/.local/share/cortex-mem/`
   - å¯é€šè¿‡ç¯å¢ƒå˜é‡ `CORTEX_DATA_DIR` ä¿®æ”¹

---

## âœ… éªŒè¯é…ç½®

è¿è¡Œ TARS æ£€æŸ¥é…ç½®æ˜¯å¦æ­£ç¡®:

```bash
cargo run -p cortex-mem-tars --release
```

**é¢„æœŸè¾“å‡º**:
```
âœ… åŠ è½½é…ç½®æ–‡ä»¶æˆåŠŸ
âœ… åˆå§‹åŒ– LLM å®¢æˆ·ç«¯æˆåŠŸ
âœ… åˆå§‹åŒ–æ–‡ä»¶ç³»ç»ŸæˆåŠŸ
âš ï¸  Qdrant é…ç½®å·²å¿½ç•¥ï¼ˆæ–°æ¶æ„ä¸ä½¿ç”¨ï¼‰
âš ï¸  Embedding é…ç½®å·²å¿½ç•¥ï¼ˆæ–°æ¶æ„ä¸ä½¿ç”¨ï¼‰
```

---

**æ›´æ–°æ—¶é—´**: 2026-02-06 14:34  
**æ¶æ„ç‰ˆæœ¬**: Cortex-Mem V2  
**é…ç½®ç‰ˆæœ¬**: 2.0
