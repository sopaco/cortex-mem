# 简化版评估配置

[general]
mode = "all"
output_dir = "results"
verbose = true
random_seed = 42
use_real_evaluators = true

[recall_evaluation]
enabled = true
test_cases_path = "data/test_cases/lab_recall_dataset.json"
ground_truth_path = "data/test_cases/lab_recall_dataset.json"
k_values = [1, 3, 5]
similarity_thresholds = [0.7, 0.8]
max_results_per_query = 10
save_intermediate_results = true
use_real_evaluator = true

[effectiveness_evaluation]
enabled = true
test_cases_path = "data/test_cases/lab_effectiveness_dataset.json"
ground_truth_path = "data/test_cases/lab_effectiveness_dataset.json"
verify_fact_extraction = true
verify_classification = true
verify_importance_evaluation = true
verify_deduplication = true
verify_memory_update = true
use_real_evaluator = true

[qdrant]
url = "http://localhost:6334"
collection_name = "evaluation_memories"
timeout_secs = 30

[llm]
api_base_url = "http://localhost:11434"
api_key = ""
model_efficient = "llama3.2:3b"
temperature = 0.7
max_tokens = 1000

[server]
host = "0.0.0.0"
port = 8080
cors_origins = ["*"]

[embedding]
api_base_url = "http://localhost:11434"
model_name = "nomic-embed-text"
api_key = ""
batch_size = 32
timeout_secs = 30

[memory]
max_memories = 10000
similarity_threshold = 0.8
max_search_results = 50
auto_summary_threshold = 32768
auto_enhance = true
deduplicate = true
merge_threshold = 0.9
search_similarity_threshold = 0.70

[logging]
enabled = true
log_directory = "logs"
level = "info"