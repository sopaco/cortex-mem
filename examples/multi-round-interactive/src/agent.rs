use memo_config::Config;
use memo_rig::{
    memory::manager::MemoryManager,
    tool::{MemoryArgs, MemoryToolConfig, create_memory_tool},
    types::Message,
};
use rig::{
    agent::Agent,
    client::CompletionClient,
    completion::Prompt,
    providers::openai::{Client, CompletionModel},
    tool::Tool,
};

use std::sync::Arc;

// å¯¼å…¥æ—¥å¿—é‡å®šå‘å‡½æ•°
use crate::app::redirect_log_to_ui;

/// åˆ›å»ºå¸¦è®°å¿†åŠŸèƒ½çš„Agent
pub async fn create_memory_agent(
    memory_manager: Arc<MemoryManager>,
    memory_tool_config: MemoryToolConfig,
    config: &Config,
) -> Result<Agent<CompletionModel>, Box<dyn std::error::Error>> {
    let _memory_tool =
        create_memory_tool(memory_manager.clone(), &config, Some(memory_tool_config));

    let llm_client = Client::builder(&config.llm.api_key)
        .base_url(&config.llm.api_base_url)
        .build();

    let completion_model = llm_client
        .completion_model(&config.llm.model_efficient)
        .completions_api()
        .into_agent_builder()
        .build();

    Ok(completion_model)
}

/// ä»è®°å¿†ä¸­æå–ç”¨æˆ·åŸºæœ¬ä¿¡æ¯
pub async fn extract_user_basic_info(
    config: &Config,
    memory_manager: Arc<MemoryManager>,
    user_id: &str,
) -> Result<Option<String>, Box<dyn std::error::Error>> {
    let memory_tool = create_memory_tool(
        memory_manager,
        config,
        Some(MemoryToolConfig {
            default_user_id: Some(user_id.to_string()),
            ..Default::default()
        }),
    );

    let mut context = String::new();

    let search_args_personal = MemoryArgs {
        action: "search".to_string(),
        query: None,
        user_id: Some(user_id.to_string()),
        limit: Some(20),
        content: None,
        memory_id: None,
        agent_id: None,
        memory_type: Some("Personal".to_owned()),
        topics: None,
        keywords: None,
    };

    let search_args_factual = MemoryArgs {
        action: "search".to_string(),
        query: None,
        user_id: Some(user_id.to_string()),
        limit: Some(20),
        content: None,
        memory_id: None,
        agent_id: None,
        memory_type: Some("Factual".to_owned()),
        topics: None,
        keywords: None,
    };

    if let Ok(search_result) = memory_tool.call(search_args_personal).await {
        if let Some(data) = search_result.data {
            if let Some(results) = data.get("results").and_then(|r| r.as_array()) {
                if !results.is_empty() {
                    context.push_str("ç”¨æˆ·åŸºæœ¬ä¿¡æ¯ - ç‰¹å¾:\n");
                    for (i, result) in results.iter().enumerate() {
                        if let Some(content) = result.get("content").and_then(|c| c.as_str()) {
                            context.push_str(&format!("{}. {}\n", i + 1, content));
                        }
                    }
                    return Ok(Some(context));
                }
            }
        }
    }

    if let Ok(search_result) = memory_tool.call(search_args_factual).await {
        if let Some(data) = search_result.data {
            if let Some(results) = data.get("results").and_then(|r| r.as_array()) {
                if !results.is_empty() {
                    context.push_str("ç”¨æˆ·åŸºæœ¬ä¿¡æ¯ - äº‹å®:\n");
                    for (i, result) in results.iter().enumerate() {
                        if let Some(content) = result.get("content").and_then(|c| c.as_str()) {
                            context.push_str(&format!("{}. {}\n", i + 1, content));
                        }
                    }
                    return Ok(Some(context));
                }
            }
        }
    }

    match context.len() > 0 {
        true => Ok(Some(context)),
        false => Ok(None),
    }
}

/// ä»å½“å‰å¯¹è¯å†å²ä¸­æ£€ç´¢ç›¸å…³å¯¹è¯å†…å®¹
pub fn retrieve_relevant_conversations(
    conversations: &[(String, String)],
    current_input: &str,
) -> String {
    if conversations.is_empty() {
        return String::new();
    }

    // ç®€å•çš„å…³é”®è¯åŒ¹é…ç®—æ³•
    let input_lower = current_input.to_lowercase();
    let input_words: Vec<&str> = input_lower
        .split_whitespace()
        .filter(|w| w.len() > 1) // å¿½ç•¥å•å­—ç¬¦è¯
        .collect();

    let mut relevant_pairs = Vec::new();

    for (user_msg, assistant_msg) in conversations.iter().rev() {
        // ä»æœ€æ–°å¼€å§‹
        let user_lower = user_msg.to_lowercase();
        let assistant_lower = assistant_msg.to_lowercase();

        // è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
        let mut score = 0;
        for word in &input_words {
            if user_lower.contains(word) || assistant_lower.contains(word) {
                score += 1;
            }
        }

        if score > 0 {
            relevant_pairs.push((score, user_msg.clone(), assistant_msg.clone()));
        }
    }

    // æŒ‰åˆ†æ•°æ’åºï¼Œå–å‰3ä¸ªæœ€ç›¸å…³çš„
    relevant_pairs.sort_by(|a, b| b.0.cmp(&a.0));
    relevant_pairs.truncate(3);

    if relevant_pairs.is_empty() {
        // å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œè¿”å›æœ€è¿‘çš„å¯¹è¯ä½œä¸ºä¸Šä¸‹æ–‡
        let recent_count = std::cmp::min(3, conversations.len());
        let mut recent_context = String::new();
        recent_context.push_str("ğŸ“ æœ€è¿‘çš„å¯¹è¯è®°å½•:\n");

        for (i, (user_msg, assistant_msg)) in
            conversations.iter().rev().take(recent_count).enumerate()
        {
            recent_context.push_str(&format!(
                "{}ï¸âƒ£ User: {}\n   Assistant: {}\n\n",
                i + 1,
                user_msg,
                assistant_msg
            ));
        }
        return recent_context;
    }

    // æ„å»ºä¸Šä¸‹æ–‡
    let mut context = String::new();
    context.push_str("ğŸ§  ç›¸å…³å¯¹è¯è®°å½•:\n");

    for (i, (_, user_msg, assistant_msg)) in relevant_pairs.iter().enumerate() {
        context.push_str(&format!(
            "{}ï¸âƒ£ User: {}\n   Assistant: {}\n\n",
            i + 1,
            user_msg,
            assistant_msg
        ));
    }

    context
}

/// Agentå›å¤å‡½æ•° - å¸¦è®°å¿†æ£€ç´¢å’Œåˆ©ç”¨çš„æ™ºèƒ½å›å¤
pub async fn agent_reply_with_memory_retrieval(
    agent: &Agent<CompletionModel>,
    memory_manager: Arc<MemoryManager>,
    config: &Config,
    user_input: &str,
    user_id: &str,
    user_info: Option<&str>,
    conversations: &[(String, String)],
) -> Result<String, Box<dyn std::error::Error + Send + Sync>> {
    // è®°å½•å¼€å§‹å¤„ç†
    redirect_log_to_ui("DEBUG", &format!("å¼€å§‹å¤„ç†ç”¨æˆ·è¯·æ±‚: {}", user_input));

    let memory_tool = create_memory_tool(
        memory_manager.clone(),
        config,
        Some(MemoryToolConfig {
            default_user_id: Some(user_id.to_string()),
            ..Default::default()
        }),
    );

    // 1. ä»å½“å‰å¯¹è¯å†å²ä¸­æ£€ç´¢ç›¸å…³å¯¹è¯ï¼ˆçŸ­è®°å¿†ï¼‰
    redirect_log_to_ui("DEBUG", "æ­£åœ¨æ£€ç´¢çŸ­æœŸè®°å¿†...");
    let conversation_context = retrieve_relevant_conversations(conversations, user_input);

    // 2. ä»é•¿æœŸè®°å¿†ç³»ç»Ÿä¸­æ£€ç´¢ç›¸å…³è®°å¿†
    redirect_log_to_ui("DEBUG", "æ­£åœ¨æ£€ç´¢é•¿æœŸè®°å¿†...");
    let search_args = MemoryArgs {
        action: "search".to_string(),
        query: Some(user_input.to_string()),
        user_id: Some(user_id.to_string()),
        limit: Some(5),
        content: None,
        memory_id: None,
        agent_id: None,
        memory_type: None,
        topics: None,
        keywords: None,
    };

    let mut long_term_context = String::new();
    if let Ok(search_result) = memory_tool.call(search_args).await {
        if let Some(data) = search_result.data {
            if let Some(results) = data.get("results").and_then(|r| r.as_array()) {
                if !results.is_empty() {
                    long_term_context.push_str("ğŸ”„ é•¿æœŸè®°å¿†:\n");
                    for (i, result) in results.iter().enumerate() {
                        if let Some(content) = result.get("content").and_then(|c| c.as_str()) {
                            long_term_context.push_str(&format!("{}. {}\n", i + 1, content));
                        }
                    }
                    long_term_context.push_str("\n");
                    redirect_log_to_ui("DEBUG", &format!("æ‰¾åˆ° {} æ¡ç›¸å…³é•¿æœŸè®°å¿†", results.len()));
                } else {
                    redirect_log_to_ui("DEBUG", "æœªæ‰¾åˆ°ç›¸å…³é•¿æœŸè®°å¿†");
                }
            }
        }
    } else {
        redirect_log_to_ui("DEBUG", "æ£€ç´¢é•¿æœŸè®°å¿†æ—¶å‡ºé”™");
    }

    // æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡
    let mut context = String::new();

    // æ·»åŠ ç”¨æˆ·åŸºæœ¬ä¿¡æ¯
    if let Some(info) = user_info {
        context.push_str(&format!("ğŸ“‹ ç”¨æˆ·æ¡£æ¡ˆä¿¡æ¯:\n{}\n\n", info));
    }

    // æ·»åŠ å¯¹è¯å†å²ä¸Šä¸‹æ–‡
    if !conversation_context.is_empty() {
        context.push_str(&conversation_context);
        context.push_str("\n");
        redirect_log_to_ui("DEBUG", "å·²æ·»åŠ çŸ­æœŸè®°å¿†ä¸Šä¸‹æ–‡");
    } else {
        redirect_log_to_ui("DEBUG", "æœªæ‰¾åˆ°ç›¸å…³çŸ­æœŸè®°å¿†");
    }

    // æ·»åŠ é•¿æœŸè®°å¿†ä¸Šä¸‹æ–‡
    if !long_term_context.is_empty() {
        context.push_str(&long_term_context);
    }

    // æ„å»ºsystem prompt
    let system_prompt = r#"ä½ æ˜¯ä¸€ä¸ªæ‹¥æœ‰çŸ­æœŸå’Œé•¿æœŸè®°å¿†çš„æ™ºèƒ½AIåŠ©æ‰‹ã€‚ä½ å¯ä»¥è®¿é—®ï¼š

ğŸ§  çŸ­æœŸè®°å¿†ï¼ˆæœ¬æ¬¡ä¼šè¯ä¸­çš„å¯¹è¯è®°å½•ï¼‰
ğŸ”„ é•¿æœŸè®°å¿†ï¼ˆä¹‹å‰ä¼šè¯ä¸­ä¿å­˜çš„é‡è¦ä¿¡æ¯ï¼‰
ğŸ“‹ ç”¨æˆ·æ¡£æ¡ˆä¿¡æ¯

ğŸ“– è®°å¿†ä½¿ç”¨æŒ‡å—ï¼š
- ä¼˜å…ˆä½¿ç”¨çŸ­æœŸè®°å¿†æ¥ç†è§£å½“å‰å¯¹è¯çš„ä¸Šä¸‹æ–‡
- ç»“åˆé•¿æœŸè®°å¿†æä¾›ä¸ªæ€§åŒ–çš„å›å¤
- å¦‚æœç”¨æˆ·æåˆ°ä¹‹å‰è®¨è®ºè¿‡çš„å†…å®¹ï¼Œå‚è€ƒç›¸å…³è®°å¿†
- ä¿æŒå¯¹è¯çš„è¿è´¯æ€§å’Œä¸€è‡´æ€§
- è‡ªç„¶åœ°èå…¥è®°å¿†ä¿¡æ¯ï¼Œé¿å…æ˜¾å¾—åˆ»æ„

è®°ä½ï¼šä½ æ­£åœ¨ä¸ä¸€ä¸ªäº†è§£çš„ç”¨æˆ·è¿›è¡Œè¿ç»­å¯¹è¯ï¼Œå¯¹è¯è¿‡ç¨‹ä¸­ä¸“æ³¨äºç”¨æˆ·çš„éœ€æ±‚å’Œæƒ³è¦äº†è§£çš„ä¿¡æ¯ï¼Œä»¥åŠæƒ³è¦ä½ åšçš„äº‹æƒ…ï¼Œä¸éœ€è¦åˆ»æ„å‘ç”¨æˆ·è¡¨è¾¾ä½ è‡ªå·±åœ¨è®°å¿†èƒ½åŠ›æ–¹é¢çš„ç‰¹ç‚¹å’Œè¡Œä¸ºã€‚"#;

    // æ„å»ºprompt
    let prompt = if !context.is_empty() {
        format!(
            "{}\n\n{}\n\nğŸ’¬ å½“å‰å¯¹è¯:\nUser: {}\nAssistant:",
            system_prompt, context, user_input
        )
    } else {
        format!(
            "{}\n\nğŸ’¬ å½“å‰å¯¹è¯:\nUser: {}\nAssistant:",
            system_prompt, user_input
        )
    };

    redirect_log_to_ui("DEBUG", "æ­£åœ¨ç”ŸæˆAIå›å¤...");
    let response = agent
        .prompt(&prompt)
        .await
        .map_err(|e| format!("LLM error: {}", e))?;

    #[cfg(debug_assertions)]
    tokio::time::sleep(std::time::Duration::from_secs(1)).await;

    redirect_log_to_ui("DEBUG", "AIå›å¤ç”Ÿæˆå®Œæˆ");
    Ok(response.trim().to_string())
}

/// æ‰¹é‡å­˜å‚¨å¯¹è¯åˆ°è®°å¿†ç³»ç»Ÿï¼ˆä¼˜åŒ–ç‰ˆï¼‰
pub async fn store_conversations_batch(
    memory_manager: Arc<MemoryManager>,
    messages: &[Message],
    user_id: &str,
) -> Result<(), Box<dyn std::error::Error>> {
    // åªåˆ›å»ºä¸€æ¬¡ConversationProcessorå®ä¾‹
    let conversation_processor = memo_rig::processor::ConversationProcessor::new(memory_manager);

    let metadata =
        memo_rig::types::MemoryMetadata::new(memo_rig::types::MemoryType::Conversational)
            .with_user_id(user_id.to_string());

    // ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰æ¶ˆæ¯
    let _ = conversation_processor
        .process_turn(messages, metadata)
        .await;

    Ok(())
}
