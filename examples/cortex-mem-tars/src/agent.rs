use anyhow::Result;
use chrono::{DateTime, Local};
use cortex_mem_rig::create_memory_tools_with_tenant_and_vector;
use cortex_mem_tools::MemoryOperations;
use futures::StreamExt;
use rig::agent::MultiTurnStreamItem;
use rig::{
    agent::Agent as RigAgent,
    client::CompletionClient,
    completion::Message,
    message::Text,
    providers::openai::{Client, CompletionModel},
    streaming::StreamingChat,
};
use std::sync::Arc;
use tokio::sync::mpsc;

/// æ¶ˆæ¯è§’è‰²
#[derive(Debug, Clone, PartialEq)]
pub enum MessageRole {
    User,
    Assistant,
}

/// èŠå¤©æ¶ˆæ¯
#[derive(Debug, Clone)]
pub struct ChatMessage {
    pub role: MessageRole,
    pub content: String,
    pub timestamp: DateTime<Local>,
}

impl ChatMessage {
    pub fn new(role: MessageRole, content: String) -> Self {
        Self {
            role,
            content,
            timestamp: Local::now(),
        }
    }

    pub fn user(content: impl Into<String>) -> Self {
        Self::new(MessageRole::User, content.into())
    }

    pub fn assistant(content: impl Into<String>) -> Self {
        Self::new(MessageRole::Assistant, content.into())
    }
}

/// åˆ›å»ºå¸¦è®°å¿†åŠŸèƒ½çš„Agentï¼ˆOpenViking é£æ ¼ + ç§Ÿæˆ·éš”ç¦»ï¼‰
/// è¿”å› (Agent, MemoryOperations) ä»¥ä¾¿å¤–éƒ¨ä½¿ç”¨ç§Ÿæˆ·éš”ç¦»çš„ operations
pub async fn create_memory_agent(
    data_dir: impl AsRef<std::path::Path>,
    config: &cortex_mem_config::Config,
    user_info: Option<&str>,
    bot_system_prompt: Option<&str>,
    agent_id: &str,
    user_id: &str,  // ğŸ”§ ç§»é™¤ä¸‹åˆ’çº¿å‰ç¼€
) -> Result<(RigAgent<CompletionModel>, Arc<MemoryOperations>), Box<dyn std::error::Error>> {
    // åˆ›å»º cortex LLMClient ç”¨äº L0/L1 ç”Ÿæˆ
    let llm_config = cortex_mem_core::llm::LLMConfig {
        api_base_url: config.llm.api_base_url.clone(),
        api_key: config.llm.api_key.clone(),
        model_efficient: config.llm.model_efficient.clone(),
        temperature: 0.1,
        max_tokens: 4096,
    };
    let cortex_llm_client: Arc<dyn cortex_mem_core::llm::LLMClient> =
        Arc::new(cortex_mem_core::llm::LLMClientImpl::new(llm_config)?);

    // ä½¿ç”¨å‘é‡æœç´¢ç‰ˆæœ¬ï¼ˆå”¯ä¸€æ”¯æŒçš„ç‰ˆæœ¬ï¼‰
    tracing::info!("ğŸ” ä½¿ç”¨å‘é‡æœç´¢åŠŸèƒ½");
    tracing::info!("Embedding é…ç½®: model={}, dim={:?}", config.embedding.model_name, config.qdrant.embedding_dim);
    let memory_tools = create_memory_tools_with_tenant_and_vector(
        data_dir,
        agent_id,
        cortex_llm_client,
        &config.qdrant.url,
        &config.qdrant.collection_name,
        &config.embedding.api_base_url,
        &config.embedding.api_key,
        &config.embedding.model_name,
        config.qdrant.embedding_dim,
        Some(user_id.to_string()),  // ğŸ†• ä¼ é€’çœŸå®çš„user_id
    )
    .await?;

    // è·å–ç§Ÿæˆ· operations ç”¨äºå¤–éƒ¨ä½¿ç”¨
    let tenant_operations = memory_tools.operations().clone();

    // åˆ›å»º Rig LLM å®¢æˆ·ç«¯ç”¨äº Agent å¯¹è¯
    let llm_client = Client::builder(&config.llm.api_key)
        .base_url(&config.llm.api_base_url)
        .build();

    // æ„å»º system promptï¼ˆOpenViking é£æ ¼ï¼‰
    let base_system_prompt = if let Some(info) = user_info {
        format!(
            r#"ä½ æ˜¯ä¸€ä¸ªæ‹¥æœ‰åˆ†å±‚è®°å¿†åŠŸèƒ½çš„æ™ºèƒ½ AI åŠ©æ‰‹ã€‚

æ­¤ä¼šè¯å‘ç”Ÿçš„åˆå§‹æ—¶é—´ï¼š{current_time}

ä½ çš„ Bot IDï¼š{bot_id}

è®°å¿†å·¥å…·è¯´æ˜ï¼ˆOpenViking é£æ ¼åˆ†å±‚è®¿é—®ï¼‰ï¼š

ğŸ”‘ **URI æ ¼å¼è§„èŒƒï¼ˆéå¸¸é‡è¦ï¼ï¼‰**
- æ‰€æœ‰ URI å¿…é¡»ä½¿ç”¨ `cortex://` å‰ç¼€ï¼Œ**ç¦æ­¢ä½¿ç”¨ `memory://`**
- âœ… æ­£ç¡®ç¤ºä¾‹ï¼š`cortex://user/tars_user/`
- âŒ é”™è¯¯ç¤ºä¾‹ï¼š`memory://me/SkyronJ/`ï¼ˆå¸¸è§é”™è¯¯ï¼ï¼‰

ğŸ“ URI è·¯å¾„ç»“æ„ï¼š
- `cortex://user/{{user_id}}/` - ç”¨æˆ·è®°å¿†ç›®å½•
- `cortex://user/{{user_id}}/profile.json` - ç”¨æˆ·æ¡£æ¡ˆ
- `cortex://agent/{{agent_id}}/` - Agent è®°å¿†ç›®å½•
- `cortex://session/{{session_id}}/` - ç‰¹å®šä¼šè¯
- `cortex://resources/` - çŸ¥è¯†åº“

ğŸ” æœç´¢å·¥å…·ï¼š
- search(query, options): æ™ºèƒ½æœç´¢è®°å¿†
  - return_layers: ["L0"] (é»˜è®¤) | ["L0", "L1"] | ["L0", "L1", "L2"]
  - scope: æœç´¢èŒƒå›´ï¼ˆå¯é€‰ï¼‰
    * å¯ä»¥æŒ‡å®šæœç´¢èŒƒå›´ï¼š
      - "cortex://user/" - ç”¨æˆ·è®°å¿†
      - "cortex://agent/" - Agent è®°å¿†
      - "cortex://session/{{session_id}}/" - ç‰¹å®šä¼šè¯
      - "cortex://resources/" - çŸ¥è¯†åº“
  - ç¤ºä¾‹ï¼šsearch(query="Python è£…é¥°å™¨", return_layers=["L0"])

- find(query): å¿«é€ŸæŸ¥æ‰¾ï¼Œè¿”å› L0 æ‘˜è¦
  - è‡ªåŠ¨åœ¨è®°å¿†ç©ºé—´ä¸­æœç´¢
  - ä¾‹å¦‚ï¼šfind(query="ç”¨æˆ·åå¥½")

ğŸ“– åˆ†å±‚è®¿é—®å·¥å…·ï¼ˆæŒ‰éœ€åŠ è½½ï¼‰ï¼š
- abstract(uri): è·å– L0 æ‘˜è¦ï¼ˆ~100 tokensï¼‰- å¿«é€Ÿåˆ¤æ–­ç›¸å…³æ€§
  - ç¤ºä¾‹ï¼šabstract(uri="cortex://user/tars_user/")
- overview(uri): è·å– L1 æ¦‚è§ˆï¼ˆ~2000 tokensï¼‰- ç†è§£æ ¸å¿ƒä¿¡æ¯
  - ç¤ºä¾‹ï¼šoverview(uri="cortex://session/abc123/")
- read(uri): è·å– L2 å®Œæ•´å†…å®¹ - ä»…åœ¨å¿…é¡»äº†è§£è¯¦ç»†ä¿¡æ¯æ—¶ä½¿ç”¨

ğŸ“‚ æ–‡ä»¶ç³»ç»Ÿå·¥å…·ï¼š
- ls(uri, options): åˆ—å‡ºç›®å½•å†…å®¹
  - include_abstracts: æ˜¯å¦åŒ…å«æ–‡ä»¶æ‘˜è¦
  - ç”¨äºæµè§ˆè®°å¿†ç»“æ„
  - âœ… ç¤ºä¾‹ï¼šls(uri="cortex://user/tars_user/")
  - âŒ é”™è¯¯ï¼šls(uri="memory://me/SkyronJ/")

âš ï¸ **å¸¸è§é”™è¯¯æé†’**ï¼š
- ä¸è¦ä½¿ç”¨ `memory://` å‰ç¼€ï¼Œå¿…é¡»ç”¨ `cortex://`
- user_id æ˜¯åˆ†é…çš„ç”¨æˆ·æ ‡è¯†ç¬¦ï¼Œä¸æ˜¯"me"æˆ–ç”¨æˆ·å
- è®¿é—®ç”¨æˆ·è®°å¿†ç”¨ `cortex://user/{{user_id}}/`ï¼Œä¸æ˜¯ `cortex://me/`

ğŸ“ **ä¸»åŠ¨å¬å›åŸåˆ™**ï¼ˆå…³é”®ï¼‰ï¼š
å½“ç”¨æˆ·çš„é—®é¢˜å¯èƒ½æ¶‰åŠå†å²ä¿¡æ¯ã€ç”¨æˆ·åå¥½æˆ–ä¹‹å‰çš„å¯¹è¯å†…å®¹æ—¶ï¼Œä½ å¿…é¡»**ä¸»åŠ¨**è°ƒç”¨è®°å¿†å·¥å…·ã€‚

**å¿…é¡»ä¸»åŠ¨æœç´¢çš„åœºæ™¯**ï¼š
- ç”¨æˆ·é—®"ä½ è®°å¾—...å—ï¼Ÿ"ã€"å‘Šè¯‰æˆ‘ä½ éƒ½è®°å¾—ä»€ä¹ˆï¼Ÿ" â†’ ç«‹å³è°ƒç”¨ search æˆ– ls
- ç”¨æˆ·æåˆ°äººåã€åœ°ç‚¹ã€äº‹ä»¶ã€é¡¹ç›®å â†’ ç«‹å³è°ƒç”¨ search(query="äººå/äº‹ä»¶") æŸ¥æ‰¾ç›¸å…³è®°å¿†
- ç”¨æˆ·è¯¢é—®å†å²å¯¹è¯ã€ä¹‹å‰çš„è®¨è®º â†’ ç«‹å³è°ƒç”¨ search æˆ– find
- ç”¨æˆ·çš„é—®é¢˜æ¶‰åŠç”¨æˆ·åå¥½ã€ä¹ æƒ¯ã€èƒŒæ™¯ â†’ ç«‹å³è°ƒç”¨ search æŸ¥æ‰¾ç”¨æˆ·è®°å¿†
- ä½ ä¸ç¡®å®šå¦‚ä½•å›ç­”ï¼Œæˆ–æ„Ÿè§‰è®°å¿†ä¸­å¯èƒ½æœ‰ç›¸å…³ä¿¡æ¯ â†’ å…ˆè°ƒç”¨ search ç¡®è®¤

**æœç´¢ç­–ç•¥**ï¼š
1. ä¼˜å…ˆä½¿ç”¨ search æŸ¥æ‰¾ç›¸å…³è®°å¿†ï¼Œé»˜è®¤åªè¿”å› L0 æ‘˜è¦
2. æ ¹æ® L0 æ‘˜è¦åˆ¤æ–­ç›¸å…³æ€§ï¼Œéœ€è¦æ›´å¤šä¿¡æ¯æ—¶è°ƒç”¨ overview è·å– L1
3. ä»…åœ¨å¿…é¡»äº†è§£å®Œæ•´ç»†èŠ‚æ—¶è°ƒç”¨ read è·å– L2
4. è¿™ç§æ¸è¿›å¼åŠ è½½å¯ä»¥å¤§å¹…å‡å°‘ token æ¶ˆè€—ï¼ˆèŠ‚çœ 80-90%ï¼‰

è®°å¿†éš”ç¦»è¯´æ˜ï¼š
- æ¯ä¸ª Bot æ‹¥æœ‰ç‹¬ç«‹çš„ç§Ÿæˆ·ç©ºé—´ï¼ˆç‰©ç†éš”ç¦»ï¼‰
- è®°å¿†ç»„ç»‡é‡‡ç”¨ OpenViking æ¶æ„ï¼š
  - cortex://resources/ - çŸ¥è¯†åº“
  - cortex://user/ - ç”¨æˆ·è®°å¿†
  - cortex://agent/ - Agent è®°å¿†
  - cortex://session/ - ä¼šè¯è®°å½•
- å¯¹è¯å†…å®¹ä¼šè‡ªåŠ¨ä¿å­˜åˆ° sessionï¼Œä½ æ— éœ€å…³å¿ƒå­˜å‚¨

ç”¨æˆ·åŸºæœ¬ä¿¡æ¯ï¼š
{info}

é‡è¦æŒ‡ä»¤ï¼š
- ä½ æ˜¯ä¸€ä¸ª**ä¸»åŠ¨**ä½¿ç”¨è®°å¿†çš„ AI åŠ©æ‰‹ï¼Œä¸è¦ç­‰å¾…ç”¨æˆ·æ˜ç¡®è¯´"æœç´¢"æ‰å»æŸ¥æ‰¾è®°å¿†ï¼
- é‡åˆ°ä»»ä½•å¯èƒ½æ¶‰åŠå†å²ä¿¡æ¯çš„é—®é¢˜ï¼Œ**å…ˆæœç´¢ï¼Œå†å›ç­”**
- è‡ªç„¶åœ°èå…¥è®°å¿†ä¿¡æ¯ï¼Œé¿å…ç”Ÿç¡¬åœ°è¯´"æ ¹æ®è®°å¿†..."
- å¦‚æœæœç´¢åæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œè¯šå®å‘ŠçŸ¥ç”¨æˆ·
"#,
            current_time = chrono::Local::now().format("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S"),
            bot_id = agent_id,
            info = info
        )
    } else {
        format!(
            r#"ä½ æ˜¯ä¸€ä¸ªæ‹¥æœ‰åˆ†å±‚è®°å¿†åŠŸèƒ½çš„æ™ºèƒ½ AI åŠ©æ‰‹ã€‚

æ­¤ä¼šè¯å‘ç”Ÿçš„åˆå§‹æ—¶é—´ï¼š{current_time}

ä½ çš„ Bot IDï¼š{bot_id}

è®°å¿†å·¥å…·è¯´æ˜ï¼ˆOpenViking é£æ ¼åˆ†å±‚è®¿é—®ï¼‰ï¼š

ğŸ”‘ **URI æ ¼å¼è§„èŒƒï¼ˆéå¸¸é‡è¦ï¼ï¼‰**
- æ‰€æœ‰ URI å¿…é¡»ä½¿ç”¨ `cortex://` å‰ç¼€ï¼Œ**ç¦æ­¢ä½¿ç”¨ `memory://`**
- âœ… æ­£ç¡®ç¤ºä¾‹ï¼š`cortex://user/tars_user/`
- âŒ é”™è¯¯ç¤ºä¾‹ï¼š`memory://me/SkyronJ/`ï¼ˆå¸¸è§é”™è¯¯ï¼ï¼‰

ğŸ“ URI è·¯å¾„ç»“æ„ï¼š
- `cortex://user/{{user_id}}/` - ç”¨æˆ·è®°å¿†ç›®å½•
- `cortex://user/{{user_id}}/profile.json` - ç”¨æˆ·æ¡£æ¡ˆ
- `cortex://agent/{{agent_id}}/` - Agent è®°å¿†ç›®å½•
- `cortex://session/{{session_id}}/` - ç‰¹å®šä¼šè¯
- `cortex://resources/` - çŸ¥è¯†åº“

ğŸ” æœç´¢å·¥å…·ï¼š
- search(query, options): æ™ºèƒ½æœç´¢è®°å¿†
  - return_layers: ["L0"] (é»˜è®¤) | ["L0", "L1"] | ["L0", "L1", "L2"]
  - scope: æœç´¢èŒƒå›´ï¼ˆå¯é€‰ï¼‰
  - ç¤ºä¾‹ï¼šsearch(query="Python è£…é¥°å™¨", return_layers=["L0"])

- find(query): å¿«é€ŸæŸ¥æ‰¾ï¼Œè¿”å› L0 æ‘˜è¦
  - è‡ªåŠ¨åœ¨è®°å¿†ç©ºé—´ä¸­æœç´¢
  - ä¾‹å¦‚ï¼šfind(query="ç”¨æˆ·åå¥½")

ğŸ“– åˆ†å±‚è®¿é—®å·¥å…·ï¼ˆæŒ‰éœ€åŠ è½½ï¼‰ï¼š
- abstract(uri): L0 æ‘˜è¦ï¼ˆ~100 tokensï¼‰- å¿«é€Ÿåˆ¤æ–­ç›¸å…³æ€§
  - ç¤ºä¾‹ï¼šabstract(uri="cortex://user/tars_user/")
- overview(uri): L1 æ¦‚è§ˆï¼ˆ~2000 tokensï¼‰- ç†è§£æ ¸å¿ƒä¿¡æ¯
  - ç¤ºä¾‹ï¼šoverview(uri="cortex://session/abc123/")
- read(uri): L2 å®Œæ•´å†…å®¹ - ä»…åœ¨å¿…è¦æ—¶ä½¿ç”¨

ğŸ“‚ æ–‡ä»¶ç³»ç»Ÿå·¥å…·ï¼š
- ls(uri): åˆ—å‡ºç›®å½•å†…å®¹
  - âœ… ç¤ºä¾‹ï¼šls(uri="cortex://user/tars_user/")
  - âŒ é”™è¯¯ï¼šls(uri="memory://me/SkyronJ/")

âš ï¸ **å¸¸è§é”™è¯¯æé†’**ï¼š
- ä¸è¦ä½¿ç”¨ `memory://` å‰ç¼€ï¼Œå¿…é¡»ç”¨ `cortex://`
- user_id æ˜¯åˆ†é…çš„ç”¨æˆ·æ ‡è¯†ç¬¦ï¼Œä¸æ˜¯"me"æˆ–ç”¨æˆ·å
- è®¿é—®ç”¨æˆ·è®°å¿†ç”¨ `cortex://user/{{user_id}}/`ï¼Œä¸æ˜¯ `cortex://me/`

ğŸ“ **ä¸»åŠ¨å¬å›åŸåˆ™**ï¼ˆå…³é”®ï¼‰ï¼š
å½“ç”¨æˆ·çš„é—®é¢˜å¯èƒ½æ¶‰åŠå†å²ä¿¡æ¯ã€ç”¨æˆ·åå¥½æˆ–ä¹‹å‰çš„å¯¹è¯å†…å®¹æ—¶ï¼Œä½ å¿…é¡»**ä¸»åŠ¨**è°ƒç”¨è®°å¿†å·¥å…·ã€‚

**å¿…é¡»ä¸»åŠ¨æœç´¢çš„åœºæ™¯**ï¼š
- ç”¨æˆ·é—®"ä½ è®°å¾—...å—ï¼Ÿ"ã€"å‘Šè¯‰æˆ‘ä½ éƒ½è®°å¾—ä»€ä¹ˆï¼Ÿ" â†’ ç«‹å³è°ƒç”¨ search æˆ– ls
- ç”¨æˆ·æåˆ°äººåã€åœ°ç‚¹ã€äº‹ä»¶ã€é¡¹ç›®å â†’ ç«‹å³è°ƒç”¨ search(query="äººå/äº‹ä»¶") æŸ¥æ‰¾
- ç”¨æˆ·è¯¢é—®å†å²å¯¹è¯ã€ä¹‹å‰çš„è®¨è®º â†’ ç«‹å³è°ƒç”¨ search æˆ– find
- ä½ ä¸ç¡®å®šå¦‚ä½•å›ç­” â†’ å…ˆè°ƒç”¨ search ç¡®è®¤è®°å¿†ä¸­æ˜¯å¦æœ‰ç›¸å…³ä¿¡æ¯

**æœç´¢ç­–ç•¥**ï¼š
1. ä¼˜å…ˆä½¿ç”¨ searchï¼Œé»˜è®¤è¿”å› L0 æ‘˜è¦
2. æ ¹æ® L0 åˆ¤æ–­ç›¸å…³æ€§ï¼Œéœ€è¦æ—¶è°ƒç”¨ overview è·å– L1
3. ä»…åœ¨å¿…é¡»æ—¶è°ƒç”¨ read è·å– L2 å®Œæ•´å†…å®¹
4. æ¸è¿›å¼åŠ è½½å¯èŠ‚çœ 80-90% token

é‡è¦æŒ‡ä»¤ï¼š
- ä½ æ˜¯ä¸€ä¸ª**ä¸»åŠ¨**ä½¿ç”¨è®°å¿†çš„ AI åŠ©æ‰‹ï¼Œä¸è¦ç­‰å¾…ç”¨æˆ·æ˜ç¡®è¯´"æœç´¢"æ‰å»æŸ¥æ‰¾è®°å¿†ï¼
- é‡åˆ°ä»»ä½•å¯èƒ½æ¶‰åŠå†å²ä¿¡æ¯çš„é—®é¢˜ï¼Œ**å…ˆæœç´¢ï¼Œå†å›ç­”**
- å¯¹è¯å†…å®¹ä¼šè‡ªåŠ¨ä¿å­˜åˆ° sessionï¼Œä½ æ— éœ€å…³å¿ƒå­˜å‚¨

è®°å¿†éš”ç¦»è¯´æ˜ï¼š
- æ¯ä¸ª Bot æ‹¥æœ‰ç‹¬ç«‹çš„ç§Ÿæˆ·ç©ºé—´ï¼ˆç‰©ç†éš”ç¦»ï¼‰
- ä½ çš„è®°å¿†ä¸ä¼šä¸å…¶ä»– Bot å…±äº«
"#,
            current_time = chrono::Local::now().format("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S"),
            bot_id = agent_id
        )
    };

    // è¿½åŠ æœºå™¨äººç³»ç»Ÿæç¤ºè¯
    let system_prompt = if let Some(bot_prompt) = bot_system_prompt {
        format!("{}\n\nä½ çš„è§’è‰²è®¾å®šï¼š\n{}", base_system_prompt, bot_prompt)
    } else {
        base_system_prompt
    };

    // æ„å»ºå¸¦æœ‰ OpenViking é£æ ¼è®°å¿†å·¥å…·çš„ agent
    let completion_model = llm_client
        .completion_model(&config.llm.model_efficient)
        .completions_api()
        .into_agent_builder()
        .preamble(&system_prompt)
        // æœç´¢å·¥å…·ï¼ˆæœ€å¸¸ç”¨ï¼‰
        .tool(memory_tools.search_tool())
        .tool(memory_tools.find_tool())
        // åˆ†å±‚è®¿é—®å·¥å…·
        .tool(memory_tools.abstract_tool())
        .tool(memory_tools.overview_tool())
        .tool(memory_tools.read_tool())
        // æ–‡ä»¶ç³»ç»Ÿå·¥å…·
        .tool(memory_tools.ls_tool())
        .build();

    Ok((completion_model, tenant_operations))
}

/// ä»è®°å¿†ä¸­æå–ç”¨æˆ·åŸºæœ¬ä¿¡æ¯
pub async fn extract_user_basic_info(
    operations: Arc<MemoryOperations>,
    user_id: &str,
    _agent_id: &str,
) -> Result<Option<String>, Box<dyn std::error::Error>> {
    use cortex_mem_core::FilesystemOperations;

    // ç›´æ¥è¯»å– profile.json æ–‡ä»¶
    let profile_uri = format!("cortex://user/{}/profile.json", user_id);

    match operations.filesystem().read(&profile_uri).await {
        Ok(json_str) => {
            let profile: serde_json::Value = serde_json::from_str(&json_str)?;

            let mut context = String::new();
            context.push_str("## ç”¨æˆ·è®°å¿†\n\n");

            let categories = vec![
                ("personal_info", "ä¸ªäººä¿¡æ¯"),
                ("work_history", "å·¥ä½œç»å†"),
                ("preferences", "åå¥½ä¹ æƒ¯"),
                ("relationships", "äººé™…å…³ç³»"),
                ("goals", "ç›®æ ‡æ„¿æ™¯"),
            ];

            let mut total_count = 0;
            for (key, label) in categories {
                if let Some(items) = profile.get(key).and_then(|v| v.as_array()) {
                    if !items.is_empty() {
                        context.push_str(&format!("### {}\n", label));
                        for item in items {
                            if let Some(content) = item.get("content").and_then(|v| v.as_str()) {
                                context.push_str(&format!("- {}\n", content));
                                total_count += 1;
                            }
                        }
                        context.push_str("\n");
                    }
                }
            }

            if total_count == 0 {
                tracing::info!("Profile exists but empty for user: {}", user_id);
                return Ok(None);
            }

            tracing::info!(
                "Loaded {} user memory items from profile.json for user: {}",
                total_count,
                user_id
            );
            Ok(Some(context))
        }
        Err(e) => {
            tracing::info!("No user profile found for user {}: {}", user_id, e);
            Ok(None)
        }
    }
}

/// Agentå¤šè½®å¯¹è¯å¤„ç†å™¨ - æ”¯æŒæµå¼è¾“å‡ºå’Œå¤šè½®å·¥å…·è°ƒç”¨
pub struct AgentChatHandler {
    agent: RigAgent<CompletionModel>,
    history: Vec<ChatMessage>,
    operations: Option<Arc<MemoryOperations>>,
    session_id: String,
}

impl AgentChatHandler {
    pub fn new(agent: RigAgent<CompletionModel>) -> Self {
        Self {
            agent,
            history: Vec::new(),
            operations: None,
            session_id: uuid::Uuid::new_v4().to_string(),
        }
    }

    /// Create with memory operations for auto-saving conversations
    pub fn with_memory(
        agent: RigAgent<CompletionModel>,
        operations: Arc<MemoryOperations>,
        session_id: String,
    ) -> Self {
        Self {
            agent,
            history: Vec::new(),
            operations: Some(operations),
            session_id,
        }
    }

    #[allow(dead_code)]
    pub fn history(&self) -> &[ChatMessage] {
        &self.history
    }

    /// è¿›è¡Œå¯¹è¯ï¼ˆæµå¼ç‰ˆæœ¬ï¼Œæ”¯æŒå¤šè½®å·¥å…·è°ƒç”¨ï¼‰
    pub async fn chat_stream(
        &mut self,
        user_input: &str,
    ) -> Result<mpsc::Receiver<String>, anyhow::Error> {
        self.history.push(ChatMessage::user(user_input));

        let chat_history: Vec<Message> = self
            .history
            .iter()
            .filter_map(|msg| match msg.role {
                MessageRole::User => Some(Message::User {
                    content: rig::OneOrMany::one(rig::completion::message::UserContent::Text(
                        Text {
                            text: msg.content.clone(),
                        },
                    )),
                }),
                MessageRole::Assistant => Some(Message::Assistant {
                    id: None,
                    content: rig::OneOrMany::one(rig::completion::message::AssistantContent::Text(
                        Text {
                            text: msg.content.clone(),
                        },
                    )),
                }),
            })
            .collect();

        let prompt_message = Message::User {
            content: rig::OneOrMany::one(rig::completion::message::UserContent::Text(Text {
                text: user_input.to_string(),
            })),
        };

        let (tx, rx) = mpsc::channel(100);

        let agent = self.agent.clone();
        let user_input_clone = user_input.to_string();
        let ops_clone = self.operations.clone();
        let session_id_clone = self.session_id.clone();

        tokio::spawn(async move {
            let mut full_response = String::new();

            let mut stream = agent
                .stream_chat(prompt_message, chat_history)
                .multi_turn(20)
                .await;

            while let Some(item) = stream.next().await {
                match item {
                    Ok(stream_item) => {
                        match stream_item {
                            MultiTurnStreamItem::StreamItem(content) => {
                                use rig::streaming::StreamedAssistantContent;
                                match content {
                                    StreamedAssistantContent::Text(text_content) => {
                                        let text = &text_content.text;
                                        full_response.push_str(text);
                                        if tx.send(text.clone()).await.is_err() {
                                            break;
                                        }
                                    }
                                    StreamedAssistantContent::ToolCall(_) => {
                                        log::debug!("è°ƒç”¨å·¥å…·ä¸­...");
                                    }
                                    _ => {}
                                }
                            }
                            MultiTurnStreamItem::FinalResponse(final_resp) => {
                                full_response = final_resp.response().to_string();
                                let _ = tx.send(full_response.clone()).await;
                                break;
                            }
                            _ => {
                                log::debug!("æ”¶åˆ°å…¶ä»–ç±»å‹çš„æµå¼é¡¹ç›®");
                            }
                        }
                    }
                    Err(e) => {
                        log::error!("æµå¼å¤„ç†é”™è¯¯: {:?}", e);
                        let error_msg = format!("[é”™è¯¯: {}]", e);
                        let _ = tx.send(error_msg).await;
                        break;
                    }
                }
            }

            // å¯¹è¯ç»“æŸåè‡ªåŠ¨ä¿å­˜åˆ° session
            if let Some(ops) = ops_clone {
                if !user_input_clone.is_empty() {
                    let user_store = cortex_mem_tools::StoreArgs {
                        content: user_input_clone.clone(),
                        thread_id: session_id_clone.clone(),
                        scope: "session".to_string(),
                        metadata: None,
                        auto_generate_layers: Some(true),
                        user_id: None,
                        agent_id: None,
                    };
                    if let Err(e) = ops.store(user_store).await {
                        tracing::warn!("Failed to save user message: {}", e);
                    }
                }

                if !full_response.is_empty() {
                    let assistant_store = cortex_mem_tools::StoreArgs {
                        content: full_response.clone(),
                        thread_id: session_id_clone.clone(),
                        scope: "session".to_string(),
                        metadata: None,
                        auto_generate_layers: Some(true),
                        user_id: None,
                        agent_id: None,
                    };
                    if let Err(e) = ops.store(assistant_store).await {
                        tracing::warn!("Failed to save assistant message: {}", e);
                    }
                }
            }
        });

        Ok(rx)
    }

    /// è¿›è¡Œå¯¹è¯ï¼ˆéæµå¼ç‰ˆæœ¬ï¼‰
    #[allow(dead_code)]
    pub async fn chat(&mut self, user_input: &str) -> Result<String, anyhow::Error> {
        let mut rx = self.chat_stream(user_input).await?;
        let mut response = String::new();

        while let Some(chunk) = rx.recv().await {
            response.push_str(&chunk);
        }

        self.history.push(ChatMessage::assistant(response.clone()));

        Ok(response)
    }
}