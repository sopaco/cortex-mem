use anyhow::Result;
use chrono::{DateTime, Local};
use cortex_mem_tools::MemoryOperations;
use cortex_mem_rig::{create_memory_tools_with_tenant, create_memory_tools_with_tenant_and_llm};
use futures::StreamExt;
use rig::{
    agent::Agent as RigAgent,
    client::CompletionClient,
    providers::openai::{Client, CompletionModel},
    completion::Message,
    streaming::StreamingChat,
    message::Text,
};
use rig::agent::MultiTurnStreamItem;
use std::sync::Arc;
use tokio::sync::mpsc;

/// æ¶ˆæ¯è§’è‰²
#[derive(Debug, Clone, PartialEq)]
pub enum MessageRole {
    User,
    Assistant,
}

/// èŠå¤©æ¶ˆæ¯
#[derive(Debug, Clone)]
pub struct ChatMessage {
    pub role: MessageRole,
    pub content: String,
    pub timestamp: DateTime<Local>,
}

impl ChatMessage {
    pub fn new(role: MessageRole, content: String) -> Self {
        Self {
            role,
            content,
            timestamp: Local::now(),
        }
    }

    pub fn user(content: impl Into<String>) -> Self {
        Self::new(MessageRole::User, content.into())
    }

    pub fn assistant(content: impl Into<String>) -> Self {
        Self::new(MessageRole::Assistant, content.into())
    }
}

/// åˆ›å»ºå¸¦è®°å¿†åŠŸèƒ½çš„Agentï¼ˆOpenViking é£æ ¼ + ç§Ÿæˆ·éš”ç¦»ï¼‰
pub async fn create_memory_agent(
    data_dir: impl AsRef<std::path::Path>,
    api_base_url: &str,
    api_key: &str,
    model: &str,
    user_info: Option<&str>,
    bot_system_prompt: Option<&str>,
    agent_id: &str,
    _user_id: &str,
) -> Result<RigAgent<CompletionModel>, Box<dyn std::error::Error>> {
    // åˆ›å»º cortex LLMClient ç”¨äº L0/L1 ç”Ÿæˆ
    let llm_config = cortex_mem_core::llm::LLMConfig {
        api_base_url: api_base_url.to_string(),
        api_key: api_key.to_string(),
        model_efficient: model.to_string(),
        temperature: 0.1,
        max_tokens: 4096,
    };
    let cortex_llm_client: Arc<dyn cortex_mem_core::llm::LLMClient> = 
        Arc::new(cortex_mem_core::llm::LLMClientImpl::new(llm_config)?);
    
    // åˆ›å»ºç§Ÿæˆ·å·¥å…·ï¼ˆagent_id ä½œä¸º tenant_idï¼‰+ LLM æ”¯æŒ
    let memory_tools = create_memory_tools_with_tenant_and_llm(
        data_dir, 
        agent_id,
        cortex_llm_client,
    ).await?;
    
    // åˆ›å»º Rig LLM å®¢æˆ·ç«¯ç”¨äº Agent å¯¹è¯
    let llm_client = Client::builder(api_key)
        .base_url(api_base_url)
        .build();

    // æ„å»º system promptï¼ˆOpenViking é£æ ¼ï¼‰
    let base_system_prompt = if let Some(info) = user_info {
        format!(r#"ä½ æ˜¯ä¸€ä¸ªæ‹¥æœ‰åˆ†å±‚è®°å¿†åŠŸèƒ½çš„æ™ºèƒ½ AI åŠ©æ‰‹ã€‚

æ­¤ä¼šè¯å‘ç”Ÿçš„åˆå§‹æ—¶é—´ï¼š{current_time}

ä½ çš„ Bot IDï¼š{bot_id}

è®°å¿†å·¥å…·è¯´æ˜ï¼ˆOpenViking é£æ ¼åˆ†å±‚è®¿é—®ï¼‰ï¼š

ğŸ” æœç´¢å·¥å…·ï¼š
- search(query, options): æ™ºèƒ½æœç´¢è®°å¿†
  - engine: "keyword"ï¼ˆé»˜è®¤ï¼‰| "vector" | "hybrid"
  - return_layers: ["L0"] (é»˜è®¤) | ["L0", "L1"] | ["L0", "L1", "L2"]
  - scope: æœç´¢èŒƒå›´ï¼ˆå¯é€‰ï¼‰
    * å¯ä»¥æŒ‡å®šæœç´¢èŒƒå›´ï¼š
      - "cortex://user/memories/" - ç”¨æˆ·è®°å¿†
      - "cortex://agent/memories/" - Agent è®°å¿†
      - "cortex://session/{{session_id}}/" - ç‰¹å®šä¼šè¯
      - "cortex://resources/" - çŸ¥è¯†åº“
  - ç¤ºä¾‹ï¼šsearch(query="Python è£…é¥°å™¨", return_layers=["L0"])

- find(query): å¿«é€ŸæŸ¥æ‰¾ï¼Œè¿”å› L0 æ‘˜è¦
  - è‡ªåŠ¨åœ¨è®°å¿†ç©ºé—´ä¸­æœç´¢
  - ä¾‹å¦‚ï¼šfind(query="ç”¨æˆ·åå¥½")

ğŸ“– åˆ†å±‚è®¿é—®å·¥å…·ï¼ˆæŒ‰éœ€åŠ è½½ï¼‰ï¼š
- abstract(uri): è·å– L0 æ‘˜è¦ï¼ˆ~100 tokensï¼‰- å¿«é€Ÿåˆ¤æ–­ç›¸å…³æ€§
- overview(uri): è·å– L1 æ¦‚è§ˆï¼ˆ~2000 tokensï¼‰- ç†è§£æ ¸å¿ƒä¿¡æ¯
- read(uri): è·å– L2 å®Œæ•´å†…å®¹ - ä»…åœ¨å¿…é¡»äº†è§£è¯¦ç»†ä¿¡æ¯æ—¶ä½¿ç”¨

ğŸ“‚ æ–‡ä»¶ç³»ç»Ÿå·¥å…·ï¼š
- ls(uri, options): åˆ—å‡ºç›®å½•å†…å®¹
  - include_abstracts: æ˜¯å¦åŒ…å«æ–‡ä»¶æ‘˜è¦
  - ç”¨äºæµè§ˆè®°å¿†ç»“æ„

ğŸ’¾ å­˜å‚¨å·¥å…·ï¼š
- store(content): å­˜å‚¨æ–°å†…å®¹åˆ°è®°å¿†ç©ºé—´ï¼Œè‡ªåŠ¨ç”Ÿæˆ L0/L1 æ‘˜è¦
  - å†…å®¹ä¼šè‡ªåŠ¨å­˜å‚¨åˆ°ä¼šè¯ä¸­
  - è‡ªåŠ¨ç”Ÿæˆåˆ†å±‚æ‘˜è¦

ä½¿ç”¨ç­–ç•¥ï¼ˆé‡è¦ï¼‰ï¼š
1. ä¼˜å…ˆä½¿ç”¨ search æŸ¥æ‰¾ç›¸å…³è®°å¿†ï¼Œé»˜è®¤åªè¿”å› L0 æ‘˜è¦
2. æ ¹æ® L0 æ‘˜è¦åˆ¤æ–­ç›¸å…³æ€§ï¼Œéœ€è¦æ›´å¤šä¿¡æ¯æ—¶è°ƒç”¨ overview è·å– L1
3. ä»…åœ¨å¿…é¡»äº†è§£å®Œæ•´ç»†èŠ‚æ—¶è°ƒç”¨ read è·å– L2
4. è¿™ç§æ¸è¿›å¼åŠ è½½å¯ä»¥å¤§å¹…å‡å°‘ token æ¶ˆè€—ï¼ˆèŠ‚çœ 80-90%ï¼‰
5. é‡è¦ä¿¡æ¯è‡ªåŠ¨ä½¿ç”¨ store å­˜å‚¨

è®°å¿†éš”ç¦»è¯´æ˜ï¼š
- æ¯ä¸ª Bot æ‹¥æœ‰ç‹¬ç«‹çš„ç§Ÿæˆ·ç©ºé—´ï¼ˆç‰©ç†éš”ç¦»ï¼‰
- è®°å¿†ç»„ç»‡é‡‡ç”¨ OpenViking æ¶æ„ï¼š
  - cortex://resources/ - çŸ¥è¯†åº“
  - cortex://user/ - ç”¨æˆ·è®°å¿†
  - cortex://agent/ - Agent è®°å¿†
  - cortex://session/ - ä¼šè¯è®°å½•

ç”¨æˆ·åŸºæœ¬ä¿¡æ¯ï¼š
{info}

é‡è¦æŒ‡ä»¤ï¼š
- å¯¹è¯å†å²å°†ä½œä¸ºä¸Šä¸‹æ–‡æä¾›ï¼Œè¯·ä½¿ç”¨è¿™äº›ä¿¡æ¯æ¥ç†è§£å½“å‰çš„å¯¹è¯æµç¨‹
- è‡ªç„¶åœ°èå…¥è®°å¿†ä¿¡æ¯ï¼Œé¿å…åˆ»æ„å¤è¿°ï¼Œå…³æ³¨å½“å‰ä¼šè¯å†…å®¹
- ä¸“æ³¨äºç”¨æˆ·çš„éœ€æ±‚å’Œæƒ³è¦äº†è§£çš„ä¿¡æ¯
"#,
            current_time = chrono::Local::now().format("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S"),
            bot_id = agent_id,
            info = info)
    } else {
        format!(r#"ä½ æ˜¯ä¸€ä¸ªæ‹¥æœ‰åˆ†å±‚è®°å¿†åŠŸèƒ½çš„æ™ºèƒ½ AI åŠ©æ‰‹ã€‚

æ­¤ä¼šè¯å‘ç”Ÿçš„åˆå§‹æ—¶é—´ï¼š{current_time}

ä½ çš„ Bot IDï¼š{bot_id}

è®°å¿†å·¥å…·è¯´æ˜ï¼ˆOpenViking é£æ ¼åˆ†å±‚è®¿é—®ï¼‰ï¼š

ğŸ” æœç´¢å·¥å…·ï¼š
- search(query, options): æ™ºèƒ½æœç´¢è®°å¿†
  - engine: "keyword"ï¼ˆé»˜è®¤ï¼‰| "vector" | "hybrid"
  - return_layers: ["L0"] (é»˜è®¤) | ["L0", "L1"] | ["L0", "L1", "L2"]
  - scope: æœç´¢èŒƒå›´ï¼ˆå¯é€‰ï¼‰
  - ç¤ºä¾‹ï¼šsearch(query="Python è£…é¥°å™¨", return_layers=["L0"])

- find(query): å¿«é€ŸæŸ¥æ‰¾ï¼Œè¿”å› L0 æ‘˜è¦
  - è‡ªåŠ¨åœ¨è®°å¿†ç©ºé—´ä¸­æœç´¢
  - ä¾‹å¦‚ï¼šfind(query="ç”¨æˆ·åå¥½")

ğŸ“– åˆ†å±‚è®¿é—®å·¥å…·ï¼ˆæŒ‰éœ€åŠ è½½ï¼‰ï¼š
- abstract(uri): L0 æ‘˜è¦ï¼ˆ~100 tokensï¼‰- å¿«é€Ÿåˆ¤æ–­ç›¸å…³æ€§
- overview(uri): L1 æ¦‚è§ˆï¼ˆ~2000 tokensï¼‰- ç†è§£æ ¸å¿ƒä¿¡æ¯
- read(uri): L2 å®Œæ•´å†…å®¹ - ä»…åœ¨å¿…è¦æ—¶ä½¿ç”¨

ğŸ“‚ æ–‡ä»¶ç³»ç»Ÿå·¥å…·ï¼š
- ls(uri): åˆ—å‡ºç›®å½•å†…å®¹

ğŸ’¾ å­˜å‚¨å·¥å…·ï¼š
- store(content): å­˜å‚¨æ–°å†…å®¹åˆ°ä½ çš„è®°å¿†ç©ºé—´

ä½¿ç”¨ç­–ç•¥ï¼š
1. ä¼˜å…ˆä½¿ç”¨ searchï¼Œé»˜è®¤è¿”å› L0 æ‘˜è¦
2. æ ¹æ® L0 åˆ¤æ–­ç›¸å…³æ€§ï¼Œéœ€è¦æ—¶è°ƒç”¨ overview è·å– L1
3. ä»…åœ¨å¿…é¡»æ—¶è°ƒç”¨ read è·å– L2 å®Œæ•´å†…å®¹
4. æ¸è¿›å¼åŠ è½½å¯èŠ‚çœ 80-90% token

è®°å¿†éš”ç¦»è¯´æ˜ï¼š
- æ¯ä¸ª Bot æ‹¥æœ‰ç‹¬ç«‹çš„ç§Ÿæˆ·ç©ºé—´ï¼ˆç‰©ç†éš”ç¦»ï¼‰
- ä½ çš„è®°å¿†ä¸ä¼šä¸å…¶ä»– Bot å…±äº«
"#,
            current_time = chrono::Local::now().format("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S"),
            bot_id = agent_id)
    };

    // è¿½åŠ æœºå™¨äººç³»ç»Ÿæç¤ºè¯
    let system_prompt = if let Some(bot_prompt) = bot_system_prompt {
        format!("{}\n\nä½ çš„è§’è‰²è®¾å®šï¼š\n{}", base_system_prompt, bot_prompt)
    } else {
        base_system_prompt
    };

    // æ„å»ºå¸¦æœ‰æ–°çš„ OpenViking é£æ ¼è®°å¿†å·¥å…·çš„ agent
    let completion_model = llm_client
        .completion_model(model)
        .completions_api()
        .into_agent_builder()
        .preamble(&system_prompt)
        // ==================== æ–°çš„ OpenViking é£æ ¼å·¥å…· ====================
        // æœç´¢å·¥å…·ï¼ˆæœ€å¸¸ç”¨ï¼‰
        .tool(memory_tools.search_tool())
        .tool(memory_tools.find_tool())
        // åˆ†å±‚è®¿é—®å·¥å…·
        .tool(memory_tools.abstract_tool())
        .tool(memory_tools.overview_tool())
        .tool(memory_tools.read_tool())
        // æ–‡ä»¶ç³»ç»Ÿå·¥å…·
        .tool(memory_tools.ls_tool())
        // å­˜å‚¨å·¥å…·
        .tool(memory_tools.store_tool())
        .build();

    Ok(completion_model)
}

/// ä»è®°å¿†ä¸­æå–ç”¨æˆ·åŸºæœ¬ä¿¡æ¯ï¼ˆä½¿ç”¨æ–°çš„ search å·¥å…·ï¼‰
pub async fn extract_user_basic_info(
    operations: Arc<MemoryOperations>,
    user_id: &str,
    _agent_id: &str,
) -> Result<Option<String>, Box<dyn std::error::Error>> {
    // ä½¿ç”¨æ–°çš„ search å·¥å…·æŸ¥æ‰¾ç”¨æˆ·ç›¸å…³ä¿¡æ¯
    let search_args = cortex_mem_tools::SearchArgs {
        query: format!("ç”¨æˆ· {} çš„åŸºæœ¬ä¿¡æ¯", user_id),
        engine: Some("keyword".to_string()),
        recursive: Some(true),
        return_layers: Some(vec!["L1".to_string()]),  // è·å– L1 æ¦‚è§ˆ
        scope: Some(format!("cortex://threads")),
        limit: Some(10),
    };

    match operations.search(search_args).await {
        Ok(response) => {
            if response.results.is_empty() {
                return Ok(None);
            }

            let mut context = String::new();
            context.push_str("ç”¨æˆ·ç›¸å…³ä¿¡æ¯:\n");

            for (i, result) in response.results.iter().enumerate() {
                if let Some(overview) = &result.overview_text {
                    context.push_str(&format!("{}. {}\n", i + 1, overview));
                }
            }

            Ok(Some(context))
        }
        Err(e) => {
            tracing::warn!("Failed to extract user info: {}", e);
            Ok(None)
        }
    }
}

/// Agentå¤šè½®å¯¹è¯å¤„ç†å™¨ - æ”¯æŒæµå¼è¾“å‡ºå’Œå¤šè½®å·¥å…·è°ƒç”¨
pub struct AgentChatHandler {
    agent: RigAgent<CompletionModel>,
    history: Vec<ChatMessage>,
}

impl AgentChatHandler {
    pub fn new(agent: RigAgent<CompletionModel>) -> Self {
        Self {
            agent,
            history: Vec::new(),
        }
    }

    pub fn history(&self) -> &[ChatMessage] {
        &self.history
    }

    /// è¿›è¡Œå¯¹è¯ï¼ˆæµå¼ç‰ˆæœ¬ï¼Œæ”¯æŒå¤šè½®å·¥å…·è°ƒç”¨ï¼‰
    pub async fn chat_stream(
        &mut self,
        user_input: &str,
    ) -> Result<mpsc::Receiver<String>, anyhow::Error> {
        // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        self.history.push(ChatMessage::user(user_input));

        // æ„å»ºå¯¹è¯å†å² - è½¬æ¢ä¸º Rig Message æ ¼å¼
        let chat_history: Vec<Message> = self
            .history
            .iter()
            .filter_map(|msg| match msg.role {
                MessageRole::User => Some(Message::User {
                    content: rig::OneOrMany::one(rig::completion::message::UserContent::Text(Text {
                        text: msg.content.clone(),
                    })),
                }),
                MessageRole::Assistant => Some(Message::Assistant {
                    id: None,
                    content: rig::OneOrMany::one(rig::completion::message::AssistantContent::Text(Text {
                        text: msg.content.clone(),
                    })),
                }),
            })
            .collect();

        // è·å–å½“å‰ç”¨æˆ·è¾“å…¥ï¼ˆæœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼‰
        let prompt_message = Message::User {
            content: rig::OneOrMany::one(rig::completion::message::UserContent::Text(Text {
                text: user_input.to_string(),
            })),
        };

        // åˆ›å»ºé€šé“ç”¨äºå‘é€æµå¼å†…å®¹
        let (tx, rx) = mpsc::channel(100);

        // å…‹éš† agent ç”¨äºå¼‚æ­¥ä»»åŠ¡
        let agent = self.agent.clone();

        // åœ¨åå°ä»»åŠ¡ä¸­å¤„ç†æµå¼å“åº”
        tokio::spawn(async move {
            let mut full_response = String::new();

            // ä½¿ç”¨ stream_chat + multi_turn æ”¯æŒå·¥å…·è°ƒç”¨ï¼ˆRig 0.23 é£æ ¼ï¼‰
            let mut stream = agent
                .stream_chat(prompt_message, chat_history)
                .multi_turn(20)  // æ”¯æŒæœ€å¤š 20 è½®å·¥å…·è°ƒç”¨
                .await;
                
            // å¤„ç†æµå¼å“åº”
            while let Some(item) = stream.next().await {
                match item {
                    Ok(stream_item) => {
                        match stream_item {
                            MultiTurnStreamItem::StreamItem(content) => {
                                use rig::streaming::StreamedAssistantContent;
                                match content {
                                    StreamedAssistantContent::Text(text_content) => {
                                        let text = &text_content.text;
                                        full_response.push_str(text);
                                        
                                        // å‘é€æµå¼å†…å®¹
                                        if tx.send(text.clone()).await.is_err() {
                                            break;
                                        }
                                    }
                                    StreamedAssistantContent::ToolCall(_) => {
                                        // å·¥å…·è°ƒç”¨ï¼Œå¯ä»¥é€‰æ‹©æ˜¾ç¤º
                                        log::debug!("è°ƒç”¨å·¥å…·ä¸­...");
                                    }
                                    _ => {}
                                }
                            }
                            MultiTurnStreamItem::FinalResponse(final_resp) => {
                                // æœ€ç»ˆå“åº”
                                full_response = final_resp.response().to_string();
                                let _ = tx.send(full_response.clone()).await;
                                break;
                            }
                            _ => {
                                // å…¶ä»–ç±»å‹çš„æµå¼é¡¹ç›®
                                log::debug!("æ”¶åˆ°å…¶ä»–ç±»å‹çš„æµå¼é¡¹ç›®");
                            }
                        }
                    }
                    Err(e) => {
                        log::error!("æµå¼å¤„ç†é”™è¯¯: {:?}", e);
                        let error_msg = format!("[é”™è¯¯: {}]", e);
                        let _ = tx.send(error_msg).await;
                        break;
                    }
                }
            }
        });

        Ok(rx)
    }

    /// è¿›è¡Œå¯¹è¯ï¼ˆéæµå¼ç‰ˆæœ¬ï¼‰
    pub async fn chat(
        &mut self,
        user_input: &str,
    ) -> Result<String, anyhow::Error> {
        let mut rx = self.chat_stream(user_input).await?;
        let mut response = String::new();

        while let Some(chunk) = rx.recv().await {
            response.push_str(&chunk);
        }

        // æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
        self.history.push(ChatMessage::assistant(response.clone()));

        Ok(response)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_chat_message() {
        let msg = ChatMessage::user("Hello");
        assert_eq!(msg.role, MessageRole::User);
        assert_eq!(msg.content, "Hello");
    }
}
