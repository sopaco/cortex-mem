use anyhow::Result;
use chrono::{DateTime, Local};
use cortex_mem_tools::MemoryOperations;
use cortex_mem_rig::create_memory_tools;
use rig::{
    agent::Agent as RigAgent,
    client::CompletionClient,
    providers::openai::{Client, CompletionModel},
    completion::Prompt,
};
use std::sync::Arc;

/// æ¶ˆæ¯è§’è‰²
#[derive(Debug, Clone, PartialEq)]
pub enum MessageRole {
    User,
    Assistant,
}

/// èŠå¤©æ¶ˆæ¯
#[derive(Debug, Clone)]
pub struct ChatMessage {
    pub role: MessageRole,
    pub content: String,
    pub timestamp: DateTime<Local>,
}

impl ChatMessage {
    pub fn new(role: MessageRole, content: String) -> Self {
        Self {
            role,
            content,
            timestamp: Local::now(),
        }
    }

    pub fn user(content: impl Into<String>) -> Self {
        Self::new(MessageRole::User, content.into())
    }

    pub fn assistant(content: impl Into<String>) -> Self {
        Self::new(MessageRole::Assistant, content.into())
    }
}

/// åˆ›å»ºå¸¦è®°å¿†åŠŸèƒ½çš„Agentï¼ˆOpenViking é£æ ¼ï¼‰
pub async fn create_memory_agent(
    operations: Arc<MemoryOperations>,
    api_base_url: &str,
    api_key: &str,
    model: &str,
    user_info: Option<&str>,
    bot_system_prompt: Option<&str>,
    _agent_id: &str,
    _user_id: &str,
) -> Result<RigAgent<CompletionModel>, Box<dyn std::error::Error>> {
    // åˆ›å»ºæ–°çš„ OpenViking é£æ ¼è®°å¿†å·¥å…·
    let memory_tools = create_memory_tools(operations.clone());

    let llm_client = Client::builder(api_key)
        .base_url(api_base_url)
        .build();

    // æ„å»º system promptï¼ˆOpenViking é£æ ¼ï¼‰
    let base_system_prompt = if let Some(info) = user_info {
        format!(r#"ä½ æ˜¯ä¸€ä¸ªæ‹¥æœ‰åˆ†å±‚è®°å¿†åŠŸèƒ½çš„æ™ºèƒ½ AI åŠ©æ‰‹ã€‚

æ­¤ä¼šè¯å‘ç”Ÿçš„åˆå§‹æ—¶é—´ï¼š{current_time}

è®°å¿†å·¥å…·è¯´æ˜ï¼ˆOpenViking é£æ ¼åˆ†å±‚è®¿é—®ï¼‰ï¼š

ğŸ” æœç´¢å·¥å…·ï¼š
- search(query, options): æ™ºèƒ½æœç´¢è®°å¿†
  - engine: "keyword"ï¼ˆé»˜è®¤ï¼‰| "vector" | "hybrid"
  - return_layers: ["L0"] (é»˜è®¤) | ["L0", "L1"] | ["L0", "L1", "L2"]
  - scope: æœç´¢èŒƒå›´ï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š
    * "cortex://threads" - æ‰€æœ‰å¯¹è¯çº¿ç¨‹ï¼ˆé»˜è®¤ï¼‰
    * "cortex://agents" - æ‰€æœ‰ Agent è®°å¿†
    * "cortex://users" - æ‰€æœ‰ç”¨æˆ·è®°å¿†
    * "cortex://global" - å…¨å±€å…±äº«è®°å¿†
    * "cortex://threads/thread_123" - ç‰¹å®šçº¿ç¨‹
  - ç¤ºä¾‹ï¼šsearch(query="Python è£…é¥°å™¨", return_layers=["L0"])

- find(query, scope): å¿«é€ŸæŸ¥æ‰¾ï¼Œè¿”å› L0 æ‘˜è¦
  - scope å‚æ•°åŒä¸Šï¼Œä¼šè‡ªåŠ¨ä¿®æ­£ä¸ºæœ‰æ•ˆçš„ dimension
  - ä¾‹å¦‚ï¼šfind(query="ç³»ç»ŸçŠ¶æ€", scope="cortex://threads")
  - æ³¨æ„ï¼šä¸è¦ä½¿ç”¨ "cortex://system" ç­‰æ— æ•ˆ dimension

ğŸ“– åˆ†å±‚è®¿é—®å·¥å…·ï¼ˆæŒ‰éœ€åŠ è½½ï¼‰ï¼š
- abstract(uri): è·å– L0 æ‘˜è¦ï¼ˆ~100 tokensï¼‰- å¿«é€Ÿåˆ¤æ–­ç›¸å…³æ€§
- overview(uri): è·å– L1 æ¦‚è§ˆï¼ˆ~2000 tokensï¼‰- ç†è§£æ ¸å¿ƒä¿¡æ¯
- read(uri): è·å– L2 å®Œæ•´å†…å®¹ - ä»…åœ¨å¿…é¡»äº†è§£è¯¦ç»†ä¿¡æ¯æ—¶ä½¿ç”¨

ğŸ“‚ æ–‡ä»¶ç³»ç»Ÿå·¥å…·ï¼š
- ls(uri, options): åˆ—å‡ºç›®å½•å†…å®¹
  - include_abstracts: æ˜¯å¦åŒ…å«æ–‡ä»¶æ‘˜è¦
  - ç”¨äºæµè§ˆè®°å¿†ç»“æ„

ğŸ’¾ å­˜å‚¨å·¥å…·ï¼š
- store(content, thread_id): å­˜å‚¨æ–°å†…å®¹ï¼Œè‡ªåŠ¨ç”Ÿæˆ L0/L1 æ‘˜è¦

ä½¿ç”¨ç­–ç•¥ï¼ˆé‡è¦ï¼‰ï¼š
1. ä¼˜å…ˆä½¿ç”¨ search æŸ¥æ‰¾ç›¸å…³è®°å¿†ï¼Œé»˜è®¤åªè¿”å› L0 æ‘˜è¦
2. æ ¹æ® L0 æ‘˜è¦åˆ¤æ–­ç›¸å…³æ€§ï¼Œéœ€è¦æ›´å¤šä¿¡æ¯æ—¶è°ƒç”¨ overview è·å– L1
3. ä»…åœ¨å¿…é¡»äº†è§£å®Œæ•´ç»†èŠ‚æ—¶è°ƒç”¨ read è·å– L2
4. è¿™ç§æ¸è¿›å¼åŠ è½½å¯ä»¥å¤§å¹…å‡å°‘ token æ¶ˆè€—ï¼ˆèŠ‚çœ 80-90%ï¼‰
5. é‡è¦ä¿¡æ¯è‡ªåŠ¨ä½¿ç”¨ store å­˜å‚¨

ç”¨æˆ·åŸºæœ¬ä¿¡æ¯ï¼š
{info}

é‡è¦æŒ‡ä»¤ï¼š
- å¯¹è¯å†å²å°†ä½œä¸ºä¸Šä¸‹æ–‡æä¾›ï¼Œè¯·ä½¿ç”¨è¿™äº›ä¿¡æ¯æ¥ç†è§£å½“å‰çš„å¯¹è¯æµç¨‹
- è‡ªç„¶åœ°èå…¥è®°å¿†ä¿¡æ¯ï¼Œé¿å…åˆ»æ„å¤è¿°ï¼Œå…³æ³¨å½“å‰ä¼šè¯å†…å®¹
- ä¸“æ³¨äºç”¨æˆ·çš„éœ€æ±‚å’Œæƒ³è¦äº†è§£çš„ä¿¡æ¯
"#,
            current_time = chrono::Local::now().format("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S"),
            info = info)
    } else {
        format!(r#"ä½ æ˜¯ä¸€ä¸ªæ‹¥æœ‰åˆ†å±‚è®°å¿†åŠŸèƒ½çš„æ™ºèƒ½ AI åŠ©æ‰‹ã€‚

æ­¤ä¼šè¯å‘ç”Ÿçš„åˆå§‹æ—¶é—´ï¼š{current_time}

è®°å¿†å·¥å…·è¯´æ˜ï¼ˆOpenViking é£æ ¼åˆ†å±‚è®¿é—®ï¼‰ï¼š

ğŸ” æœç´¢å·¥å…·ï¼š
- search(query, options): æ™ºèƒ½æœç´¢è®°å¿†
  - engine: "keyword"ï¼ˆé»˜è®¤ï¼‰| "vector" | "hybrid"
  - return_layers: ["L0"] (é»˜è®¤) | ["L0", "L1"] | ["L0", "L1", "L2"]
  - scope: æœç´¢èŒƒå›´ï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š
    * "cortex://threads" - æ‰€æœ‰å¯¹è¯çº¿ç¨‹ï¼ˆé»˜è®¤ï¼‰
    * "cortex://agents" - æ‰€æœ‰ Agent è®°å¿†
    * "cortex://users" - æ‰€æœ‰ç”¨æˆ·è®°å¿†
    * "cortex://global" - å…¨å±€å…±äº«è®°å¿†
  - ç¤ºä¾‹ï¼šsearch(query="Python è£…é¥°å™¨", return_layers=["L0"])

- find(query): å¿«é€ŸæŸ¥æ‰¾ï¼Œè¿”å› L0 æ‘˜è¦
  - è‡ªåŠ¨åœ¨ threads ç»´åº¦ä¸‹æœç´¢
  - ä¾‹å¦‚ï¼šfind(query="ç³»ç»ŸçŠ¶æ€")

ğŸ“– åˆ†å±‚è®¿é—®å·¥å…·ï¼ˆæŒ‰éœ€åŠ è½½ï¼‰ï¼š
- abstract(uri): L0 æ‘˜è¦ï¼ˆ~100 tokensï¼‰- å¿«é€Ÿåˆ¤æ–­ç›¸å…³æ€§
- overview(uri): L1 æ¦‚è§ˆï¼ˆ~2000 tokensï¼‰- ç†è§£æ ¸å¿ƒä¿¡æ¯
- read(uri): L2 å®Œæ•´å†…å®¹ - ä»…åœ¨å¿…è¦æ—¶ä½¿ç”¨

ğŸ“‚ æ–‡ä»¶ç³»ç»Ÿå·¥å…·ï¼š
- ls(uri): åˆ—å‡ºç›®å½•å†…å®¹

ğŸ’¾ å­˜å‚¨å·¥å…·ï¼š
- store(content, thread_id): å­˜å‚¨æ–°å†…å®¹

ä½¿ç”¨ç­–ç•¥ï¼š
1. ä¼˜å…ˆä½¿ç”¨ searchï¼Œé»˜è®¤è¿”å› L0 æ‘˜è¦
2. æ ¹æ® L0 åˆ¤æ–­ç›¸å…³æ€§ï¼Œéœ€è¦æ—¶è°ƒç”¨ overview è·å– L1
3. ä»…åœ¨å¿…é¡»æ—¶è°ƒç”¨ read è·å– L2 å®Œæ•´å†…å®¹
4. æ¸è¿›å¼åŠ è½½å¯èŠ‚çœ 80-90% token
"#,
            current_time = chrono::Local::now().format("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S"))
    };

    // è¿½åŠ æœºå™¨äººç³»ç»Ÿæç¤ºè¯
    let system_prompt = if let Some(bot_prompt) = bot_system_prompt {
        format!("{}\n\nä½ çš„è§’è‰²è®¾å®šï¼š\n{}", base_system_prompt, bot_prompt)
    } else {
        base_system_prompt
    };

    // æ„å»ºå¸¦æœ‰æ–°çš„ OpenViking é£æ ¼è®°å¿†å·¥å…·çš„ agent
    let completion_model = llm_client
        .completion_model(model)
        .completions_api()
        .into_agent_builder()
        .preamble(&system_prompt)
        // ==================== æ–°çš„ OpenViking é£æ ¼å·¥å…· ====================
        // æœç´¢å·¥å…·ï¼ˆæœ€å¸¸ç”¨ï¼‰
        .tool(memory_tools.search_tool())
        .tool(memory_tools.find_tool())
        // åˆ†å±‚è®¿é—®å·¥å…·
        .tool(memory_tools.abstract_tool())
        .tool(memory_tools.overview_tool())
        .tool(memory_tools.read_tool())
        // æ–‡ä»¶ç³»ç»Ÿå·¥å…·
        .tool(memory_tools.ls_tool())
        // å­˜å‚¨å·¥å…·
        .tool(memory_tools.store_tool())
        .build();

    Ok(completion_model)
}

/// ä»è®°å¿†ä¸­æå–ç”¨æˆ·åŸºæœ¬ä¿¡æ¯ï¼ˆä½¿ç”¨æ–°çš„ search å·¥å…·ï¼‰
pub async fn extract_user_basic_info(
    operations: Arc<MemoryOperations>,
    user_id: &str,
    _agent_id: &str,
) -> Result<Option<String>, Box<dyn std::error::Error>> {
    // ä½¿ç”¨æ–°çš„ search å·¥å…·æŸ¥æ‰¾ç”¨æˆ·ç›¸å…³ä¿¡æ¯
    let search_args = cortex_mem_tools::SearchArgs {
        query: format!("ç”¨æˆ· {} çš„åŸºæœ¬ä¿¡æ¯", user_id),
        engine: Some("keyword".to_string()),
        recursive: Some(true),
        return_layers: Some(vec!["L1".to_string()]),  // è·å– L1 æ¦‚è§ˆ
        scope: Some(format!("cortex://threads")),
        limit: Some(10),
    };

    match operations.search(search_args).await {
        Ok(response) => {
            if response.results.is_empty() {
                return Ok(None);
            }

            let mut context = String::new();
            context.push_str("ç”¨æˆ·ç›¸å…³ä¿¡æ¯:\n");

            for (i, result) in response.results.iter().enumerate() {
                if let Some(overview) = &result.overview_text {
                    context.push_str(&format!("{}. {}\n", i + 1, overview));
                }
            }

            Ok(Some(context))
        }
        Err(e) => {
            tracing::warn!("Failed to extract user info: {}", e);
            Ok(None)
        }
    }
}

/// Agentå¤šè½®å¯¹è¯å¤„ç†å™¨
pub struct AgentChatHandler {
    agent: RigAgent<CompletionModel>,
    history: Vec<ChatMessage>,
}

impl AgentChatHandler {
    pub fn new(agent: RigAgent<CompletionModel>) -> Self {
        Self {
            agent,
            history: Vec::new(),
        }
    }

    pub fn history(&self) -> &[ChatMessage] {
        &self.history
    }

    /// è¿›è¡Œå¯¹è¯ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œä½¿ç”¨ promptï¼‰
    pub async fn chat(
        &mut self,
        user_input: &str,
    ) -> Result<String, Box<dyn std::error::Error>> {
        // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        self.history.push(ChatMessage::user(user_input));

        // æ„å»ºå®Œæ•´çš„æç¤ºï¼ˆåŒ…å«å†å²ï¼‰
        let mut full_prompt = String::new();
        for msg in &self.history {
            match msg.role {
                MessageRole::User => full_prompt.push_str(&format!("User: {}\n", msg.content)),
                MessageRole::Assistant => full_prompt.push_str(&format!("Assistant: {}\n", msg.content)),
            }
        }
        full_prompt.push_str("Assistant: ");

        // ä½¿ç”¨ prompt è€Œä¸æ˜¯ chat
        let response = self.agent.prompt(&full_prompt).await?;

        // æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
        self.history.push(ChatMessage::assistant(response.clone()));

        Ok(response)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_chat_message() {
        let msg = ChatMessage::user("Hello");
        assert_eq!(msg.role, MessageRole::User);
        assert_eq!(msg.content, "Hello");
    }
}
