# System Boundary Interface Documentation

This document describes the system's external invocation interfaces, including CLI commands, API endpoints, configuration parameters, and other boundary mechanisms.

## Command Line Interface (CLI)

### cortex-mem-cli

**Description**: Main CLI interface for memory management operations

**Source File**: `cortex-mem-cli/src/main.rs`

**Arguments**:

- `command` (Commands): required - Subcommand to execute (add, delete, list, search)
- `config` (PathBuf): optional - Path to configuration file (default: `config.toml`)

**Usage Examples**:

```bash
cortex-mem-cli add --content "Meeting notes" --user-id user123
```

```bash
cortex-mem-cli search "project timeline" --user-id user123
```

```bash
cortex-mem-cli list --agent-id agent456 --limit 10
```

### cortex-mem-mcp

**Description**: MCP server for memory operations over stdio transport

**Source File**: `cortex-mem-mcp/src/main.rs`

**Arguments**:

- `config` (PathBuf): optional - Path to the TOML configuration file (default: `config.toml`)
- `agent` (String): optional - Optional agent identifier used for scoping memory operations

**Usage Examples**:

```bash
cortex-mem-mcp --config /path/to/config.toml
```

```bash
cortex-mem-mcp --agent agent123
```

### cortex-mem-tars

**Description**: Advanced TUI (Terminal User Interface) AI assistant with multi-agent management, persistent memory integration, and real-time API server

**Source File**: `examples/cortex-mem-tars/src/main.rs`

**Arguments**:

- `config` (PathBuf): optional - Configuration file path parameter (default: `config.toml`)
- `--enhance-memory-saver` (bool): optional - Enable enhanced memory saving, automatically saves conversations to memory on exit
- `--enable-audio-connect` (bool): optional - Enable audio connection feature, start API server for external integrations
- `--audio-connect-mode` (string): optional - Audio connection mode: "store" (store to memory system) or "chat" (inject as user input)

**Usage Examples**:

```bash
# Run with enhanced memory saving (saves conversations on exit)
cortex-mem-tars --enhance-memory-saver

# Run with API server enabled in store mode
cortex-mem-tars --enable-audio-connect --audio-connect-mode store

# Run with API server in chat mode
cortex-mem-tars --enable-audio-connect --audio-connect-mode chat

# Use custom config file
cortex-mem-tars --config config.prod.toml --enhance-memory-saver
```

**Key Features**:

- **Multi-Agent Management**: Create and manage multiple AI personas with distinct personalities, system prompts, and isolated memories
- **Persistent Role Memory**: Each agent maintains independent long-term memory through Cortex Memory integration
- **Memory Isolation**: Complete separation between agents and users to prevent cross-contamination
- **Modern TUI Experience**: 
  - Built with ratatui for polished terminal interface
  - 5 pre-built themes (Default, Dark, Forest, Ocean, Sunset)
  - Full Markdown support with syntax highlighting
  - Real-time streaming AI responses
  - Message export to clipboard (Ctrl+D)
   - **Extensible API Integration**: REST API server enabling external services to interact with memory system
   - **Store Mode**: External services store information directly to memory
   - **Chat Mode**: External messages injected as user input for AI processing
   - **Health Check**: Monitor API service status
   - **Memory Retrieval**: Query and list stored memories programmatically

#### Cortex TARS API Endpoints

The API server operates on a configurable port (default: 8080, overridable via `TARS_API_PORT` env var or `[api].port` in config).

##### Health Check
```bash
GET http://localhost:8080/api/memory/health
```

**Response**:
```json
{
  "status": "healthy",
  "timestamp": "2024-01-07T10:30:00Z"
}
```

##### Store Memory (Store Mode)
When `--audio-connect-mode=store`, external services can store information directly to the memory system:

```bash
POST http://localhost:8080/api/memory/store
Content-Type: application/json

{
  "content": "The user mentioned they prefer Rust over Python",
  "source": "audio_listener",
  "timestamp": "2024-01-07T10:30:00Z",
  "speaker_type": "user",
  "speaker_confidence": 0.95
}
```

**Request Fields**:
- `content` (string, required): Text content to store
- `source` (string, required): Must be "audio_listener"
- `timestamp` (string, required): ISO 8601 timestamp
- `speaker_type` (string, optional): "user" or "other"
- `speaker_confidence` (float, optional): 0-1 confidence score

##### Store Memory (Chat Mode)
When `--audio-connect-mode=chat`, external messages are treated as user input and trigger AI responses:

```bash
POST http://localhost:8080/api/memory/store
Content-Type: application/json

{
  "content": "Hello, how are you?",
  "source": "audio_listener",
  "timestamp": "2024-01-07T10:30:00Z"
}
```

The message is injected as if typed by the user, triggering AI response generation through the selected bot.

##### Retrieve Memories
Query memories with optional semantic search and filtering:

```bash
GET http://localhost:8080/api/memory/retrieve?query=user%20preferences&limit=5
```

**Query Parameters**:
- `query` (string, optional): Semantic search query
- `speaker_type` (string, optional): Filter by "user" or "other"
- `limit` (number, optional): Maximum number of results (default: 5)

##### List Memories
List memories with optional filtering and pagination:

```bash
GET http://localhost:8080/api/memory/list?speaker_type=user&limit=10
```

**Query Parameters**:
- `speaker_type` (string, optional): Filter by speaker type
- `limit` (number, optional): Maximum number of results (default: 10)
- `offset` (number, optional): Pagination offset

**Keyboard Shortcuts**:

| Key | Action |
|-----|--------|
| `Enter` | Send message |
| `Shift+Enter` | New line in input |
| `Ctrl+C` | Clear current session |
| `Ctrl+D` | Export conversation to clipboard |
| `Ctrl+H` | Show help modal |
| `Ctrl+T` | Open theme selector |
| `Ctrl+B` | Open bot management |
| `q` | Quit application (in bot selection) |
| `Esc` | Close modal / Return to previous state |

### cortex-mem-service

**Description**: HTTP service for memory operations

**Source File**: `cortex-mem-service/src/main.rs`

**Usage Examples**:

```bash
cortex-mem-service
```

## API Interfaces

### GET /health

**Description**: Health check endpoint that verifies the overall system health including vector store and LLM service

**Source File**: `cortex-mem-service/src/handlers.rs`

**Response Format**: Json<HealthResponse>

### POST /memories

**Description**: Creates a new memory with support for both simple content and conversation-based procedural memory

**Source File**: `cortex-mem-service/src/handlers.rs`

**Request Format**: Json<CreateMemoryRequest>

**Response Format**: Json<SuccessResponse>

### GET /memories/{id}

**Description**: Retrieves a specific memory by its ID

**Source File**: `cortex-mem-service/src/handlers.rs`

**Response Format**: Json<MemoryResponse>

### PUT /memories/{id}

**Description**: Updates an existing memory with new content

**Source File**: `cortex-mem-service/src/handlers.rs`

**Request Format**: Json<UpdateMemoryRequest>

**Response Format**: Json<SuccessResponse>

### DELETE /memories/{id}

**Description**: Deletes a memory by its ID

**Source File**: `cortex-mem-service/src/handlers.rs`

**Response Format**: Json<SuccessResponse>

### POST /search

**Description**: Searches memories using similarity matching with optional filters

**Source File**: `cortex-mem-service/src/handlers.rs`

**Request Format**: Json<SearchMemoryRequest>

**Response Format**: Json<SearchResponse>

### GET /memories

**Description**: Lists memories with optional filtering and pagination

**Source File**: `cortex-mem-service/src/handlers.rs`

**Request Format**: Query<ListMemoryQuery>

**Response Format**: Json<ListResponse>

### POST /batch-delete

**Description**: Performs batch deletion of multiple memories

**Source File**: `cortex-mem-service/src/handlers.rs`

**Request Format**: Json<BatchDeleteRequest>

**Response Format**: Json<BatchOperationResponse>

### POST /batch-update

**Description**: Performs batch update of multiple memories

**Source File**: `cortex-mem-service/src/handlers.rs`

**Request Format**: Json<BatchUpdateRequest>

**Response Format**: Json<BatchOperationResponse>

### POST /optimization

**Description**: Initiates a new optimization task with the specified parameters

**Source File**: `cortex-mem-service/src/optimization_handlers.rs`

**Request Format**: Json<StartOptimizationRequest>

**Response Format**: Json<OptimizationResponse>

### GET /optimization/{job_id}

**Description**: Retrieves the current status and progress of a specific optimization job

**Source File**: `cortex-mem-service/src/optimization_handlers.rs`

**Response Format**: Json<OptimizationResponse>

### POST /optimization/{job_id}/cancel

**Description**: Cancels a running optimization job if it hasn't completed

**Source File**: `cortex-mem-service/src/optimization_handlers.rs`

**Response Format**: Json<OptimizationResponse>

## Router Routes

### /

**Description**: Dashboard page component that manages dashboard state, loads data on mount, calculates derived metrics, handles errors with fallback data

**Source File**: `cortex-mem-insights/src/routes/+page.svelte`

### /optimization

**Description**: Optimization dashboard component that manages complete optimization lifecycle (initiation, execution, monitoring), provides UI for strategy selection and configuration

**Source File**: `cortex-mem-insights/src/routes/optimization/+page.svelte`

### /layout

**Description**: Layout component providing consistent structure across all pages, imports global styles, tracks current route path via $page store

**Source File**: `cortex-mem-insights/src/routes/+layout.svelte`

## Integration Suggestions

### API

Use the TypeScript client for seamless integration with the Cortex Memory Service API

**Example Code**:

```
import { cortexMemService } from './integrations/cortex-mem';\n\nconst client = new cortexMemService('http://localhost:8080');\nconst response = await client.listMemories({ user_id: 'user123', limit: 10 });
```

**Best Practices**:

- Use environment variables for API endpoints
- Implement proper error handling around API calls
- Cache responses when appropriate to reduce latency
- Use typed interfaces for type safety

### CLI

Integrate CLI commands into your deployment pipelines or scripts

**Example Code**:

```
#!/bin/bash\n# Script to backup memories regularly\nUSER_ID="${1:-user123}"\nBACKUP_DIR="/backups/memories/$(date +%Y%m%d)"\n\nmkdir -p "$BACKUP_DIR"\n\ncortex-mem-cli list --user-id "$USER_ID" --format json > "$BACKUP_DIR/memories.json"\necho "Backup completed: $BACKUP_DIR/memories.json"
```

**Best Practices**:

- Use configuration files for complex setups
- Implement logging in wrapper scripts
- Handle exit codes appropriately
- Use absolute paths in production environments

### Monitoring

Set up monitoring for system health and performance metrics

**Example Code**:

```
import { systemApi } from '$lib/api/client';\n\nsetInterval(async () => {\n  try {\n    const status = await systemApi.getStatus();\n    if (status.overall_status !== 'healthy') {\n      // Send alert or notification\n      console.error('System health degraded:', status);\n    }\n  } catch (error) {\n    console.error('Failed to check system status:', error);\n  }\n}, 30000); // Check every 30 seconds
```

**Best Practices**:

- Monitor both application and system metrics
- Set up alerts for critical failures
- Log monitoring data for trend analysis
- Use exponential backoff for retry logic


---

**Analysis Confidence**: 9.5/10
