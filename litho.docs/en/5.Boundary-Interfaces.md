# System Boundary Interface Documentation

This document describes the system's external invocation interfaces, including CLI commands, API endpoints, configuration parameters, and other boundary mechanisms.

## Command Line Interface (CLI)

### cortex-mem-cli

**Description**: CLI tool for managing memories and sessions

**Source File**: `cortex-mem-cli/src/main.rs`

**Arguments**:

- `config` (PathBuf): required - Path to configuration file
- `tenant` (String): required - Tenant identifier for multi-tenancy
- `verbose` (bool): optional - Enable verbose logging

**Options**:

- `--config, -c`(PathBuf): required - Configuration file path
- `--tenant, -t`(String): required - Tenant ID
- `--verbose, -v`(bool): optional - Enable verbose output (default: `false`)

**Usage Examples**:

```bash
cortex-mem-cli --config /etc/cortex/config.toml --tenant acme add --thread thread-123 --role user --content "Hello"
```

```bash
cortex-mem-cli -c config.toml -t acme search --query "machine learning" --limit 10
```

```bash
cortex-mem-cli --config config.toml --tenant acme session create --thread thread-456 --title "My Session"
```

```bash
cortex-mem-cli --config config.toml --tenant acme list --uri /memories --include-abstracts
```

```bash
cortex-mem-cli --config config.toml --tenant acme stats
```

### cortex-mem-mcp

**Description**: MCP (Model Context Protocol) server for memory operations via stdio

**Source File**: `cortex-mem-mcp/src/main.rs`

**Arguments**:

- `config` (PathBuf): required - Path to configuration file
- `tenant` (String): required - Tenant identifier

**Options**:

- `--config, -c`(PathBuf): required - Configuration file path
- `--tenant, -t`(String): required - Tenant ID

**Usage Examples**:

```bash
cortex-mem-mcp --config /etc/cortex/config.toml --tenant acme
```

### cortex-mem-service

**Description**: HTTP service for memory operations with RESTful API

**Source File**: `cortex-mem-service/src/main.rs`

**Arguments**:

- `data_dir` (String): required - Data directory for persistence
- `host` (String): required - Server host address
- `port` (u16): required - Server port
- `verbose` (bool): optional - Enable verbose logging

**Options**:

- `--data-dir, -d`(String): required - Data directory path
- `--host, -h`(String): required - Host address to bind
- `--port, -p`(u16): required - Port to listen on
- `--verbose, -v`(bool): optional - Enable verbose logging (default: `false`)

**Usage Examples**:

```bash
cortex-mem-service --data-dir /var/lib/cortex --host 0.0.0.0 --port 8085
```

```bash
cortex-mem-service -d /data -h 127.0.0.1 -p 3000 --verbose
```

### cortex-mem-tars

**Description**: TARS (Talk, Ask, Retrieve, Store) example application with memory integration

**Source File**: `examples/cortex-mem-tars/src/main.rs`

**Arguments**:

- `enhance_memory_saver` (bool): optional - Enable memory saver enhancement
- `enable_audio_connect` (bool): optional - Enable audio connect feature
- `audio_connect_mode` (String): optional - Audio connect mode setting
- `enhance_vector_search` (bool): optional - Enable vector search enhancement

**Options**:

- `--enhance-memory-saver`(bool): optional - Enhance memory saver functionality (default: `false`)
- `--enable-audio-connect`(bool): optional - Enable audio connect integration (default: `false`)
- `--audio-connect-mode`(String): optional - Audio connect mode (stdio, websocket, sse) (default: `stdio`)
- `--enhance-vector-search`(bool): optional - Enhance vector search capabilities (default: `false`)

**Usage Examples**:

```bash
cortex-mem-tars --enhance-memory-saver --enable-audio-connect --audio-connect-mode websocket
```

```bash
cortex-mem-tars --enhance-vector-search
```

## API Interfaces

### Health Endpoints

#### GET /health

**Description**: Health check endpoint for service availability

**Source File**: `cortex-mem-service/src/handlers/health.rs`

**Request Format**: None

**Response Format**: JSON: `{ status: string, service: string, version: string, llm_available: boolean }`

### Tenant Endpoints

#### GET /api/v2/tenants/tenants

**Description**: List all available tenants

**Source File**: `cortex-mem-service/src/handlers/tenants.rs`

**Request Format**: None

**Response Format**: JSON: `ApiResponse<string[]>`

#### POST /api/v2/tenants/tenants/switch

**Description**: Switch active tenant context

**Source File**: `cortex-mem-service/src/handlers/tenants.rs`

**Request Format**: JSON: `{ tenant_id: string }`

**Response Format**: JSON: `ApiResponse<string>`

### Filesystem Endpoints

#### GET /api/v2/filesystem/list

**Description**: List directory contents

**Source File**: `cortex-mem-service/src/handlers/filesystem.rs`

**Request Format**: Query: `{ uri: string }`

**Response Format**: JSON: `ApiResponse<FileEntryResponse[]>`

**FileEntryResponse**:
```typescript
{
  uri: string;
  name: string;
  is_directory: boolean;
  size: number;
  modified: string;
}
```

#### GET /api/v2/filesystem/read/:path

**Description**: Read file content

**Source File**: `cortex-mem-service/src/handlers/filesystem.rs`

**Request Format**: Path parameter: `path` (URL encoded, supports `cortex://` URIs)

**Response Format**: JSON: `ApiResponse<string>`

#### POST /api/v2/filesystem/write

**Description**: Write content to a file

**Source File**: `cortex-mem-service/src/handlers/filesystem.rs`

**Request Format**: JSON: `{ path: string, content: string }`

**Response Format**: JSON: `ApiResponse<string>`

#### GET /api/v2/filesystem/stats

**Description**: Get directory statistics

**Source File**: `cortex-mem-service/src/handlers/filesystem.rs`

**Request Format**: Query: `{ uri: string }`

**Response Format**: JSON: `ApiResponse<{ file_count: number, total_size: number }>`

### Session Endpoints

#### GET /api/v2/sessions

**Description**: List all sessions

**Source File**: `cortex-mem-service/src/handlers/sessions.rs`

**Request Format**: None

**Response Format**: JSON: `ApiResponse<SessionResponse[]>`

**SessionResponse**:
```typescript
{
  thread_id: string;
  status: string;
  message_count: number;
}
```

#### POST /api/v2/sessions

**Description**: Create new session

**Source File**: `cortex-mem-service/src/handlers/sessions.rs`

**Request Format**: JSON: `{ thread_id?: string, title?: string, metadata?: object }`

**Response Format**: JSON: `ApiResponse<SessionResponse>`

#### POST /api/v2/sessions/:thread_id/messages

**Description**: Add message to session

**Source File**: `cortex-mem-service/src/handlers/sessions.rs`

**Request Format**: JSON: `{ role: string, content: string, metadata?: object }`

**Response Format**: JSON: `ApiResponse<string>` (message ID)

#### POST /api/v2/sessions/:thread_id/close

**Description**: Close session and trigger extraction

**Source File**: `cortex-mem-service/src/handlers/sessions.rs`

**Request Format**: Path parameter: `thread_id`

**Response Format**: JSON: `ApiResponse<SessionResponse>`

### Search Endpoints

#### POST /api/v2/search

**Description**: Search memories with semantic similarity

**Source File**: `cortex-mem-service/src/handlers/search.rs`

**Request Format**: JSON:
```typescript
{
  query: string;
  thread?: string;
  limit?: number;
  min_score?: number;
  scope?: string;
}
```

**Response Format**: JSON: `ApiResponse<SearchResultResponse[]>`

**SearchResultResponse**:
```typescript
{
  uri: string;
  score: number;
  snippet: string;
  content?: string;
  source: string;
}
```

### Automation Endpoints

#### POST /api/v2/automation/extract/:thread_id

**Description**: Trigger extraction for thread

**Source File**: `cortex-mem-service/src/handlers/automation.rs`

**Request Format**: JSON: `{ auto_save?: boolean }`

**Response Format**: JSON: `ApiResponse<ExtractionResult>`

#### POST /api/v2/automation/index/:thread_id

**Description**: Trigger indexing for thread

**Source File**: `cortex-mem-service/src/handlers/automation.rs`

**Request Format**: Path parameter: `thread_id`

**Response Format**: JSON: `ApiResponse<IndexResult>`

#### POST /api/v2/automation/index-all

**Description**: Trigger indexing for all threads

**Source File**: `cortex-mem-service/src/handlers/automation.rs`

**Request Format**: None

**Response Format**: JSON: `ApiResponse<IndexAllResult>`

### TARS API Endpoints

#### POST /api/memory/store

**Description**: Store memory via TARS API

**Source File**: `examples/cortex-mem-tars/src/api_server.rs`

**Request Format**: JSON: `StoreMemoryRequest`

**Response Format**: JSON: `StoreMemoryResponse`

#### GET /api/memory/retrieve

**Description**: Retrieve memories via TARS API

**Source File**: `examples/cortex-mem-tars/src/api_server.rs`

**Request Format**: Query: `{ query?: string, speaker_type?: string, limit?: number }`

**Response Format**: JSON: `RetrieveMemoryResponse`

#### GET /api/memory/list

**Description**: List memories via TARS API

**Source File**: `examples/cortex-mem-tars/src/api_server.rs`

**Request Format**: Query: `{ speaker_type?: string, limit?: number, offset?: number }`

**Response Format**: JSON: `ListMemoryResponse`

#### GET /api/memory/health

**Description**: Health check for memory service

**Source File**: `examples/cortex-mem-tars/src/api_server.rs`

**Request Format**: None

**Response Format**: JSON: `{ status: string }`

### External Service Endpoints

#### POST /embed (external)

**Description**: Embedding service for text vectorization

**Source File**: `cortex-mem-core/src/embedding/client.rs`

**Request Format**: JSON: `{ text: string }` or `{ texts: string[] }`

**Response Format**: JSON: `{ embedding: number[] }` or `{ embeddings: number[][] }`

## Router Routes

### cortex-mem-service Routes

**Source File**: `cortex-mem-service/src/routes/mod.rs`

```
/health                           → Health check endpoint
/api/v2/filesystem/list           → List directory contents
/api/v2/filesystem/read/*path     → Read file content
/api/v2/filesystem/write          → Write file content
/api/v2/filesystem/stats          → Get directory statistics
/api/v2/sessions                  → List/create sessions
/api/v2/sessions/:thread_id/messages → Add message to session
/api/v2/sessions/:thread_id/close    → Close session
/api/v2/search                    → Semantic search
/api/v2/automation/extract/:thread_id → Trigger extraction
/api/v2/automation/index/:thread_id   → Trigger indexing
/api/v2/automation/index-all      → Index all threads
/api/v2/tenants/tenants           → List tenants
/api/v2/tenants/tenants/switch    → Switch tenant
```

### cortex-mem-insights Routes

**Source File**: `cortex-mem-insights/src/App.svelte`

Client-side routing (manual, not SvelteKit file-system routing):

```
/              → Dashboard page (tenant overview, health status)
/memories      → Memories page (file browser for cortex:// URIs)
/search        → Search page (semantic search interface)
```

## Common Response Format

All API responses from `cortex-mem-service` follow a consistent wrapper format:

```typescript
interface ApiResponse<T> {
  success: boolean;
  data: T | null;
  error: string | null;
  timestamp: string;
}
```

## Integration Suggestions

### Web Dashboard Integration

Integration with Cortex Memory Insights Web Dashboard

**Example Code**:

```typescript
import apiClient from './api';

// Health check
const health = await apiClient.getHealth();
console.log('Service status:', health.status);
console.log('LLM available:', health.llm_available);

// List tenants
const tenants = await apiClient.listTenants();
console.log('Available tenants:', tenants);

// Switch tenant
await apiClient.switchTenant('acme');

// Browse memories
const files = await apiClient.listDirectory('cortex://memories');
for (const file of files) {
  if (!file.is_directory) {
    const content = await apiClient.readFile(file.uri);
    console.log(`${file.name}: ${content}`);
  }
}

// Search memories
const results = await apiClient.search('machine learning', 'all', 10);
for (const result of results) {
  console.log(`[${result.score.toFixed(2)}] ${result.snippet}`);
}

// Get directory statistics
const stats = await apiClient.getDirectoryStats('cortex://memories');
console.log(`Total files: ${stats.file_count}, Size: ${stats.total_size} bytes`);
```

**Best Practices**:

- Always handle API errors with try-catch blocks
- Use the tenant context for multi-tenant scenarios
- Implement loading states for better UX
- Cache tenant information to reduce API calls
- Use URL encoding for filesystem paths

### MCP Protocol Integration

Model Context Protocol (MCP) integration for AI assistants

**Example Code**:

```rust
use cortex_mem_mcp::MemoryMcpService;
use cortex_mem_core::{Config, LLMClientImpl, MemoryOperations};

#[tokio::main]
async fn main() -> Result<()> {
    let config = Config::load("/etc/cortex/config.toml")?;
    let _ = tracing_subscriber::fmt::init();
    
    let llm_client = LLMClientImpl::new(&config.llm).await?;
    let memory_ops = MemoryOperations::new(&config, &llm_client).await?;
    
    let mcp_service = MemoryMcpService::new(memory_ops);
    mcp_service.serve_stdio().await?;
    
    Ok(())
}
```

**Best Practices**:

- Initialize LLM client before MemoryOperations
- Store configuration in TOML format
- Use tenant isolation for multi-tenant scenarios
- Implement proper error handling for MCP operations
- Enable tracing for debugging
- Use stdio transport for MCP protocol compliance

### Rust Service Router Integration

Rust Axum service integration with modular routes

**Example Code**:

```rust
use axum::{Router, routing::{get, post}};
use std::sync::Arc;

// Build modular router
let api_routes = Router::new()
    .nest("/filesystem", filesystem::routes())
    .nest("/sessions", sessions::routes())
    .nest("/search", search::routes())
    .nest("/automation", automation::routes())
    .nest("/tenants", tenants::routes());

let app = Router::new()
    .route("/health", get(health_check))
    .nest("/api/v2", api_routes)
    .layer(CorsLayer::permissive())
    .layer(TraceLayer::new_for_http())
    .with_state(Arc::new(app_state));

// Start server
let addr = SocketAddr::from(([127, 0, 0, 1], 8085));
let listener = tokio::net::TcpListener::bind(addr).await?;
axum::serve(listener, app).await?;
```

**Best Practices**:

- Use the service router for modular API design
- Implement proper state management with Arc<AppState>
- Use layered search for complex queries
- Implement health checks for service monitoring
- Use JSON API responses consistently
- Handle file path encoding properly for filesystem routes
- Use batch indexing for large datasets

### TARS Application Template

TARS (Talk, Ask, Retrieve, Store) application integration pattern

**Example Code**:

```rust
use cortex_mem_tars::{ConfigManager, Infrastructure, App};

#[tokio::main]
async fn main() -> Result<()> {
    let args = Args::parse();
    
    // Configuration
    let config_manager = ConfigManager::new()?;
    init_logger();
    
    // Create bots
    let bots = create_default_bots(&config_manager);
    
    // Infrastructure
    let infrastructure = Infrastructure::new(
        &config_manager,
        args.enhance_memory_saver,
        args.enable_audio_connect,
        &args.audio_connect_mode,
        args.enhance_vector_search
    ).await?;
    
    // Application
    let app = App::new(bots, infrastructure)?;
    
    // Check services
    app.check_service_status().await?;
    
    // Run and cleanup
    app.run().await?;
    
    // Conditional save on exit
    if args.enhance_memory_saver {
        app.on_exit().await?;
    }
    
    Ok(())
}
```

**Best Practices**:

- Initialize ConfigManager before other components
- Use conditional memory saving on exit
- Start API server for external integrations
- Check service status before operations
- Use proper logging initialization
- Implement graceful shutdown with on_exit handlers

### Automation Indexing Integration

Automated indexing for conversation threads and messages

**Example Code**:

```rust
use cortex_mem_core::automation::{AutoIndexer, IndexerConfig};

// Configuration
let config = IndexerConfig {
    auto_index: true,
    batch_size: 100,
    async_index: true,
};

// Initialize indexer
let indexer = AutoIndexer::new(
    Arc::new(filesystem),
    Arc::new(embedding_client),
    Arc::new(vector_store),
    config
);

// Index thread with progress
indexer.index_thread_with_progress(
    &thread_id,
    |progress| println!("Indexed: {:.1}%", progress * 100.0)
).await?;

// Collect messages recursively
let messages = indexer.collect_messages_recursive(&thread_uri).await?;

// Batch index
indexer.index_message_batch(&messages).await?;
```

**Best Practices**:

- Use AutoIndexer for batch processing
- Enable async indexing for performance
- Calculate content hash to avoid duplicate indexing
- Use progress callbacks for long-running operations
- Parse markdown content for structured extraction
- Configure batch size based on embedding service capacity

---

**Document Version**: 2.0  
**Last Updated**: 2026-02-18  
**Analysis Confidence**: 9.0/10