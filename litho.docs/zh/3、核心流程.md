# 核心工作流

**文档版本**: 1.0  
**系统**: Cortex Memory (cortex-mem)  
**最后更新**: 2024

## 目录
1. [工作流概述](#1-工作流概述)
2. [主要工作流](#2-主要工作流)
3. [流程协调与控制](#3-流程协调与控制)
4. [异常处理与恢复](#4-异常处理与恢复)
5. [关键流程实现](#5-关键流程实现)

---

## 1. 工作流概述

### 1.1 系统架构与工作流全景

Cortex-Mem实现了一个**多维度记忆管理系统**，为AI智能体设计，围绕五个核心运营工作流构建，确保跨会话的持久化、上下文感知记忆。系统遵循**分层检索架构**（L0抽象、L1概览、L2细节）结合**基于向量的语义搜索**和**文件系统抽象**。

### 1.2 核心工作流分类

系统通过五个主要工作流运行，涵盖初始化、运行时操作和后台自动化：

| 工作流 | 类型 | 频率 | 关键性 | 关键组件 |
|----------|------|-----------|-------------|----------------|
| **系统初始化** | 引导 | 每个实例 | 关键 | 配置加载、DI容器、服务连接 |
| **语义记忆搜索** | 用户面向 | 每个查询 | 关键 | 向量引擎、层级管理器、排序 |
| **记忆索引与同步** | 后台 | 事件驱动 | 高 | 文件监视器、索引器、向量存储 |
| **记忆提取与画像** | 后台 | 会话关闭 | 高 | LLM提取、配置文件合并、去重 |
| **多租户请求处理** | 跨切面 | 每个请求 | 关键 | 租户隔离、URI路由、集合作用域 |

### 1.3 工作流依赖关系

```mermaid
graph TD
    A[系统初始化] --> B[语义记忆搜索]
    A --> C[记忆索引与同步]
    A --> D[记忆提取与画像]
    A --> E[多租户请求处理]
    
    E --> B
    E --> C
    E --> D
    
    C --> B
    D --> C
    
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#bbf,stroke:#333,stroke-width:2px
```

**依赖理由**:
- **初始化**是所有运营工作流的前提，建立依赖注入图和服务边界。
- **多租户处理**作为跨切面问题，限定所有后续操作。
- **索引**为**搜索**依赖的向量存储提供数据。
- **提取**生成丰富未来搜索上下文的配置文件数据。

---

## 2. 主要工作流

### 2.1 系统初始化与依赖注入

#### 2.1.1 流程概述

初始化工作流通过加载配置、初始化核心服务（LLM、Qdrant、文件系统）并为所有接口（CLI、HTTP API、MCP、Web）连接依赖项来引导整个系统。这确保所有入口点的状态一致。

#### 2.1.2 执行流程

```mermaid
sequenceDiagram
    participant Entry as 二进制入口
    participant CLI as CLI解析器
    participant Config as 配置加载器
    participant LLM as LLM客户端
    participant Emb as 嵌入客户端
    participant Qdrant as 向量存储
    participant FS as 文件系统
    participant MemOps as 记忆操作
    participant Interface as 目标接口
    
    Entry->>CLI: 解析参数（--config, --tenant）
    CLI->>Config: 加载TOML + 环境变量
    Config->>Config: 解析数据目录<br/>环境变量 > 系统 > ./cortex
    Config->>Config: 验证必需部分<br/>[llm], [qdrant], [embedding]
    
    Config->>LLM: 初始化LLMClientImpl<br/>带model_efficient、api_key、base_url
    Config->>Emb: 初始化EmbeddingClient<br/>带维度（默认1536）
    
    LLM->>Qdrant: 创建QdrantVectorStore<br/>租户感知集合命名
    Emb->>Qdrant: 验证嵌入维度
    
    Qdrant->>FS: 初始化CortexFilesystem<br/>带租户隔离路径
    
    FS->>MemOps: 构造记忆操作<br/>Arc封装用于共享所有权
    
    MemOps->>Interface: 注入依赖<br/>CLI命令 / HTTP状态 / MCP服务
    Interface->>Interface: 启动服务器或执行命令
```

#### 2.1.3 关键流程节点

**配置解析策略**:
1. **环境变量**（`CORTEX_DATA_DIR`、`EMBEDDING_API_KEY`）具有最高优先级
2. **TOML配置文件**通过`--config`指定或默认位置
3. **系统目录**使用`directories` crate（如macOS上的`~/Library/Application Support/com.cortex-mem.tars`）
4. **本地回退**到`.cortex`用于开发/可移植性

**依赖注入模式**:
- 使用`Arc<T>`进行`MemoryOperations`的线程安全共享所有权
- boxed特性对象（`Box<dyn VectorStore>`、`Box<dyn LLMClient>`）实现松耦合和可测试性
- 构建器模式（`CortexMemBuilder`）用于流式初始化

**验证门控**:
- 必需配置部分：`[llm]`、`[qdrant]`、`[embedding]`
- Qdrant连接验证
- 嵌入维度自动检测（回退到1536用于text-embedding-3-small）

---

### 2.2 语义记忆搜索流程

#### 2.2.1 流程概述

语义搜索工作流使用L0（抽象）、L1（概览）和L2（细节）层的加权组合，对记忆维度（用户、智能体、会话）执行智能的多层检索。这是系统的主要价值交付工作流。

#### 2.2.2 执行流程

```mermaid
flowchart TD
    A[用户查询输入] --> B{解析参数}
    B --> C[作用域：用户/智能体/会话]
    B --> D[阈值：默认0.5]
    B --> E[限制：1-100个结果]
    
    C --> F[意图检测]
    F --> F1[事实查询]
    F --> F2[实体查询<br/>2-4个CJK字符]
    F --> F3[时间/关系]
    F --> F4[一般]
    
    F --> G[生成查询嵌入]
    G --> H[L0抽象搜索<br/>.abstract.md文件]
    
    H --> I{找到结果?}
    I -->|是| J[加权评分<br/>0.2×L0 + 0.3×L1 + 0.5×L2]
    I -->|否| K[降级策略]
    
    K --> K1[降低阈值<br/>0.5→0.4→0.3]
    K1 --> L[L1概览搜索]
    L --> M[L2细节搜索]
    M --> J
    
    J --> N[元数据过滤<br/>tenant_id、时间、实体]
    N --> O[片段生成<br/>100字符上下文窗口]
    O --> P[排序并返回<br/>带URI + 评分]
```

#### 2.2.3 分层检索算法

**三层架构**:

1. **L0层（抽象）**: 使用`.abstract.md`文件（~100 tokens）的快速定位
   - **目的**: 粗粒度候选选择
   - **权重**: 最终评分的20%
   - **内容**: 捕获核心本质的单句或2-3句摘要（谁、什么、何时）

2. **L1层（概览）**: 使用`.overview.md`文件（500-2000 tokens）的深度探索
   - **目的**: 决策的上下文精炼
   - **权重**: 最终评分的30%
   - **内容**: 带摘要、核心主题、关键点、实体的结构化markdown

3. **L2层（细节）**: 使用完整消息内容的精确匹配
   - **目的**: 最终相关性确认
   - **权重**: 最终评分的50%
   - **内容**: Markdown格式的原始对话消息

**评分公式**:
```rust
final_score = (l0_score × 0.2) + (l1_score × 0.3) + (l2_score × 0.5)
```

#### 2.2.4 自适应查询处理

**意图检测**:
- **实体查询**: 短中文名（2-4个CJK字符）或短英文专有名词触发专门处理，阈值为0.4
- **事实查询**: 事实寻求的模式匹配（谁、什么、何时）
- **时间查询**: 通过正则表达式检测的基于时间的约束

**降级策略**:
1. **渐进阈值降低**: 如果L0返回空，将相似度阈值从0.5 → 0.4 → 0.3降低
2. **层级旁路**: 当分层检索失败时，回退到绕过层级架构的完整语义搜索

---

### 2.3 记忆索引与同步

#### 2.3.1 流程概述

此后台工作流自动检测文件系统存储的对话记忆变化，并将其与Qdrant向量数据库同步。它通过批量处理和去重确保实时可搜索性，同时平衡性能。

#### 2.3.2 执行流程

```mermaid
flowchart TD
    A[文件系统监视器] -->|轮询间隔5秒| B[扫描cortex://session]
    B --> C{检测变化}
    C -->|新增/修改| D[排队等待批量处理]
    C -->|无变化| A
    
    D --> E[延迟2秒]
    E --> F[加载原始内容<br/>L2层]
    
    F --> G[检查哈希去重]
    G -->|重复| A
    G -->|新内容| H[生成L0抽象]
    
    H --> I[生成L1概览]
    I --> J[创建记忆对象]
    
    J --> K[生成向量ID<br/>URI + Layer哈希]
    K --> L[使用EmbeddingClient嵌入]
    
    L --> M[Upsert到Qdrant<br/>租户感知集合]
    M --> N[更新索引状态]
    N --> A
```

#### 2.3.3 关键机制

**确定性向量ID生成**:
```rust
// 双重哈希确保相同URI+Layer始终生成相同ID
id = hash(hash(uri) + layer_suffix)
```
- **目的**: 实现幂等更新和去重
- **格式**: 来自内容URI和层标识符（L0/L1/L2）的UUIDv5

**批量处理策略**:
- **实时模式**（`index_on_message=true`）：消息添加时立即索引（高开销）
- **批量模式**（默认）：在`pending_sessions`集合中累积变化，通过`tokio::select!`超时处理
- **去重**：在嵌入生成前检查内容哈希以避免冗余LLM API调用

**层级生成管道**:
1. **原始内容**（L2）：从文件系统markdown加载
2. **抽象生成**：使用`Prompts::generate_abstract`的LLM提示（~100 tokens）
3. **概览生成**：使用`Prompts::generate_overview`的LLM提示（结构化markdown）
4. **向量化**：每个层级分别嵌入，带维度一致性检查

---

### 2.4 记忆提取与画像

#### 2.4.1 流程概述

在会话关闭时触发，此工作流从对话历史中提取结构化事实、决策和实体，并丰富用户或智能体画像。它实现跨会话的持久化个性化和累积学习。

#### 2.4.2 执行流程

```mermaid
sequenceDiagram
    participant Session as 会话管理器
    participant AutoMgr as 自动化管理器
    participant Extractor as 自动提取器
    participant LLM as LLM客户端
    participant Profile as 配置文件管理器
    participant FS as 文件系统
    
    Session->>AutoMgr: 发出SessionEvent::Closed
    AutoMgr->>AutoMgr: 检查auto_extract启用
    
    alt 提取启用
        AutoMgr->>Extractor: extract_from_thread(session_id)
        Extractor->>FS: 递归读取timeline/*.md
        FS->>Extractor: 对话文本
        
        Extractor->>Extractor: 构建上下文提示<br/>带现有配置文件
        
        par 并行提取
            Extractor->>LLM: 提取事实
            Extractor->>LLM: 提取决策
            Extractor->>LLM: 提取实体
        end
        
        LLM-->>Extractor: JSON结构化结果<br/>带置信度评分
        
        Extractor->>Extractor: 按阈值过滤<br/>通过LCS去重
        
        Extractor->>Profile: 合并到用户配置文件<br/>（个人、工作、偏好、关系、目标）
        
        Profile->>Profile: 实施类别限制<br/>如每类别最多100个事实
        
        Profile->>FS: 持久化到cortex://user/{id}/profile.json
        FS->>AutoMgr: 提取完成
    else 提取禁用
        AutoMgr->>AutoMgr: 跳过处理
    end
```

#### 2.4.3 提取分类

**记忆类型**:
- **事实**: 带置信度（0.0-1.0）和重要性（低/中/高/关键）的客观陈述
- **决策**: 带有上下文和理由的选择
- **实体**: 带属性的人、组织、产品

**配置文件类别**:
1. **个人信息**: 人口统计、联系方式
2. **工作经历**: 职业背景
3. **偏好**: 明确的喜欢/不喜欢
4. **关系**: 实体之间的联系
5. **目标**: 声明的目标和愿望

**去重策略**:
- **算法**: 最长公共子串（LCS）相似度
- **阈值**: 可配置的字符串相似度（默认0.85）
- **冲突解决**: 更高置信度分数覆盖现有；以时间戳为基础的平局决胜

---

### 2.5 多租户记忆管理

#### 2.5.1 流程概述

通过将所有操作限定到租户ID，实现不同用户、智能体或组织之间记忆数据的隔离。支持多个租户共享同一系统实例同时保持数据分离的SaaS部署。

#### 2.5.2 隔离架构

```mermaid
flowchart LR
    A[请求上下文] -- "提取" --> B[租户ID]
    
    B --> C[文件系统隔离]
    B --> D[向量存储隔离]
    B --> E[处理范围]
    
    C --> C1[租户文件会话路径]
    D --> D1[向量存储集合后缀]
    E --> E1[会话事件档案提取]
    
    style B fill:#f9f,stroke:#333,stroke-width:2px
```

#### 2.5.3 租户传播链

1. **入口点提取**:
   - CLI: `--tenant`参数
   - HTTP: `Authorization` header或请求元数据
   - MCP: 上下文参数

2. **配置传播**:
   - `QdrantConfig::with_tenant_id()`：后缀集合名称
   - `CortexFilesystem`：在所有路径前加上`/tenants/{tenant_id}`
   - `AutomationManager`：按租户限定事件处理

3. **数据隔离保证**:
   - **文件系统**: 物理目录分离防止跨租户文件访问
   - **向量存储**: 每个租户独立的Qdrant集合（或共享集合中的命名空间隔离）
   - **搜索**: 所有向量查询自动按`tenant_id`元数据过滤

---

## 3. 流程协调与控制

### 3.1 事件驱动架构

系统使用Tokio的`mpsc`无界通道实现**发布/订阅事件总线**，实现组件间的松耦合。

**事件分类**:
```rust
enum CortexEvent {
    Session(SessionEvent),      // 创建、消息添加、关闭
    Filesystem(FilesystemEvent), // 创建、修改、删除
}
```

**事件流**:
```mermaid
graph LR
    A[会话管理器] -->|SessionEvent::Closed| B[事件总线]
    C[FsWatcher] -->|FilesystemEvent::Modify| B
    B --> D[自动化管理器]
    B --> E[自动索引器]
    B --> F[自动提取器]
    
    D -->|触发| G[批量处理]
    E -->|索引| H[向量存储]
    F -->|提取| I[用户配置文件]
```

**协调模式**:
- **即发即忘**: 会话事件触发后台提取而不阻塞UI
- **批量聚合**: `AutomationManager`使用`HashSet`对快速连续事件去重
- **并发处理**: `tokio::spawn`用于并行索引；`tokio::select!`用于超时管理

### 3.2 状态管理

**会话状态机**:
```mermaid
stateDiagram-v2
    [*] --> Active: create_session
    Active --> Active: add_message
    Active --> Closing: close_session
    Closing --> Indexing: 发出Closed事件
    Indexing --> Extracting: 索引完成
    Extracting --> [*]: 配置文件已更新
```

**索引状态跟踪**:
- **内存中**: `HashMap<String, Vec<String>>`跟踪每个线程处理的消息ID
- **去重**: 存储在向量元数据中的内容哈希防止重新索引
- **持久化**: 向量存储作为索引状态的真相来源

### 3.3 数据流模式

**请求-响应流**（同步）:
1. 接口接收请求（HTTP/MCP/CLI）
2. 提取租户上下文
3. 调用`MemoryOperations`方法
4. 直接访问文件系统或向量存储
5. 返回结构化响应

**后台处理流**（异步）:
1. 检测到事件（文件变化、会话关闭）
2. 事件排队到`AutomationManager`
3. `tokio::spawn`创建后台任务
4. 进度通过`tracing`日志跟踪
5. 结果持久化到存储

### 3.4 并发控制

**资源共享**:
- `Arc<MemoryOperations>`: 在所有请求处理器间共享
- `Arc<Mutex<File>>`: 日志文件访问串行化
- `RwLock<HashMap>`: Web UI中的租户缓存

**并行策略**:
- **每租户并行**: 不同租户并发处理
- **层级并行**: L0/L1/L2向量化按顺序发生（依赖），但多条消息批量并行处理
- **提取并行**: 事实、决策、实体通过`join!`同时提取

---

## 4. 异常处理与恢复

### 4.1 错误分类

系统使用`thiserror`定义全面的错误层次：

| 错误变体 | 来源 | 处理策略 |
|--------------|--------|-------------------|
| `InvalidUri` | URI解析 | 快速失败，带用户上下文 |
| `InvalidDimension` | 类别验证 | 返回400 Bad Request |
| `MemoryNotFound` | 存储查找 | 返回空结果集 |
| `IoError` | 文件系统 | 指数退避重试 |
| `JsonError` | 序列化 | 记录并继续（跳过记录） |
| `LlmError` | AI/ML服务 | 降级到关键词搜索 |
| `EmbeddingError` | 向量化 | 跳过索引，警告监控 |
| `QdrantError` | 向量存储 | 断路器模式 |
| `ConfigError` | 初始化 | 恐慌/退出带错误消息 |

### 4.2 降级策略

**搜索降级**:
```mermaid
flowchart TD
    A[向量搜索请求] --> B{向量存储可用?}
    B -->|否| C[文件系统回退<br/>全文扫描]
    B -->|是| D{找到结果?}
    
    D -->|否| E[降低阈值<br/>0.5→0.4→0.3]
    E --> F{仍无结果?}
    F -->|是| G[仅元数据搜索<br/>跳过向量相似度]
    
    D -->|是| H[返回排名结果]
    G --> H
    C --> H
```

**LLM服务降级**:
- **主要**: OpenAI兼容API
- **回退**: 通过兼容端点的本地LLM
- **紧急**: 跳过提取/索引，仅维护L2存储

**索引失败恢复**:
1. **批量回滚**: 失败批次项目记录到`warn!`，其他提交
2. **重试逻辑**: 3次尝试，延迟1s、5s、30s
3. **死信队列**: 持久化失败写入`failed_index/{tenant_id}/{timestamp}.json`

### 4.3 容错模式

**断路器**（向量存储）:
- **关闭**: 正常运行
- **打开**: 5次连续失败后，绕过向量操作60秒
- **半开**: 冷却后测试ping，如果健康则恢复

**优雅关闭**:
1. 停止接受新请求
2. 等待进行中的索引完成（30秒超时）
3. 刷新待处理提取队列
4. 关闭文件系统句柄
5. 终止运行时

### 4.4 恢复程序

**数据一致性修复**:
- **SyncManager**: 通过CLI `cortex-mem sync`手动触发，协调文件系统与向量存储
- **哈希不匹配**: 重新索引文件系统哈希≠存储哈希的内容
- **孤立向量**: 每周清理作业删除具有不存在文件系统URI的向量

**租户隔离 breach恢复**:
- 立即隔离集合
- 审计日志分析数据泄漏范围
- 从文件系统备份重新生成配置文件

---

## 5. 关键流程实现

### 5.1 向量ID生成算法

**目的**: 确保向量条目的确定性、唯一标识符，支持幂等更新。

**实现**:
```rust
fn uri_to_vector_id(uri: &str, layer: ContextLayer) -> String {
    // 步骤1: 规范化URI（小写、修剪）
    let normalized = uri.to_lowercase().trim();
    
    // 步骤2: 创建层后缀
    let suffix = match layer {
        ContextLayer::Abstract => "#L0",
        ContextLayer::Overview => "#L1", 
        ContextLayer::Detail => "#L2",
    };
    
    // 步骤3: 双重哈希增加熵
    let hash1 = sha256(normalized);
    let hash2 = sha256(hash1 + suffix);
    
    // 步骤4: 转换为UUIDv5格式
    uuid_from_hash(hash2)
}
```

**属性**:
- **确定性**: 相同URI + Layer始终产生相同ID
- **抗碰撞**: 双重SHA256，带租户作用域URI
- **可解析**: `parse_vector_id()`从ID提取原始URI和层

### 5.2 意图检测引擎

**分类逻辑**:

```rust
fn detect_intent(query: &str) -> IntentType {
    // 实体检测：短专有名词
    if is_cjk(query) && query.len() <= 12 {  // 2-4个CJK字符
        return IntentType::Entity;
    }
    
    // 事实模式
    if query.matches(r"^(who|what|when|where|why|how)\b") {
        return IntentType::Factual;
    }
    
    // 时间模式
    if query.matches(r"\b(yesterday|today|last week|in 2024)\b") {
        return IntentType::Temporal;
    }
    
    // 关系模式
    if query.matches(r"\b(related to|about|with)\b") {
        return IntentType::Relational;
    }
    
    IntentType::General
}
```

**阈值适配**:
- **实体/事实**: 0.4（更高召回率用于特定查找）
- **一般**: 0.5（平衡精确度/召回率）
- **关系**: 0.45（加权用于连接发现）

### 5.3 内容哈希与去重

**去重管道**:
1. **内容规范化**: 移除空白、小写、规范化Unicode
2. **SimHash生成**: 64位哈希用于近重复检测
3. **汉明距离**: 3位阈值用于相似度
4. **LCS验证**: 最长公共子串 > 80%确认重复

**批量去重**:
- 每次索引运行中处理消息ID的内存`HashSet`
- 向量存储预检查：`exists(vector_id)`在嵌入前
- 基于时间戳的冲突解决：如果哈希匹配则保留较新

### 5.4 配置文件合并算法

**冲突解决**:
```rust
fn merge_profile(existing: UserProfile, new: ExtractedMemories) -> UserProfile {
    for fact in new.facts {
        // 检查语义重复
        if existing.facts.any(|f| similarity(f, fact) > 0.85) {
            // 如果更高置信度则更新
            if fact.confidence > existing.confidence {
                replace(existing_fact, fact);
            }
        } else {
            // 检查类别限制
            if category_count < MAX_CATEGORY_SIZE {
                existing.facts.push(fact);
            } else if fact.importance > existing.min_importance {
                // 替换最不重要的
                replace_least_important(existing.facts, fact);
            }
        }
    }
}
```

**类别限制**:
- 个人信息: 50项
- 工作经历: 100项
- 偏好: 200项
- 关系: 50项
- 目标: 50项

### 5.5 性能优化策略

**嵌入批量处理**:
- **最优批量大小**: 32项（平衡延迟与吞吐量）
- **分块处理**: 大批量分割为子批次，带100ms产生活动点
- **连接池**: HTTP/2多路复用用于嵌入API调用

**文件系统I/O**:
- **异步操作**: 所有FS调用使用`tokio::fs`（非阻塞）
- **元数据缓存**: 文件stat的LRU缓存（1000条）
- **缓冲写入**: Markdown文件写入的4KB缓冲区

**向量搜索优化**:
- **HNSW索引**: Qdrant的HNSW算法用于亚毫秒相似度搜索
- **元数据过滤**: 在向量比较前按tenant_id预过滤（减少搜索空间）
- **分页**: 大结果集的光标滚动（避免偏移限制）

**内存管理**:
- **流式处理**: 大会话文件通过流式JSON解析器处理
- **对象池**: 跨请求重用LLM客户端连接
- **延迟加载**: L0/L1层按需生成，缓存到文件系统

---

## 附录：工作流指标与监控

**关键性能指标**:

| 工作流 | 指标 | 目标 | 告警阈值 |
|----------|--------|--------|----------------|
| 搜索 | P95延迟 | <200ms | >500ms |
| 索引 | 吞吐量 | 100 docs/sec | <20 docs/sec |
| 提取 | 准确度 | >90%置信度 | <70%置信度 |
| 初始化 | 启动时间 | <5s | >15s |

**健康检查端点**:
- `/health`: 存活探针（运行时活跃则HTTP 200）
- `/ready`: 就绪探针（检查Qdrant连接、磁盘空间）
- `/metrics`: Prometheus风格指标，用于向量存储延迟、索引队列深度

---

*核心工作流文档结束*
