# 记忆智能处理域技术文档

## 1. 概述

记忆智能处理域是cortex-mem系统的核心智能引擎，负责将原始的非结构化记忆内容转化为具有丰富语义和结构化元数据的高质量记忆数据。该域通过深度集成大语言模型（LLM）与规则引擎，实现了对记忆内容的自动化分类、重要性评估、知识提取和重复检测，是提升AI智能体长期记忆能力与个性化服务水平的关键模块。

本域采用“混合智能”架构，结合LLM的语义理解能力与规则系统的高效性，构建了多层降级处理机制。在保证处理精度的同时，有效应对LLM服务不可用或响应延迟的场景，确保系统整体的稳定性和可用性。

## 2. 核心功能与实现

### 2.1 记忆分类（Classification）

记忆分类模块负责将原始记忆内容自动归类为预定义的语义类型，为后续的检索、优化和个性化服务提供基础维度。

**实现架构**：
- **接口定义**：`MemoryClassifier` trait定义了统一的分类接口，支持`classify_memory`、`extract_entities`和`extract_topics`等方法。
- **双模式实现**：
  - **LLM分类器** (`LLMMemoryClassifier`)：使用LLM进行语义分析。通过精心设计的提示词（prompt），引导LLM将内容归类为`Conversational`、`Procedural`、`Factual`、`Semantic`、`Episodic`或`Personal`六种类型之一。为提高可靠性，采用`rig`框架的结构化提取器（`classify_memory`）直接输出JSON格式的分类结果，避免了传统文本解析的不稳定性。若结构化提取失败，则降级为文本补全模式，通过正则匹配进行回退。
  - **规则分类器** (`RuleBasedMemoryClassifier`)：基于关键词匹配的轻量级分类器。通过预定义的关键词列表（如“我喜欢”、“我擅长”、“姓名”、“生日”等）判断内容是否属于个人记忆（Personal）或程序型记忆（Procedural）。该模式响应速度快，适用于短文本或LLM服务不可用的场景。

**关键设计**：
- **多维度信息提取**：除分类外，该模块同时提取实体（Entities）和主题（Topics），为记忆元数据提供丰富的搜索维度。
- **语言感知**：在实体和主题提取中，系统会自动检测内容语言，确保提取结果的准确性。

### 2.2 重要性评估（Importance Evaluation）

重要性评估模块为每条记忆赋予一个0.0至1.0的数值评分，量化其对AI智能体长期价值的贡献，是记忆优化和优先级排序的核心依据。

**实现架构**：
- **接口定义**：`ImportanceEvaluator` trait定义了`evaluate_importance`和`evaluate_batch`方法。
- **双模式实现**：
  - **LLM评估器** (`LLMImportanceEvaluator`)：利用LLM的综合判断能力。提示词设计极为精细，不仅提供评分标准（0.0-1.0的五个等级），还要求LLM综合考虑记忆类型、内容相关性、独特性、未来参考价值和情感意义等多维度因素。同样，优先使用`rig`框架的`score_importance`结构化提取器，确保输出为精确的浮点数。若失败，则降级为文本解析，通过`parse::<f32>()`提取数字。
  - **规则评估器** (`RuleBasedImportanceEvaluator`)：基于启发式规则进行快速评估。主要依据三个维度：
    1.  **内容长度**：文本越长，重要性评分越高（最长文本评分为0.7）。
    2.  **记忆类型**：个人记忆（Personal）和事实记忆（Factual）被赋予最高权重（0.8和0.7），对话记忆（Conversational）权重最低（0.3）。
    3.  **关键词密度**：检测“重要”、“永远”、“喜欢”、“密码”等关键词，每出现一个增加0.1分，最高不超过0.5分。

**关键设计**：
- **混合评分**：在`create_importance_evaluator`工厂函数中，可配置为混合模式，即LLM评分与规则评分加权平均，兼顾精度与效率。
- **上下文感知**：LLM评估器会将记忆的创建时间、类型等元数据作为上下文输入，使评分更具情境性。

### 2.3 知识提取（Fact Extraction）

知识提取模块是记忆智能处理域中最复杂的部分，它能从对话历史中精准地抽取出用户偏好、个人事实和程序性知识，是实现个性化服务的基石。

**实现架构**：
- **接口定义**：`FactExtractor` trait定义了`extract_facts`、`extract_user_facts`等多种提取策略。
- **核心实现**：`LLMFactExtractor`是唯一实现，其核心在于**多角色、多策略的提示工程**。
  - **用户事实提取** (`build_user_memory_prompt`)：严格限定只从用户消息中提取信息，明确禁止提取助手的任何回应。提示词中包含“# [IMPORTANT]: GENERATE FACTS SOLELY BASED ON THE USER'S MESSAGES.”等强制性指令，确保提取结果的纯净性。
  - **助手事实提取** (`build_user_focused_assistant_prompt`)：与用户提取相反，此策略旨在从助手的回复中识别出**用户明确表达的偏好或信息**，并过滤掉所有技术性解释、建议和通用知识。例如，助手说“Rust是内存安全的”，此信息不会被提取；但若助手说“您提到您喜欢Rust”，则“喜欢Rust”会被提取。
  - **策略自适应**：系统会根据对话内容的复杂度和角色分布，自动选择最优的提取策略，实现“智能决策”。

**关键设计**：
- **结构化输出**：提取结果为`ExtractedFact`结构体，包含`content`、`importance`、`category`（Personal, Preference, Factual等）、`entities`和`source_role`等字段，为下游系统提供高度结构化的数据。
- **语言检测**：自动检测输入文本的语言，并在提取时保持语言一致性。

### 2.4 重复检测与合并（Deduplication）

重复检测与合并模块负责识别并处理记忆库中的冗余信息，保持记忆库的精简和高效。

**实现架构**：
- **接口定义**：`DuplicateDetector` trait定义了`detect_duplicates`、`merge_memories`和`are_similar`方法。
- **核心实现**：`AdvancedDuplicateDetector`采用**多维度相似度计算**：
  1.  **语义相似度**：计算两条记忆嵌入向量的余弦相似度，这是最核心的判断依据。
  2.  **内容相似度**：使用Jaccard相似度计算两段文本的词汇重叠率。
  3.  **元数据相似度**：比较`user_id`、`agent_id`、`memory_type`、`entities`和`topics`等元数据字段的匹配程度。
- **最终决策**：综合以上三个维度的得分，若总分超过预设的`similarity_threshold`（如0.8），则判定为重复。
- **智能合并**：当检测到重复时，系统会调用LLM（`create_merge_prompt`）生成一个融合了所有重复记忆优点的、更全面、更精炼的合并后记忆。合并后的记忆会替换旧的重复项，实现记忆库的“进化”。

**关键设计**：
- **分层检测**：先通过向量数据库进行快速的语义搜索，再对候选结果进行精细化的多维度比对，平衡了效率与精度。
- **原子性操作**：合并操作是原子的，确保在删除旧记忆和插入新记忆的过程中，数据一致性得到保障。

## 3. 核心技术与模式

### 3.1 混合智能架构（Hybrid Intelligence Architecture）

这是本域最核心的设计哲学。系统并非完全依赖LLM，而是构建了“LLM优先，规则兜底”的双层处理体系。

- **优势**：
  - **高精度**：在内容复杂、语义模糊时，LLM提供强大的语义理解能力。
  - **高效率**：在内容简单、规则明确时，规则引擎提供毫秒级响应，降低LLM调用成本。
  - **高鲁棒性**：当LLM服务出现故障、超时或API配额耗尽时，规则引擎能保证系统核心功能（分类、评估、去重）持续可用，避免服务雪崩。
- **实现**：所有核心模块（分类、重要性、提取、去重）均提供LLM和规则两种实现，并通过工厂模式（`create_*`）根据配置动态选择。

### 3.2 结构化提取器（Structured Extractor）

系统深度集成`rig`框架的结构化提取功能，这是提升处理可靠性的关键技术。

- **原理**：`rig`允许开发者定义一个结构化的Rust结构体（如`MemoryClassification`、`ImportanceScore`），并让LLM直接输出符合该结构体的JSON格式响应。
- **优势**：
  - **消除解析歧义**：避免了从自由文本中解析“Conversational”或“0.85”这类字符串时可能产生的错误。
  - **提高准确性**：LLM在生成结构化输出时，其输出模式被严格约束，结果更稳定。
  - **简化代码**：开发者无需编写复杂的正则表达式或JSON解析逻辑，直接使用强类型的Rust结构体即可。

### 3.3 工厂模式与依赖注入

- **工厂模式**：`create_memory_classifier`、`create_importance_evaluator`等工厂函数，根据`MemoryConfig`中的`auto_enhance`等配置项，动态创建并返回`MemoryClassifier`、`ImportanceEvaluator`等trait对象的具体实现。这使得系统配置与具体实现完全解耦。
- **依赖注入**：`MemoryManager`通过构造函数接收所有依赖项（`Box<dyn VectorStore>`、`Box<dyn LLMClient>`等），实现了高内聚、低耦合的设计。这使得单元测试变得极为容易，可以轻松地用Mock对象替换真实服务。

### 3.4 多层降级策略（Fallback Strategy）

系统在所有关键路径上都实现了降级策略，确保在任何单一组件失效时，整体功能仍能以降级模式运行。

- **示例**：在`LLMMemoryClassifier::classify_memory`中，首先尝试`rig`结构化提取器，失败后降级为`complete`文本补全，再失败则使用默认值`Conversational`。
- **价值**：这种设计是构建高可用性AI系统的关键，确保了“即使LLM挂了，系统也能用”。

## 4. 与系统其他模块的交互

记忆智能处理域是cortex-mem系统的核心“大脑”，其交互关系如下：

1.  **输入**：接收来自`MemoryManager`的原始记忆内容（`String`）和元数据。
2.  **核心处理**：调用`LLMClient`进行分类、评估、提取和去重分析。
3.  **输出**：返回增强后的、带有丰富元数据的`Memory`对象，供`MemoryManager`持久化到`VectorStore`。
4.  **依赖**：依赖`MemoryConfig`获取阈值、模型名称等配置参数。
5.  **被依赖**：被`MemoryManager`、`OptimizationDetector`和`OptimizationEngine`等模块直接调用，是记忆创建和优化流程的基石。

## 5. 总结

记忆智能处理域通过创新的混合智能架构、结构化提取技术和多层降级策略，成功地将AI大语言模型的潜力转化为可落地、高可靠的工程能力。它不仅是cortex-mem系统智能化的体现，更是其稳定性和可用性的保障。该域的设计充分体现了“智能为先，稳健为本”的工程哲学，为AI智能体的长期记忆管理提供了坚实的技术基础。