# 核心工作流程

## 1. 工作流程概览 (Workflow Overview)

Cortex-Mem系统的核心工作流程是一个多层、异步、基于智能分析的内存管理流水线，其本质是将非结构化的用户交互内容转化为结构化、可检索、可优化的记忆资产。整个流程从用户输入或外部系统请求开始，经过智能分析、元数据增强、向量嵌入和持久化存储四个核心阶段，最终形成AI智能体的长期记忆能力。

### 系统主干工作流程
系统主干工作流程遵循“输入-处理-存储-反馈”的经典模式，但其核心创新在于引入了大语言模型（LLM）作为智能决策引擎，实现了从原始文本到高价值记忆的自动化转换。该流程的主干路径为：
1. **接入层接收请求**：用户通过CLI、HTTP API、MCP协议或TUI界面发起内存管理请求。
2. **核心控制器协调**：MemoryManager作为核心控制器，接收请求并协调多个专业子组件。
3. **智能分析与增强**：通过FactExtractor、MemoryClassifier、ImportanceEvaluator和DuplicateDetector等组件，对内容进行分类、提取、评分和去重。
4. **向量嵌入与存储**：使用LLM生成内容的语义嵌入向量，并将其与增强的元数据一同存储至Qdrant向量数据库。
5. **结果反馈**：向用户或调用方返回操作成功/失败的状态和相关信息。

### 核心执行路径
核心执行路径贯穿了系统所有接入层，其关键节点如下：
- **入口节点**：`cortex-mem-cli/src/main.rs`、`cortex-mem-service/src/main.rs`、`examples/cortex-mem-tars/src/main.rs`、`cortex-mem-mcp/src/main.rs` 等入口文件，负责解析参数、加载配置并初始化核心组件。
- **协调节点**：`cortex-mem-core/src/memory/manager.rs` 中的 `MemoryManager`，是整个流程的中枢，负责调度所有子组件。
- **智能处理节点**：`cortex-mem-core/src/memory/extractor.rs`、`cortex-mem-core/src/memory/classification.rs`、`cortex-mem-core/src/memory/importance.rs` 和 `cortex-mem-core/src/memory/deduplication.rs`，这些组件利用LLM进行深度语义分析。
- **存储节点**：`cortex-mem-core/src/vector_store/qdrant.rs`，负责与Qdrant数据库的交互，实现向量的增删改查。
- **反馈节点**：各接入层的响应处理器，将操作结果以用户友好的方式呈现。

### 关键流程节点
| 节点 | 组件 | 功能 | 输入 | 输出 |
| :--- | :--- | :--- | :--- | :--- |
| 接入 | `MemoryManager::add_memory` | 接收对话消息 | `Vec<Message>` | `Vec<MemoryResult>` |
| 分类 | `MemoryClassifier::classify_memory` | 智能判断记忆类型 | 内容文本 | `MemoryType` |
| 提取 | `FactExtractor::extract_facts` | 抽取用户偏好与事实 | 对话历史 | `Vec<ExtractedFact>` |
| 评分 | `ImportanceEvaluator::evaluate_importance` | 评估记忆重要性 | `Memory` | `f32` (0.0-1.0) |
| 去重 | `DuplicateDetector::detect_duplicates` | 检测语义相似记忆 | `Memory` | `Vec<Memory>` |
| 嵌入 | `LLMClient::embed` | 生成语义向量 | 内容文本 | `Vec<f32>` |
| 存储 | `QdrantVectorStore::upsert` | 持久化存储 | `PointStruct` | `Result<()>` |

### 流程协调机制
系统采用**组合模式**和**依赖注入**实现高度解耦的协调机制。`MemoryManager`不直接实现任何智能分析逻辑，而是通过持有多个`Box<dyn Trait>`接口的实例来委托任务。例如：
- `MemoryManager` 持有 `Box<dyn FactExtractor>`，当需要提取事实时，调用其 `extract_facts()` 方法。
- `MemoryManager` 持有 `Box<dyn MemoryClassifier>`，当需要分类时，调用其 `classify_memory()` 方法。
- 所有子组件（如 `LLMFactExtractor`、`LLMMemoryClassifier`）都实现了各自的接口，但内部逻辑完全独立。

这种设计使得：
1. **可插拔性**：可以轻松替换LLM后端（如OpenAI、Claude）或规则引擎。
2. **可测试性**：可以为每个子组件编写独立的单元测试。
3. **可扩展性**：可以添加新的分析维度（如情感分析）而无需修改核心逻辑。

## 2. 主要工作流程 (Main Workflows)

### 核心业务流程详解：记忆创建与增强流程

这是系统最核心、最频繁执行的流程，负责将用户输入转化为结构化记忆。其详细执行顺序如下：

1.  **请求接收与解析**：
    - **CLI**：用户执行 `cortex-mem-cli add --content "..."`，`AddCommand` 解析命令行参数。
    - **HTTP API**：客户端发送 `POST /memory` 请求，`handlers.rs` 中的 `create_memory` 处理函数解析JSON请求体。
    - **TUI**：用户在输入框中输入内容并按回车，`events.rs` 的 `handle_key_event` 捕获事件，将内容传递给 `agent.rs`。
    - **MCP**：外部AI代理通过 `CallToolRequestParam` 调用 `store_memory` 工具。

2.  **记忆类型判断与预处理**：
    - `MemoryManager` 接收到内容后，首先判断是否为对话格式（包含换行符或`User:`/`Assistant:`前缀）。
    - 若为对话格式，调用 `parse_conversation_content` 函数，将多行文本解析为 `Vec<Message>` 结构，其中每个 `Message` 包含 `role` (user/assistant) 和 `content` 字段。
    - 若为普通文本，则直接创建一个单条 `Message`。

3.  **智能分析与元数据增强**：
    - **分类**：调用 `MemoryClassifier`（通常是 `LLMMemoryClassifier`），使用预设的提示词（`MEMORY_UPDATE_PROMPT`）让LLM判断内容属于 `Conversational`, `Factual`, `Personal` 等哪种类型。
    - **事实提取**：调用 `FactExtractor`（通常是 `LLMFactExtractor`），使用 `USER_MEMORY_EXTRACTION_PROMPT` 和 `AGENT_MEMORY_EXTRACTION_PROMPT` 等提示词，让LLM从对话中提取出结构化的事实（如“用户喜欢咖啡”、“用户住在纽约”）。
    - **重要性评估**：调用 `ImportanceEvaluator`（通常是 `LLMImportanceEvaluator`），使用 `create_importance_prompt` 生成的提示词，让LLM为该记忆打分（0.0-1.0），分数越高表示越重要。
    - **关键词与实体提取**：调用 `LLMClient` 的 `extract_keywords` 和 `extract_entities` 方法，自动提取内容中的关键词和命名实体（如人名、地名）。
    - **去重检测**：调用 `DuplicateDetector`（通常是 `AdvancedDuplicateDetector`），计算当前记忆与数据库中所有记忆的语义相似度（余弦相似度）。若相似度超过阈值（默认0.85），则标记为潜在重复项。

4.  **向量嵌入与存储**：
    - 调用 `LLMClient::embed` 方法，将原始内容文本（或合并后的文本）转换为一个高维浮点向量（如1536维）。
    - 将生成的向量、原始内容、所有元数据（类型、重要性、关键词、实体、时间戳等）封装成 `Memory` 结构体。
    - 调用 `QdrantVectorStore::upsert` 方法，将 `Memory` 转换为Qdrant的 `PointStruct`，并将其插入或更新到向量数据库的集合中。

5.  **结果反馈**：
    - **CLI**：打印成功信息和操作摘要。
    - **HTTP API**：返回 `SuccessResponse` JSON，包含 `id` 和 `message`。
    - **TUI**：在对话区域显示AI的回复，并在后台异步执行上述流程，确保UI流畅。
    - **MCP**：返回 `CallToolResult`，包含成功状态和存储的 `memory_id`。

### 关键技术流程说明：记忆优化流程

该流程是系统实现长期健康和信息密度的关键，它是一个周期性或按需触发的维护流程。

1.  **触发**：用户执行 `cortex-mem-cli optimize` 命令，或系统根据配置的定时任务（如每天凌晨）自动启动。
2.  **问题检测**：`OptimizationDetector` 被实例化，它通过 `MemoryManager` 获取所有记忆，并应用五种检测算法：
    - **重复检测**：使用 `AdvancedDuplicateDetector` 计算所有记忆对的语义相似度，找出高度相似的组。
    - **低质量检测**：基于内容长度、元数据完整性、重要性评分（低于阈值）等规则进行评估。
    - **过时检测**：检查记忆的 `updated_at` 时间戳，若超过配置的衰减天数（如30天），则标记为过时。
    - **分类不当检测**：检查记忆的 `memory_type` 是否与内容语义匹配（如一个“个人偏好”被错误分类为“事实”）。
    - **空间效率检测**：识别数量过多、重要性过低或内容过大的记忆。
3.  **计划制定**：`OptimizationAnalyzer` 接收检测结果（`Vec<OptimizationIssue>`）和用户指定的策略（`Full`, `Deduplication`等），生成一个 `OptimizationPlan`。该计划包含：
    - **问题列表**：所有被发现的问题。
    - **操作列表**：为每个问题生成的建议操作（如 `Merge`、`Delete`、`Archive`）。
    - **预估影响**：预计能节省多少空间、提升多少质量。
4.  **执行与报告**：`ExecutionEngine` 按照计划，分批（默认100个为一批）执行操作。它调用 `MemoryManager` 的 `delete`、`update` 等方法来修改数据库。`ResultReporter` 在执行后生成详细的文本、JSON或YAML格式的报告，总结优化成效。

### 流程执行顺序和依赖

整个系统的工作流程具有严格的依赖关系，形成了一个清晰的调用链：

```
[接入层] (CLI, HTTP, MCP, TUI)
        ↓
[MemoryManager] (核心控制器)
        ↓
├── [LLMClient] (提供嵌入、分类、提取等AI能力)
├── [FactExtractor] (依赖LLMClient)
├── [MemoryClassifier] (依赖LLMClient)
├── [ImportanceEvaluator] (依赖LLMClient)
├── [DuplicateDetector] (依赖LLMClient + VectorStore)
└── [VectorStore] (Qdrant, 存储和检索)
```

- **依赖关系**：`MemoryManager` 依赖 `LLMClient` 和 `VectorStore`。`FactExtractor`、`MemoryClassifier` 等智能组件依赖 `LLMClient`。`DuplicateDetector` 既依赖 `LLMClient` 进行内容分析，也依赖 `VectorStore` 进行向量搜索。
- **执行顺序**：对于一次 `add_memory` 操作，执行顺序是固定的：`分类` → `提取` → `评分` → `去重` → `嵌入` → `存储`。所有步骤都是异步的，但 `MemoryManager` 会按顺序等待每个步骤完成，确保元数据的完整性。

### 输入输出数据流转

- **输入**：
    - **原始数据**：用户输入的纯文本、对话历史（`String` 或 `Vec<Message>`）。
    - **元数据**：`user_id`, `agent_id`, `memory_type` (可选)。
- **中间数据**：
    - `MemoryMetadata`：包含 `memory_type`, `importance_score`, `entities`, `topics`, `keywords`, `hash` 等字段。
    - `Vec<f32>`：由LLM生成的语义嵌入向量。
    - `OptimizationIssue`：包含 `kind`, `severity`, `affected_memories` 等字段的优化问题描述。
- **输出**：
    - **成功**：`Memory` 结构体（包含 `id`, `content`, `embedding`, `metadata`）被持久化，返回 `id` 或 `SuccessResponse`。
    - **失败**：返回 `MemoryError` 枚举类型的错误，如 `LLMError`, `VectorStoreError`。

## 3. 流程协调与控制 (Flow Coordination)

### 多模块协调机制

Cortex-Mem的协调机制是其架构的精髓，它采用了**依赖注入**和**接口抽象**的组合模式，实现了模块间的松耦合。

- **核心控制器**：`MemoryManager` 是所有协调的中心。它不包含任何具体的分析逻辑，而是通过其构造函数接收所有子组件的实例。
    ```rust
    pub struct MemoryManager {
        vector_store: Box<dyn VectorStore>,
        llm_client: Box<dyn LLMClient>,
        fact_extractor: Box<dyn FactExtractor>,
        memory_classifier: Box<dyn MemoryClassifier>,
        importance_evaluator: Box<dyn ImportanceEvaluator>,
        duplicate_detector: Box<dyn DuplicateDetector>,
        // ... 其他组件
    }
    ```
- **接口定义**：`FactExtractor`, `MemoryClassifier` 等都是 `trait`，定义了方法签名（如 `async fn extract_facts(&self, messages: &[Message]) -> Result<Vec<ExtractedFact>>`）。
- **具体实现**：`LLMFactExtractor`、`LLMMemoryClassifier` 等结构体实现了这些 `trait`，它们内部调用 `LLMClient` 来完成具体的AI任务。
- **工厂函数**：`create_fact_extractor`, `create_memory_classifier` 等工厂函数根据配置（如 `config.auto_enhance`）决定是使用基于LLM的实现还是基于规则的轻量级实现。

这种机制使得：
- **替换LLM**：只需实现一个新的 `LLMClient`（如 `ClaudeLLMClient`），并将其注入 `MemoryManager`，整个系统就能无缝切换。
- **启用/禁用功能**：通过配置 `auto_enhance: false`，工厂函数会返回 `RuleBasedMemoryClassifier`，从而关闭LLM调用，提升性能。

### 状态管理和同步

系统主要通过**异步任务**和**共享状态**来管理状态。

- **异步任务**：所有I/O操作（网络、磁盘）都使用 `async/await`，确保主线程不会被阻塞。例如，`MemoryManager::add_memory` 是一个 `async fn`，它内部的 `llm_client.embed()` 和 `vector_store.upsert()` 都是异步的。
- **共享状态**：
    - **TUI应用**：`App` 结构体是全局状态的持有者，包含 `conversations`, `current_input`, `logs` 等字段。UI线程和后台处理线程通过 `tokio::sync::mpsc` 通道进行通信。`redirect_log_to_ui` 函数将日志消息发送到通道，UI线程从通道接收并更新 `App` 的 `logs` 字段。
    - **优化流程**：`DefaultMemoryOptimizer` 使用 `tokio::sync::RwLock<HashMap<String, OptimizationStatus>>` 来跟踪所有正在进行的优化任务的状态（`Running`, `Completed`），确保多个并发请求不会互相干扰。

### 数据传递和共享

- **内存数据**：`Memory` 结构体是系统内数据传递的核心载体。它包含了所有需要的信息（内容、向量、元数据），在 `MemoryManager` 和 `VectorStore` 之间传递。
- **配置数据**：`Config` 结构体在系统启动时被加载一次，然后通过 `Arc<Config>`（原子引用计数）在所有模块间共享，确保配置的一致性。
- **LLM客户端**：`LLMClient` 是一个 `dyn Clone` 的 trait 对象，`MemoryManager` 通过 `dyn_clone::clone_box` 创建其克隆，确保每个子组件都能独立地与LLM服务通信，避免了单点瓶颈。

### 执行控制和调度

- **命令分发**：在CLI中，`main.rs` 使用 `clap` 解析命令行参数，然后通过 `match` 语句将控制权分发给 `AddCommand`, `SearchCommand` 等具体命令处理器。
- **HTTP路由**：在HTTP服务中，`Axum` 框架根据请求的URL路径（`/memory`, `/search`）和HTTP方法（`POST`, `GET`）将请求路由到对应的处理函数。
- **异步任务调度**：`tokio` 运行时负责调度所有的异步任务。例如，在TUI中，当用户输入后，`agent.rs` 会启动一个异步任务来处理 `agent_reply_with_memory_retrieval_streaming`，而UI线程则继续监听键盘事件，实现了真正的并发。
- **优化任务调度**：`DefaultMemoryOptimizer` 内部使用 `ExecutionEngine` 的 `batch_size` 和 `max_concurrent_tasks` 配置来控制执行的并发度，防止对LLM或Qdrant服务造成过载。

## 4. 异常处理与恢复 (Exception Handling)

### 错误检测和处理

系统采用了**统一的错误类型**和**分层的错误处理**策略。

- **统一错误类型**：`cortex-mem-core/src/error.rs` 定义了一个 `MemoryError` 枚举，涵盖了所有可能的错误场景：
    ```rust
    #[derive(Debug, thiserror::Error)]
    pub enum MemoryError {
        #[error("LLM service error: {0}")]
        LLM(String),
        #[error("Vector store error: {0}")]
        VectorStore(String),
        #[error("Configuration error: {0}")]
        Config(String),
        #[error("Validation error: {0}")]
        Validation(String),
        #[error("Serialization error: {0}")]
        Serialization(String),
        // ... 其他错误
    }
    ```
    所有子组件在发生错误时，都会将其转换为 `MemoryError` 并返回 `Result<T, MemoryError>`。

- **分层处理**：
    - **底层组件**（如 `QdrantVectorStore`）：捕获网络错误、数据库连接失败等，转换为 `MemoryError::VectorStore`。
    - **中间层**（如 `MemoryManager`）：捕获 `MemoryError`，进行日志记录，并可能进行重试或降级。
    - **接入层**（如 `handlers.rs`）：将 `MemoryError` 转换为HTTP响应码（如500 Internal Server Error）和JSON错误体。

### 异常恢复机制

系统设计了多种恢复机制，确保服务的高可用性。

- **LLM服务降级**：在 `LLMClient` 的实现中，如果 `extract_structured_facts` 失败，会自动降级到 `complete` 方法，使用字符串解析的方式获取结果。这保证了即使LLM的结构化提取API不稳定，系统仍能工作。
- **向量存储健康检查**：`MemoryManager` 实现了 `health_check` 方法，定期检查Qdrant和LLM服务的可用性。如果服务暂时不可用，系统会记录错误，但不会立即崩溃，而是等待服务恢复。
- **优化流程的容错**：`ExecutionEngine` 在执行优化计划时，会逐条执行操作。如果某条操作（如删除某个记忆）失败，它会记录错误并继续执行后续操作，而不是中断整个优化流程。

### 容错策略设计

- **幂等性**：`MemoryManager::store` 和 `MemoryManager::update` 操作是幂等的。多次调用同一个ID的更新操作，结果是一致的。
- **重试机制**：在 `QdrantVectorStore` 和 `OpenAILLMClient` 中，对网络请求实现了简单的重试逻辑（如最多重试3次）。
- **超时控制**：所有异步操作都设置了合理的超时时间，防止因网络延迟导致的无限等待。
- **数据完整性**：`Memory` 结构体中的 `hash` 字段是内容的SHA256哈希，用于快速检测重复，避免了因网络传输错误导致的重复存储。

### 失败重试和降级

- **重试**：在 `OpenAILLMClient::complete` 方法中，如果调用失败，会等待一段时间后重试。
- **降级**：在 `LLMMemoryClassifier::classify_memory` 中，如果LLM的结构化提取器（rig）失败，会立即降级到传统的文本生成+解析方式，确保分类功能不中断。
- **优雅降级**：在TUI中，如果后台的内存存储任务失败，UI会显示一个错误日志，但不会影响用户继续与AI对话，用户体验不受影响。

## 5. 关键流程实现 (Key Process Implementation)

### 核心算法流程：语义相似度计算与去重

这是系统实现信息密度的核心算法，由 `AdvancedDuplicateDetector` 实现。

```rust
fn calculate_semantic_similarity(&self, memory1: &Memory, memory2: &Memory) -> f32 {
    let dot_product: f32 = memory1.embedding.iter()
        .zip(memory2.embedding.iter())
        .map(|(a, b)| a * b)
        .sum();

    let norm1: f32 = memory1.embedding.iter().map(|x| x * x).sum::<f32>().sqrt();
    let norm2: f32 = memory2.embedding.iter().map(|x| x * x).sum::<f32>().sqrt();

    if norm1 == 0.0 || norm2 == 0.0 {
        return 0.0;
    }

    dot_product / (norm1 * norm2) // 余弦相似度
}
```

1.  **计算余弦相似度**：这是最核心的算法。它计算两个向量的夹角余弦值，值域为[-1, 1]，值越接近1表示越相似。
2.  **综合评分**：除了语义相似度，`are_similar` 方法还会计算内容相似度（基于词频的Jaccard系数）和元数据相似度（用户ID、实体、主题是否匹配）。
3.  **加权决策**：最终的相似度是这三个分数的加权平均。只有当综合评分超过配置的阈值（默认0.85）时，才会被判定为重复。
4.  **智能合并**：如果检测到重复，`merge_memories` 方法会调用LLM，使用一个专门的提示词，让LLM将多个相似的记忆内容合并成一个更全面、更简洁的版本。

### 数据处理管道

整个记忆创建流程构成了一个清晰的数据处理管道：

```
[原始文本] 
    ↓ (parse_conversation_content)
[Vec<Message>] 
    ↓ (MemoryClassifier::classify_memory)
[MemoryType] 
    ↓ (FactExtractor::extract_facts)
[Vec<ExtractedFact>] 
    ↓ (ImportanceEvaluator::evaluate_importance)
[f32] 
    ↓ (LLMClient::extract_keywords, extract_entities)
[Vec<String>, Vec<String>] 
    ↓ (DuplicateDetector::detect_duplicates)
[Vec<Memory>] (潜在重复项)
    ↓ (LLMClient::embed)
[Vec<f32>] 
    ↓ (Memory::new)
[Memory] (完整结构体)
    ↓ (QdrantVectorStore::upsert)
[持久化存储]
```

每个环节都对数据进行一次转换和增强，最终输出一个信息密度极高的记忆单元。

### 业务规则执行

系统内置了多种业务规则，由 `RuleBased` 组件执行，作为LLM的轻量级替代。

- **语言检测**：`detect_language` 函数通过检查Unicode字符范围（如中文字符范围 `0x4E00-0x9FFF`）来判断文本语言，无需调用LLM。
- **重要性评分**：`RuleBasedImportanceEvaluator` 根据内容长度和记忆类型进行启发式评分。例如，`Personal` 类型的记忆默认评分为0.8，内容长度超过1000字符评分为0.7。
- **分类**：`RuleBasedMemoryClassifier` 通过关键词匹配进行快速分类。例如，如果内容包含“喜欢”、“偏好”、“我叫”等词，则分类为 `Personal`。
- **去重**：`RuleBasedDuplicateDetector` 仅通过内容的精确字符串匹配和长度比较来检测重复，速度极快，适用于对精度要求不高的场景。

### 技术实现细节

- **异步I/O**：所有网络和磁盘操作都使用 `async/await`，基于 `tokio` 运行时，确保高并发性能。
- **零拷贝**：`Memory` 结构体中的 `content` 字段是 `String`，但在传递给LLM时，通过引用传递，避免了不必要的内存拷贝。
- **序列化**：所有数据结构都实现了 `Serialize` 和 `Deserialize`，便于通过HTTP API和MCP协议进行网络传输。
- **日志**：使用 `tracing` 库，支持不同日志级别（info, debug, trace），并能输出到文件，便于运维监控。
- **配置**：使用 `serde` 和 `config` 库，从TOML文件中加载配置，支持默认值和环境变量覆盖，部署灵活。
- **安全**：`sanitize_for_cypher` 函数对特殊字符进行编码，防止Cypher查询注入攻击。