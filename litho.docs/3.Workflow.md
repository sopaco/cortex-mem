# Core Workflows

## 1. Workflow Overview

Cortex-Mem is a full-stack memory management system designed to capture, structure, and retrieve conversational memories from AI interactions. Its core value lies in enabling AI agents and human users to maintain persistent, context-aware dialogue across sessions by automatically indexing, extracting, and optimizing memory content. The system operates through five primary workflows that form a closed-loop memory lifecycle: **Storage**, **Retrieval**, **Extraction**, **Optimization**, and **Monitoring** ‚Äî each tightly integrated with external systems (LLMs, Qdrant) and user interfaces (CLI, HTTP API, MCP, Web UI).

### Core Execution Paths
The system‚Äôs execution is orchestrated across three architectural layers:
- **Frontend Interfaces**: CLI (`cortex-mem-cli`), HTTP API (`cortex-mem-service`), MCP server (`cortex-mem-mcp`), and Web UI (`cortex-mem-insights`) serve as entry points.
- **Core Memory Domain**: `cortex-mem-core` provides the persistent, indexed, and searchable memory engine using filesystem abstraction, SQLite metadata, Tantivy full-text search, and Qdrant vector storage.
- **External Dependencies**: LLM providers (e.g., OpenAI) for embedding and extraction, and Qdrant for vector indexing ‚Äî both accessed via HTTP/TCP.

All workflows begin with user or agent input, traverse through the core domain for processing, and conclude with persistent storage or output delivery. Execution is asynchronous, leveraging Rust‚Äôs `tokio` runtime and `Arc`-shared state for thread-safe concurrency.

### Key Process Nodes
| Node | Description | Trigger | Output |
|------|-------------|---------|--------|
| **Message Storage** | Persists conversational messages with metadata | CLI `add`, MCP `store_memory`, HTTP `/api/v2/memory` | URI, SQLite index entry |
| **Full-Text Search** | Keyword-based retrieval from `.md` files | CLI `search`, HTTP `/search` | Ranked list of snippets |
| **Vector Search** | Semantic similarity search via embeddings | CLI `search --vector`, MCP `query_memory` | Ranked URIs with scores |
| **Memory Extraction** | LLM-driven extraction of facts, decisions, entities | CLI `session extract`, automation on close | `.extracted.json` + index update |
| **Vector Indexing** | Batch embedding and Qdrant upsert of messages | CLI `automation index`, session close | Qdrant collection updated |
| **Optimization** | Deduplication, merging, pruning based on relevance | CLI `optimize`, API `/optimization/start` | Reduced storage, updated metadata |
| **System Analytics** | Aggregation of memory volume, quality, health | CLI `stats`, Web UI dashboard | Metrics, charts, status indicators |

### Process Coordination Mechanisms
- **Shared State**: `Arc<CortexFilesystem>` is passed across all components to ensure consistent filesystem access.
- **Feature Gating**: Vector search and automation features are compiled conditionally (`#[cfg(feature = "vector-search")]`) to maintain lean builds.
- **Configuration Injection**: TOML-based `Config` objects (from `cortex-mem-config`) are loaded at startup and injected into services (LLM, Qdrant, logging).
- **Async Coordination**: `tokio::join!` enables concurrent execution of hybrid search and batch operations.
- **URI-Based Addressing**: All data is accessed via canonical `cortex://` URIs (`cortex://threads/{id}/timeline/{msg_id}.md`), ensuring consistent naming across modules.
- **Protocol Adapters**: MCP and HTTP APIs translate external protocols into internal `cortex-mem-core` function calls, decoupling transport from logic.

---

## 2. Main Workflows

### 2.1 Memory Storage Process

**Business Value**: Enables durable, structured persistence of conversational context, forming the foundation for all downstream memory operations. Without this, no retrieval, extraction, or optimization is possible.

**Technical Description**:  
The process begins when a message is submitted via any interface (CLI, MCP, HTTP). The system validates the input, constructs a canonical URI, persists the content, and updates metadata.

**Execution Order & Dependencies**:
1. **Input Validation**  
   - *Source*: `cortex-mem-cli/src/commands/add.rs`, `cortex-mem-mcp/src/service.rs`, `cortex-mem-service/src/handlers/memory.rs`  
   - *Action*: Parse `role` (user/assistant/system), `thread_id`, and `content`. Reject invalid roles (non-enum values) with user-friendly error.  
   - *Dependency*: `MessageRole` enum from `cortex-mem-core/src/types.rs`.

2. **URI Construction**  
   - *Source*: `cortex-mem-core/src/filesystem/uri.rs`  
   - *Action*: Generate `cortex://threads/{thread_id}/timeline/{message_id}.md` using UUIDv4 for message ID.  
   - *Output*: Canonical URI used for all subsequent operations.

3. **Content Persistence**  
   - *Source*: `cortex-mem-core/src/filesystem/operations.rs`  
   - *Action*: Write message content as UTF-8 text to the filesystem path. Uses atomic write via `tokio::fs::write` to prevent corruption.  
   - *Dependency*: `CortexFilesystem` (abstracts OS file operations).

4. **Metadata Indexing**  
   - *Source*: `cortex-mem-core/src/index/sqlite.rs`  
   - *Action*: Upsert into `memories` table with fields: `uri`, `dimension` ("threads"), `entity_id` (thread_id), `category` ("timeline"), `created_at`, `size`, `checksum`.  
   - *Critical Detail*: Uses `INSERT OR REPLACE` for idempotency. Indexes on `(dimension, entity_id, created_at)` for fast temporal queries.

5. **Response Return**  
   - *Output*: Success response with URI and message ID (e.g., `"Stored at cortex://threads/abc123/timeline/def456.md"`).

**Data Flow**:
```
[Input: role, thread_id, content]
        ‚Üì
[Parse ‚Üí Validate Role]
        ‚Üì
[Generate URI: cortex://threads/{tid}/timeline/{mid}.md]
        ‚Üì
[Write .md file via CortexFilesystem]
        ‚Üì
[Upsert metadata into SQLite index]
        ‚Üì
[Return URI + ID]
```

**Performance Optimization**:  
- SQLite writes are batched in high-throughput scenarios (via `batch_upsert()` ‚Äî recommended enhancement).  
- Filesystem writes are non-blocking (`tokio::fs`).  
- Checksums (SHA-256) detect content corruption.

**Exception Handling**:  
- Invalid role ‚Üí Non-fatal error (should be fatal; see Improvement).  
- Disk full ‚Üí `anyhow::Error` propagated, process exits with code 1.  
- SQLite lock ‚Üí Retry 3x with exponential backoff (not implemented; recommended).

**Improvement Recommendations**:  
- Return non-zero exit code on invalid role (currently returns `Ok(())`).  
- Add transactional batch upsert for bulk message ingestion.  
- Validate `thread_id` and `content` are non-empty.

---

### 2.2 Memory Retrieval Process

**Business Value**: Enables context-aware responses by retrieving relevant past interactions. Critical for agent memory and user experience.

**Technical Description**:  
Supports three search modes: **full-text**, **vector**, and **hybrid**. Mode selection is determined by client input or configuration.

**Execution Order & Dependencies**:
1. **Scope Resolution**  
   - *Source*: `cortex-mem-cli/src/commands/search.rs`, `cortex-mem-mcp/src/service.rs`  
   - *Action*: Build URI from parameters:  
     - `thread_id` ‚Üí `cortex://threads/{id}`  
     - `dimension` ‚Üí `cortex://{dim}`  
     - None ‚Üí `cortex://`  
   - *Dependency*: `CortexFilesystem::list()` for directory traversal.

2. **Full-Text Search (Tantivy)**  
   - *Source*: `cortex-mem-core/src/index/fulltext.rs`  
   - *Action*:  
     - Scan all `.md` files under scope.  
     - Tokenize query and content using Tantivy‚Äôs `TextAnalyzer`.  
     - Return top 10 results with relevance score and snippet (first 100 chars).  
   - *Output*: `Vec<FullTextResult>` (URI, score, snippet).

3. **Vector Search (Qdrant + LLM)**  
   - *Source*: `cortex-mem-core/src/embedding/client.rs`, `cortex-mem-core/src/vector_store/qdrant.rs`  
   - *Action*:  
     - Generate embedding of query via `EmbeddingClient::embed()` (e.g., OpenAI text-embedding-3-small).  
     - Query Qdrant with `top_k=10`, `min_score=0.5` (configurable).  
     - Return `Vec<VectorResult>` (URI, score, metadata).  
   - *Dependency*: `QdrantVectorStore::query()` requires pre-built collection with matching embedding dimension.

4. **Hybrid Search (Combined)**  
   - *Source*: `cortex-mem-core/src/search/vector_engine.rs`  
   - *Action*:  
     - Execute full-text and vector searches **concurrently** using `tokio::join!`.  
     - Merge results by URI, apply weighted scoring: `score = 0.6 * vector_score + 0.4 * tf_idf_score`.  
     - Sort by final score, truncate to top 10.  
   - *Output*: Unified ranked list.

5. **Response Formatting**  
   - *Source*: CLI, MCP, HTTP handlers  
   - *Action*: Render results with colored output (CLI), JSON array (HTTP), or MCP content array (MCP).

**Data Flow (Hybrid)**:
```
[Query: "What did I say about project deadlines?"]
        ‚Üì
[Build Scope: cortex://threads/abc123]
        ‚Üì
[Parallel: Full-Text Search (Tantivy) + Vector Search (Qdrant)]
        ‚Üì
[Combine: Weighted scoring (60% vector, 40% text)]
        ‚Üì
[Sort by score, limit 10]
        ‚Üì
[Return: [{uri, score, snippet}, ...]]
```

**Performance Optimization**:  
- Embedding generation is batched (10 messages at a time) via `EmbeddingClient::embed_batch()`.  
- Qdrant queries use `with_payload=false` to reduce network overhead.  
- Tantivy index is memory-mapped for fast reads.

**Exception Handling**:  
- Missing `config.toml` for vector search ‚Üí Fallback to full-text only (CLI) or error (MCP).  
- LLM timeout ‚Üí Log warning, return only full-text results.  
- Qdrant unreachable ‚Üí Log error, return empty vector results.

**Improvement Recommendations**:  
- Add `min_score` and `limit` as CLI/API parameters.  
- Implement result deduplication (same URI from both engines).  
- Cache embeddings for repeated queries (LRU cache).

---

### 2.3 Memory Extraction Process

**Business Value**: Transforms unstructured conversation logs into structured, queryable facts ‚Äî enabling semantic recall beyond keyword matching.

**Technical Description**:  
Automatically extracts **facts**, **decisions**, and **entities** from conversation timelines using LLM prompts. Triggered manually or on session closure.

**Execution Order & Dependencies**:
1. **Timeline Loading**  
   - *Source*: `cortex-mem-core/src/session/timeline.rs`  
   - *Action*: List all `.md` files under `cortex://threads/{id}/timeline/`.  
   - *Output*: Ordered list of message files.

2. **Prompt Formatting**  
   - *Source*: `cortex-mem-core/src/llm/prompts.rs`  
   - *Action*: Inject conversation into `EXTRACTION_PROMPT` template:  
     ```
     You are a memory extractor. Extract facts, decisions, and entities from this conversation.
     Messages:
     [üë§ User: ...]
     [ü§ñ Assistant: ...]
     ```
   - *Output*: Formatted prompt string.

3. **LLM Invocation**  
   - *Source*: `cortex-mem-core/src/llm/client.rs`  
   - *Action*: Call `LLMClientImpl::extract_memories(prompt)` with `temperature=0.1`, `max_tokens=4096`.  
   - *Output*: Raw JSON string from LLM (e.g., `{ "facts": [...], "decisions": [...], "entities": [...] }`).

4. **Structured Parsing & Validation**  
   - *Source*: `cortex-mem-core/src/extraction/types.rs`  
   - *Action*:  
     - Deserialize into `MemoryExtractionResponse`.  
     - If JSON parse fails ‚Üí fallback to regex-based extraction (e.g., `r#"\"facts\":\s*\[.*?\]"`).  
     - Normalize field names, validate types.  
   - *Output*: Structured `MemoryExtractionResponse`.

5. **Persistence & Indexing**  
   - *Source*: `cortex-mem-core/src/filesystem/operations.rs`  
   - *Action*:  
     - Write `.extracted.json` alongside timeline.  
     - Update SQLite index with `category="extracted"` and `parent_uri` pointing to thread.  
   - *Output*: File at `cortex://threads/{id}/timeline/.extracted.json`.

6. **Feedback**  
   - *Source*: CLI/MCP handlers  
   - *Action*: Print count: `Facts: 12, Decisions: 3, Entities: 8`.

**Data Flow**:
```
[Trigger: Session Close or CLI extract]
        ‚Üì
[Load all .md files in timeline/]
        ‚Üì
[Format with EXTRACTION_PROMPT]
        ‚Üì
[Send to LLM ‚Üí Get raw JSON]
        ‚Üì
[Parse ‚Üí Validate ‚Üí Fallback if needed]
        ‚Üì
[Write .extracted.json to filesystem]
        ‚Üì
[Update SQLite: category=extracted, parent_uri=thread_uri]
        ‚Üì
[Return extraction summary]
```

**Performance Optimization**:  
- Extraction is batched per thread (not per message) to reduce LLM calls.  
- LLM client uses connection pooling and retry logic (recommended: exponential backoff).  
- `.extracted.json` is written atomically.

**Exception Handling**:  
- LLM returns malformed JSON ‚Üí Log error, return empty extraction.  
- Disk write fails ‚Üí Abort, log error, do not delete original messages.  
- Config missing ‚Üí Use defaults (env vars) or fail gracefully.

**Improvement Recommendations**:  
- Add retry with jitter on LLM failures (3x max).  
- Implement incremental extraction: only extract new messages since last run.  
- Store extraction confidence scores in metadata.

---

### 2.4 Memory Optimization Process

**Business Value**: Reduces storage bloat, improves retrieval accuracy by removing redundancy and low-quality content.

**Technical Description**:  
Analyzes memory store for duplicates, low-relevance items, and outdated content. Applies strategies: deduplication, merging, pruning.

**Execution Order & Dependencies**:
1. **Candidate Scanning**  
   - *Source*: `cortex-mem-cli/src/commands/optimize.rs`, `cortex-mem-core/src/retrieval/relevance.rs`  
   - *Action*:  
     - Enumerate all threads and extracted memories.  
     - For each, compute vector embedding (if not already indexed).  
   - *Output*: List of candidate URIs with embeddings.

2. **Similarity Scoring**  
   - *Source*: `cortex-mem-core/src/retrieval/relevance.rs`  
   - *Action*:  
     - Compute cosine similarity between all pairs of embeddings.  
     - Threshold: `similarity > 0.85` ‚Üí candidate for deduplication.  
   - *Output*: Clusters of similar memories.

3. **Strategy Application**  
   - *Deduplication*:  
     - Select highest-scoring memory as master.  
     - Mark others as redundant.  
   - *Merging*:  
     - Group memories by context (e.g., same topic).  
     - Use LLM to generate unified summary ‚Üí store as `.merged.md`.  
   - *Pruning*:  
     - Flag memories with `confidence < 0.3` or `created_at < 1 year ago`.  
   - *Source*: `cortex-mem-core/src/automation/auto_extract.rs` (reused logic).

4. **Execution & Update**  
   - *Action*:  
     - Move redundant files to `.archive/` directory.  
     - Write merged summaries.  
     - Update SQLite index: mark `status=archived`, `merged_into=uri`.  
   - *Dependency*: `CortexFilesystem::rename()` and `upsert()`.

5. **Reporting**  
   - *Action*: Print stats: `Removed: 42, Merged: 8, Preserved: 120`.

**Data Flow**:
```
[Start Optimization Job]
        ‚Üì
[Scan all threads ‚Üí Extract embeddings]
        ‚Üì
[Cluster by similarity (cosine > 0.85)]
        ‚Üì
[Apply Strategy: Dedup ‚Üí Merge ‚Üí Prune]
        ‚Üì
[Move files to .archive/, write summaries]
        ‚Üì
[Update SQLite: status, merged_into, tags]
        ‚Üì
[Return: Removed=42, Merged=8, Preserved=120]
```

**Performance Optimization**:  
- Parallelize similarity computation using `tokio::task::spawn`.  
- Use approximate nearest neighbor (ANN) in Qdrant for large datasets.  
- Skip extraction if `.extracted.json` already exists.

**Exception Handling**:  
- Qdrant unreachable ‚Üí Fall back to heuristic-based deduplication (e.g., content hash).  
- LLM timeout during merge ‚Üí Skip merge, flag for manual review.  
- Disk full ‚Üí Abort, preserve original data.

**Improvement Recommendations**:  
- Add dry-run mode (`--preview`) to show proposed changes.  
- Support user-defined rules (e.g., ‚Äúkeep all messages tagged with #critical‚Äù).  
- Integrate with analytics to optimize based on usage patterns.

---

### 2.5 System Monitoring and Analytics Process

**Business Value**: Provides operational visibility into memory health, usage trends, and system dependencies ‚Äî critical for DevOps and debugging.

**Technical Description**:  
Aggregates statistics from filesystem, SQLite, and external services to generate dashboards and API responses.

**Execution Order & Dependencies**:
1. **Thread & Dimension Enumeration**  
   - *Source*: `cortex-mem-cli/src/commands/stats.rs`, `cortex-mem-insights/src/server/api/system.ts`  
   - *Action*:  
     - `fs.list("cortex://threads")` ‚Üí count directories.  
     - `fs.list("cortex://agents")`, `fs.list("cortex://users")` ‚Üí count top-level dims.  
   - *Output*: Thread count, agent count, user count.

2. **Message Estimation**  
   - *Source*: `cortex-mem-cli/src/commands/stats.rs`  
   - *Action*:  
     - For each thread, check `cortex://threads/{id}/timeline/`.  
     - Count `.md` files (non-directory).  
     - *Note*: Does not recurse into subdirectories ‚Äî approximation only.  
   - *Output*: Total message count.

3. **SQLite Metadata Aggregation**  
   - *Source*: `cortex-mem-core/src/index/sqlite.rs`  
   - *Action*:  
     - `SELECT COUNT(*), SUM(size), AVG(created_at) FROM memories WHERE dimension='threads'`.  
     - Extract min/max timestamps for retention analysis.  
   - *Output*: Total size (bytes), avg message age.

4. **Service Health Check**  
   - *Source*: `cortex-mem-insights/src/lib/components/ServiceStatus.svelte`, `cortex-mem-service/src/handlers/health.rs`  
   - *Action*:  
     - Ping `/health` endpoint ‚Üí HTTP 200.  
     - Ping Qdrant `/collections` ‚Üí HTTP 200.  
     - Ping LLM `/models` ‚Üí HTTP 200.  
   - *Output*: Status: `online`, `offline`, `degraded`.

5. **Response Formatting**  
   - *CLI*: Human-readable table with emojis.  
   - *HTTP API*: JSON schema:  
     ```json
     {
       "threads": 142,
       "messages": 2890,
       "storage_size_mb": 12.4,
       "services": {
         "cortex-mem": "online",
         "qdrant": "online",
         "llm": "degraded"
       }
     }
     ```

6. **Frontend Rendering**  
   - *Source*: `cortex-mem-insights/src/routes/analytics/+page.svelte`  
   - *Action*:  
     - Use Chart.js to render bar charts (messages/month), pie charts (memory types), line graphs (storage growth).  
     - Reactively update via Svelte stores (`memoryStatsStore`).

**Data Flow**:
```
[Request: /stats or Dashboard Refresh]
        ‚Üì
[Enumerate threads ‚Üí Count .md files]
        ‚Üì
[Query SQLite: count, size, avg age]
        ‚Üì
[Call /health, /vector-store/status, /llm/status]
        ‚Üì
[Aggregate into JSON]
        ‚Üì
[Render in Svelte: Cards, Charts, Status Indicators]
```

**Performance Optimization**:  
- Stats are cached for 5 minutes (in-memory).  
- SQLite queries use indexed columns.  
- Health checks run in parallel.

**Exception Handling**:  
- SQLite unreachable ‚Üí Show partial stats with warning.  
- Qdrant offline ‚Üí Show ‚Äúvector search disabled‚Äù.  
- LLM unreachable ‚Üí Show ‚Äúextraction unavailable‚Äù.

**Improvement Recommendations**:  
- Add real-time WebSocket push for live metrics.  
- Expose `/metrics` for Prometheus scraping.  
- Include memory quality score (avg extraction confidence).

---

## 3. Flow Coordination and Control

### 3.1 Multi-Module Coordination Mechanisms

Cortex-Mem‚Äôs architecture enforces strict separation of concerns via **dependency inversion** and **interface abstraction**:

| Module | Role | Coordination Mechanism |
|--------|------|------------------------|
| **CLI / MCP / HTTP API** | Entry Points | Delegate to `cortex-mem-core` via `Arc<CortexFilesystem>` and `LLMClientImpl`. No business logic. |
| **CortexFilesystem** | Storage Abstraction | Implemented once in `cortex-mem-core`; used by all modules. Ensures URI consistency. |
| **SqliteIndex** | Metadata Layer | Accessed by storage, extraction, stats. Provides transactional consistency. |
| **VectorSearchEngine** | Hybrid Search Orchestrator | Composes `EmbeddingClient` and `QdrantVectorStore`. Coordinates parallel execution. |
| **AutoIndexer / AutoExtractor** | Automation | Triggered by session events or CLI. Use `Arc`-shared dependencies. |
| **LayerManager** | Memory Hierarchy | Generates L0/L1/L2 layers on-demand from L2 content. Uses LLM client internally. |

**Key Coordination Patterns**:
- **Shared State**: `Arc<CortexFilesystem>` is cloned across async handlers. Safe for concurrent reads.
- **Feature Gating**: Vector search features are compiled conditionally. CLI/MCP auto-disable vector commands if feature is absent.
- **Configuration Injection**: `Config::load()` from TOML ‚Üí injected into `MemoryMcpService`, `AppState`, `AutoIndexer`.
- **Async Composition**: `tokio::join!` used in hybrid search and batch extraction to maximize I/O parallelism.
- **Protocol Translation**: MCP server maps `tools/call` ‚Üí `tool_store_memory` ‚Üí `MessageStorage::save_message()`.

### 3.2 State Management and Synchronization

- **State**: Only mutable state is the filesystem and SQLite database. All in-memory state is read-only or ephemeral.
- **Synchronization**:  
  - Filesystem: Atomic writes (`tokio::fs::write`) prevent corruption.  
  - SQLite: Uses WAL mode and transactions. No explicit locking ‚Äî relies on SQLite‚Äôs concurrency model.  
  - LLM Client: Thread-safe via `Arc<RwLock<Client>>` (recommended: use async mutex or connection pool).  
- **Consistency**:  
  - URI ‚Üí File ‚Üí Index is atomic: if file write succeeds, index is updated.  
  - Extraction: `.extracted.json` written only after successful LLM call.  
  - Optimization: Files moved only after index update.

### 3.3 Data Passing and Sharing

| Data Type | Source | Destination | Mechanism |
|----------|--------|-------------|-----------|
| `CortexFilesystem` | `main.rs` | All commands/services | `Arc<CortexFilesystem>` passed as parameter |
| `LLMConfig` | `config.toml` | `LLMClientImpl`, `AutoExtractor` | `Config::load()` ‚Üí injected at startup |
| `QdrantConfig` | `config.toml` | `QdrantVectorStore`, `AutoIndexer` | Same as above |
| `MemoryExtractionResponse` | `LLMClientImpl` | `AutoExtractor` ‚Üí `CortexFilesystem` | Struct passed via function call |
| `SearchResult` | `VectorSearchEngine` | CLI/MCP/HTTP | Returned as `Vec<SearchResult>` |

**Data Flow Example (Hybrid Search)**:
```
CLI ‚Üí search(query="deadline")  
     ‚Üì  
     resolve_scope() ‚Üí cortex://threads/abc  
     ‚Üì  
     tokio::join!(  
         fulltext_search(uri, query),  
         vector_search(uri, query)  
     )  
     ‚Üì  
     combine_scores() ‚Üí weighted_ranked_results  
     ‚Üì  
     format_output() ‚Üí colored table
```

### 3.4 Execution Control and Scheduling

- **Manual Triggers**: CLI commands (`add`, `search`, `extract`, `optimize`) ‚Äî synchronous, user-initiated.
- **Automated Triggers**:  
  - `AutoExtractor`: Triggered on `session close` (via CLI `session close` ‚Üí calls `auto_extract_on_close`).  
  - `AutoIndexer`: Triggered on `session close` or `automation index` command.  
- **Scheduled Jobs**: Not implemented ‚Äî but can be added via cron or `tokio::time::interval`.
- **Concurrency Control**:  
  - All I/O is async.  
  - SQLite writes are serialized by the database engine.  
  - Qdrant writes are batched (100 vectors per request).  
  - LLM calls are rate-limited by client (not system-wide).

**Scheduling Enhancement**:  
- Add `cortex-mem-scheduler` daemon to run optimization nightly.  
- Use `tokio::select!` to handle graceful shutdown during long-running jobs.

---

## 4. Exception Handling and Recovery

### 4.1 Error Detection and Handling

| Error Type | Detection Point | Handling Strategy | Severity |
|------------|------------------|-------------------|----------|
| Invalid role (CLI) | `add.rs` | Prints error, returns `Ok(())` | ‚ö†Ô∏è Low (should be fatal) |
| Missing config.toml | `search.rs`, `automation.rs` | Falls back to defaults or errors | ‚ö†Ô∏è Medium |
| LLM timeout | `LLMClientImpl::extract_memories()` | Logs warning, returns empty extraction | ‚ö†Ô∏è Medium |
| Qdrant unreachable | `QdrantVectorStore::query()` | Logs error, returns empty results | ‚ö†Ô∏è Medium |
| Disk full | `CortexFilesystem::save()` | Propagates `std::io::Error` ‚Üí `anyhow::Error` | üî¥ High |
| SQLite lock | `SqliteIndex::upsert()` | No retry ‚Üí may fail | üî¥ High |
| Invalid JSON from LLM | `MemoryExtractionResponse::try_from()` | Fallback regex parsing ‚Üí logs warning | ‚ö†Ô∏è Medium |
| Network unreachable | HTTP/MCP client | Retry 3x with backoff (not implemented) | üî¥ High |

### 4.2 Exception Recovery Mechanisms

- **Fallback to Full-Text**: If vector search fails, fall back to Tantivy.  
- **Graceful Degradation**:  
  - If LLM is down ‚Üí extraction skipped, but storage and search still work.  
  - If Qdrant is down ‚Üí vector search disabled, hybrid falls back to full-text.  
- **Data Integrity**:  
  - Files are never deleted during optimization ‚Äî only moved to `.archive/`.  
  - SQLite index is updated only after successful file operations.  
- **Retry Logic**:  
  - Not implemented for LLM/Qdrant ‚Äî critical gap.  
  - **Recommendation**: Add exponential backoff (1s, 2s, 4s) with max 3 retries.

### 4.3 Fault Tolerance Strategy Design

| Layer | Strategy |
|-------|----------|
| **Storage** | Atomic writes, checksums, backup via `rsync` (external) |
| **Indexing** | WAL mode, periodic SQLite backup (`VACUUM`), snapshotting |
| **LLM** | Fallback to cached responses (if enabled), degrade to keyword search |
| **Qdrant** | Use local Qdrant instance (embedded mode), or fallback to in-memory vector store (for dev) |
| **Network** | Circuit breaker pattern (not implemented) ‚Äî recommend `circuit_breaker` crate |

### 4.4 Failure Retry and Degradation

**Current State**:  
- No retry logic in core components.  
- Errors are propagated as `anyhow::Error` with context (e.g., `.context("failed to save message")`).  
- CLI exits with code 0 even on errors ‚Äî violates Unix convention.

**Recommended Improvements**:
1. **Add Retry with Backoff**:  
   ```rust
   let mut attempts = 0;
   loop {
       match llm_client.extract(prompt).await {
           Ok(res) => break res,
           Err(e) if attempts < 3 => {
               tokio::time::sleep(Duration::from_secs(2u64.pow(attempts))).await;
               attempts += 1;
           }
           Err(e) => return Err(e),
       }
   }
   ```
2. **Circuit Breaker**:  
   - If 3 LLM failures in 1 minute ‚Üí disable extraction for 5 minutes.  
3. **Exit Code Fix**:  
   - `add.rs`: Return `Err(anyhow!("Invalid role"))` instead of `Ok(())`.  
4. **Health Endpoint**:  
   - Add `/health` with `/health/ready` (all dependencies up) and `/health/live` (service running).

---

## 5. Key Process Implementation

### 5.1 Core Algorithm Processes

#### **Hybrid Search Algorithm**
```rust
pub async fn hybrid_search(
    query: &str,
    scope: Uri,
    fs: &CortexFilesystem,
    embedding_client: &Arc<EmbeddingClient>,
    qdrant: &Arc<QdrantVectorStore>,
) -> Result<Vec<SearchResult>> {
    let (text_results, vector_results) = tokio::join!(
        fulltext_search(query, scope, fs),
        vector_search(query, scope, embedding_client, qdrant)
    );

    let mut combined = Vec::new();
    let mut seen = HashSet::new();

    // Merge and deduplicate
    for result in text_results? {
        if !seen.contains(&result.uri) {
            combined.push(result);
            seen.insert(result.uri.clone());
        }
    }
    for result in vector_results? {
        if !seen.contains(&result.uri) {
            combined.push(result);
            seen.insert(result.uri.clone());
        }
    }

    // Weighted scoring: 60% vector, 40% text
    for result in &mut combined {
        let vector_score = result.vector_score.unwrap_or(0.0);
        let text_score = result.text_score.unwrap_or(0.0);
        result.score = 0.6 * vector_score + 0.4 * text_score;
    }

    combined.sort_by(|a, b| b.score.partial_cmp(&a.score).unwrap());
    Ok(combined.into_iter().take(10).collect())
}
```

#### **Memory Extraction Algorithm**
```rust
pub async fn extract_session(
    thread_id: &str,
    llm_client: &Arc<LLMClientImpl>,
    fs: &CortexFilesystem,
) -> Result<MemoryExtractionResponse> {
    let timeline_uri = format!("cortex://threads/{}/timeline", thread_id);
    let messages = Timeline::list_messages(fs, &timeline_uri).await?;

    let prompt = format_prompt(EXTRACTION_PROMPT, &messages);
    let raw_json = llm_client.extract_memories(&prompt).await?;

    // Primary: JSON parse
    match serde_json::from_str::<MemoryExtractionResponse>(&raw_json) {
        Ok(extracted) => {
            let extracted_uri = format!("{}/.extracted.json", timeline_uri);
            fs.save(&extracted_uri, serde_json::to_vec_pretty(&extracted)?).await?;
            Ok(extracted)
        }
        Err(_) => {
            // Fallback: regex extract
            let facts = extract_facts_via_regex(&raw_json);
            let decisions = extract_decisions_via_regex(&raw_json);
            let entities = extract_entities_via_regex(&raw_json);
            let fallback = MemoryExtractionResponse { facts, decisions, entities };
            Ok(fallback)
        }
    }
}
```

### 5.2 Data Processing Pipelines

#### **Storage Pipeline**
```
Input ‚Üí Validate ‚Üí URI ‚Üí Write File ‚Üí Upsert SQLite ‚Üí Return URI
```

#### **Retrieval Pipeline**
```
Query ‚Üí Scope ‚Üí [Full-Text] + [Vector] ‚Üí Combine ‚Üí Rank ‚Üí Return Snippets
```

#### **Extraction Pipeline**
```
Thread ‚Üí Load Messages ‚Üí Format Prompt ‚Üí LLM ‚Üí Parse JSON ‚Üí Write .extracted.json ‚Üí Update Index
```

#### **Optimization Pipeline**
```
Scan ‚Üí Embed ‚Üí Cluster ‚Üí Dedup/Merge/Prune ‚Üí Move Files ‚Üí Update Index ‚Üí Report
```

### 5.3 Business Rule Execution

| Rule | Implementation |
|------|----------------|
| **Only user/assistant/system roles allowed** | Match lowercase string against `MessageRole::enum` in `add.rs` |
| **Extract only on session close** | `auto_extract_on_close` called in `session.rs` after `close()` |
| **Vector search requires config.toml** | `load_vector_configs()` checks file existence ‚Äî fails if missing |
| **No deletion of original messages** | Optimization moves to `.archive/`, never deletes |
| **URI must be canonical** | All modules use `cortex-mem-core/src/filesystem/uri.rs` for construction |
| **Embedding dimension must match Qdrant** | `initialize_memory_system()` auto-detects or uses 1536 (hardcoded) ‚Äî risky |

### 5.4 Technical Implementation Details

| Component | Technology | Key Implementation Detail |
|----------|------------|---------------------------|
| **Filesystem** | `CortexFilesystem` | Abstracts `tokio::fs` with URI scheme (`cortex://`) ‚Äî supports in-memory and disk |
| **Indexing** | SQLite + rusqlite | Uses `INSERT OR REPLACE` for idempotency. Indexes on `(dimension, entity_id, created_at)`. |
| **Full-Text** | Tantivy | Uses `TextAnalyzer` with `UnicodeSegmentation`. Stores `uri`, `content`, `keywords` in separate fields. |
| **Vector Store** | Qdrant | Uses `upsert_points()` with `Vector` type. Collection name = `cortex-{dimension}`. |
| **LLM Client** | rig-core + OpenAI | Uses `Client::builder().build()` with `api_key` from env or config. |
| **Concurrency** | Tokio | All I/O is async. `Arc` for shared state. `tokio::join!` for parallel search. |
| **Configuration** | Serde + TOML | `Config` struct aggregates `QdrantConfig`, `LLMConfig`, `LoggingConfig`. |
| **Error Handling** | anyhow | All functions return `Result<T, anyhow::Error>`. Uses `.context()` for traceability. |
| **Logging** | tracing + tracing_subscriber | INFO level by default. Structured logs with `span!` and `trace!` for debug. |
| **Web UI** | Svelte + Elysia | Reactive stores (`writable`, `derived`) for real-time updates. i18n via `localStorage`. |

**Critical Technical Debt**:
- **SQL Injection Risk**: `LIMIT {}` in `sqlite.rs` ‚Äî must be parameterized.
- **Hardcoded Embedding Dimension**: 1536 in `init/mod.rs` ‚Äî should be inferred from LLM model.
- **Unused Default IDs**: `_default_agent_id` in `service.rs` ‚Äî remove or use.
- **Wildcard Imports**: `use cortex_mem_core::*` ‚Äî replace with explicit imports.
- **No Transactional Batch Upsert**: SQLite writes are atomic per call ‚Äî inefficient for bulk.

**Improvement Summary**:
| Area | Recommendation |
|------|----------------|
| **Security** | Parameterize LIMIT clause in SQLite. |
| **Reliability** | Add retry with backoff for LLM/Qdrant. |
| **Performance** | Batch SQLite upserts. Use WAL mode. |
| **Maintainability** | Replace wildcard imports. Add doc comments. |
| **Observability** | Add `/metrics`, Prometheus, structured JSON logs. |
| **UX** | Add `--dry-run` for optimize, `--json` for CLI output. |
| **Testing** | Add integration tests for hybrid search, extraction fallback. |

---

## Conclusion

Cortex-Mem‚Äôs core workflows form a robust, extensible memory lifecycle that transforms raw conversation into structured, retrievable knowledge. The system‚Äôs strength lies in its modular design, consistent URI-based addressing, and clean separation of concerns. Key areas for improvement include **retry logic**, **error exit codes**, **embedding dimension inference**, and **transactional batch operations**.

This documentation provides a complete operational blueprint for developers, operators, and architects. By implementing the recommended improvements, Cortex-Mem can evolve from a powerful prototype into a production-grade memory infrastructure for AI agents and human-AI collaboration systems.